{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CM \"script\" automation specification","text":"<p>Please check the CM documentation for more details about the CM automation language.</p> <p>See the automatically generated catalog of all CM scripts from MLCommons.</p>"},{"location":"#understanding-cm-scripts","title":"Understanding CM scripts","text":"<ul> <li>A CM script is identified by a set of tags and by unique ID. </li> <li>Further each CM script can have multiple variations and they are identified by variation tags which are treated in the same way as tags and identified by a <code>_</code> prefix.</li> </ul>"},{"location":"#cm-script-execution-flow","title":"CM script execution flow","text":"<ul> <li>When a CM script is invoked (either by tags or by unique ID), its <code>_cm.json</code> is processed first which will check for any <code>deps</code> script and if there are, then they are executed in order.</li> <li>Once all the <code>deps</code> scripts are executed, <code>customize.py</code> file is checked and if existing <code>preprocess</code> function inside it is executed if present. </li> <li>Then any <code>prehook_deps</code> CM scripts mentioned in <code>_cm.json</code> are executed similar to <code>deps</code></li> <li>After this, keys in <code>env</code> dictionary is exported as <code>ENV</code> variables and <code>run</code> file if exists is executed.</li> <li>Once run file execution is done, any <code>posthook_deps</code> CM scripts mentioned in <code>_cm.json</code> are executed similar to <code>deps</code></li> <li>Then <code>postprocess</code> function inside customize.py is executed if present.</li> <li>After this stage any <code>post_deps</code> CM scripts mentioned in <code>_cm.json</code> is executed.</li> </ul> <p>** If a script is already cached, then the <code>preprocess</code>, <code>run file</code> and <code>postprocess</code> executions won't happen and only the dependencies marked as <code>dynamic</code> will be executed from <code>deps</code>, <code>prehook_deps</code>, <code>posthook_deps</code> and <code>postdeps</code>.</p>"},{"location":"#input-flags","title":"Input flags","text":"<p>When we run a CM script we can also pass inputs to it and any input added in <code>input_mapping</code> dictionary inside <code>_cm.json</code> gets converted to the corresponding <code>ENV</code> variable.</p>"},{"location":"#conditional-execution-of-any-deps-post_deps","title":"Conditional execution of any <code>deps</code>, <code>post_deps</code>","text":"<p>We can use <code>skip_if_env</code> dictionary inside any <code>deps</code>, <code>prehook_deps</code>, <code>posthook_deps</code> or <code>post_deps</code> to make its execution conditional</p>"},{"location":"#versions","title":"Versions","text":"<p>We can specify any specific version of a script using <code>version</code>. <code>version_max</code> and <code>version_min</code> are also possible options. </p> <ul> <li> <p>When <code>version_min</code> is given, any version above this if present in the cache or detected in the system can be chosen. If nothing is detected <code>default_version</code> if present and if above <code>version_min</code> will be used for installation. Otherwise <code>version_min</code> will be used as <code>version</code>.</p> </li> <li> <p>When <code>version_max</code> is given, any version below this if present in the cache or detected in the system can be chosen. If nothing is detected <code>default_version</code> if present and if below <code>version_max</code> will be used for installation. Otherwise <code>version_max_usable</code> (additional needed input for <code>version_max</code>) will be used as <code>version</code>.</p> </li> </ul>"},{"location":"#variations","title":"Variations","text":"<ul> <li>Variations are used to customize CM script and each unique combination of variations uses a unique cache entry. Each variation can turn on <code>env</code> keys also any other meta including dependencies specific to it. Variations are turned on like tags but with a <code>_</code> prefix. For example, if a script is having tags <code>\"get,myscript\"</code>, to call the variation <code>\"test\"</code> inside it, we have to use tags <code>\"get,myscript,_test\"</code>. </li> </ul>"},{"location":"#variation-groups","title":"Variation groups","text":"<p><code>group</code> is a key to map variations into a group and at any time only one variation from a group can be used in the variation tags. For example, both <code>cpu</code> and <code>cuda</code> can be two variations under the <code>device</code> group, but user can at any time use either <code>cpu</code> or <code>cuda</code> as variation tags but not both.</p>"},{"location":"#dynamic-variations","title":"Dynamic variations","text":"<p>Sometimes it is difficult to add all variations needed for a script like say <code>batch_size</code> which can take many different values. To handle this case, we support dynamic variations using '#' where '#' can be dynamically replaced by any string. For example, <code>\"_batch_size.8\"</code> can be used as a tag to turn on the dynamic variation <code>\"_batch_size.#\"</code>.</p>"},{"location":"#env-flow-during-cm-script-execution","title":"ENV flow during CM script execution","text":"<ul> <li>During a given script execution incoming <code>env</code> dictionary is saved <code>(saved_env)</code> and all the updates happens on a copy of it.</li> <li>Once a script execution is over (which includes all the dependent script executions as well), newly created keys and any updated keys are merged with the <code>saved_env</code> provided the keys are mentioned in <code>new_env_keys</code></li> <li>Same behaviour applies to <code>state</code> dictionary.</li> </ul>"},{"location":"#special-env-keys","title":"Special env keys","text":"<ul> <li>Any env key with a prefix <code>CM_TMP_*</code> and <code>CM_GIT_*</code> are not passed by default to any dependency. These can be force passed by adding the key(s) to the <code>force_env_keys</code> list of the concerned dependency. </li> <li>Similarly we can avoid any env key from being passed to a given dependency by adding the prefix of the key in the <code>clean_env_keys</code> list of the concerned dependency.</li> <li><code>--input</code> is automatically converted to <code>CM_INPUT</code> env key</li> <li><code>version</code> is converted to <code>CM_VERSION</code>, <code>`version_min</code> to <code>CM_VERSION_MIN</code> and <code>version_max</code> to <code>CM_VERSION_MAX</code></li> <li>If <code>env['CM_GH_TOKEN']=TOKEN_VALUE</code> is set then git URLs (specified by <code>CM_GIT_URL</code>) are changed to add this token.</li> <li>If <code>env['CM_GIT_SSH']=yes</code>, then git URLs are changed to SSH from HTTPS.</li> </ul>"},{"location":"#script-meta","title":"Script Meta","text":""},{"location":"#special-keys-in-script-meta","title":"Special keys in script meta","text":"<ul> <li>TBD: <code>reuse_version</code>, <code>inherit_variation_tags</code>, <code>update_env_tags_from_env</code></li> </ul>"},{"location":"#how-cache-works","title":"How cache works?","text":"<ul> <li>If <code>cache=true</code> is set in a script meta, the result of the script execution is cached for further use. </li> <li>For a cached script, <code>env</code> and <code>state</code> updates are done using <code>new_env</code> and <code>new_state</code> dictionaries which are stored in the <code>cm-cached.json</code> file inside the cached folder.</li> <li>By using <code>--new</code> input, a new cache entry can be forced even when an old one exist. </li> <li>By default no depndencies are run for a cached entry unless <code>dynamic</code> key is set for it. </li> </ul> <p>Please see here for trying CM scripts.</p> <p>\u00a9 2022-24 MLCommons</p>"},{"location":"cm-yaml-guide/","title":"Cm yaml guide","text":"<p>This README provides a walkthrough of the <code>_cm.yaml</code> file.</p>"},{"location":"cm-yaml-guide/#keys-and-datatypes-followed","title":"Keys and Datatypes followed","text":"<ol> <li>alias: <code>string</code></li> <li>uid: <code>string</code></li> <li>automation_alias: <code>string</code></li> <li>automation_uid: <code>string</code></li> <li>category: <code>string</code></li> <li>developers: <code>list of strings</code></li> <li>tags: <code>list of strings</code></li> <li>default_env: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>env: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>input_mapping: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>env_key_mapping: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>new_env_keys: <code>list of strings</code></li> <li>new_state_keys: <code>list of strings</code></li> <li>deps: <code>list of dictionaries</code> - Each dictionary can contain <code>tags</code> or other nested keys</li> <li>names: <code>list of strings</code></li> <li>enable_if_env: <code>dictionary</code> - Contains key-value pairs where values are lists of <code>strings</code></li> <li>skip_if_env: <code>dictionary</code> - Contains key-value pairs where values are lists of <code>strings</code></li> <li>prehook_deps: <code>list of dictionaries</code> - Each dictionary may contain <code>names</code> and <code>tags</code> as lists</li> <li>posthook_deps: <code>list of dictionaries</code> - Each dictionary may contain <code>tags</code> and other keys</li> <li>variation_groups_order: <code>list of strings</code></li> <li>variations: <code>dictionary</code> - Each variation is a dictionary containing keys like <code>alias</code>, <code>default_variations</code>, <code>group</code>, etc.</li> <li>group: <code>string</code></li> <li>add_deps_recursive: <code>dictionary</code> - Contains nested <code>tags</code> and other keys</li> <li>default_variations: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>docker: <code>dictionary</code> - Contains keys specific to Docker configurations:<ul> <li>base_image: <code>string</code></li> <li>image_name: <code>string</code></li> <li>os: <code>string</code></li> <li>os_version: <code>string</code></li> <li>deps: <code>list of dictionaries</code> - Each dictionary can include <code>tags</code> or other keys.</li> <li>env: <code>dictionary</code> - Contains key-value pairs where values are <code>strings</code></li> <li>interactive: <code>boolean</code></li> <li>extra_run_args: <code>string</code></li> <li>mounts: <code>list of strings</code> - Specifies mount paths in the format <code>\"source:destination\"</code></li> <li>pre_run_cmds: <code>list of strings</code> - Commands to run before the container starts</li> <li>docker_input_mapping: <code>dictionary</code> - Contains key-value pairs where values are strings, mapping input parameters to Docker environment variables</li> <li>use_host_user_id: <code>boolean</code></li> <li>use_host_group_id: <code>boolean</code></li> <li>skip_run_cmd: <code>string</code></li> <li>shm_size: <code>string</code></li> <li>real_run: <code>boolean</code></li> <li>all_gpus: <code>string</code></li> </ul> </li> </ol>"},{"location":"getting-started/","title":"Getting Started with CM Script Automation","text":""},{"location":"getting-started/#running-cm-scripts","title":"Running CM Scripts","text":"<p>To execute a simple script in CM that captures OS details, use the following command:</p> <pre><code>cm run script --tags=detect,os -j\n</code></pre> <p>This command gathers details about the system on which it's run, such as:</p> <pre><code>{\n    \"CM_HOST_OS_TYPE\": \"linux\",\n    \"CM_HOST_OS_BITS\": \"64\",\n    \"CM_HOST_OS_FLAVOR\": \"ubuntu\",\n    \"CM_HOST_OS_FLAVOR_LIKE\": \"debian\",\n    \"CM_HOST_OS_VERSION\": \"24.04\",\n    \"CM_HOST_OS_KERNEL_VERSION\": \"6.8.0-45-generic\",\n    \"CM_HOST_OS_GLIBC_VERSION\": \"2.39\",\n    \"CM_HOST_OS_MACHINE\": \"x86_64\",\n    \"CM_HOST_OS_PACKAGE_MANAGER\": \"apt\",\n    \"CM_HOST_OS_PACKAGE_MANAGER_INSTALL_CMD\": \"DEBIAN_FRONTEND=noninteractive apt-get install -y\",\n    \"CM_HOST_OS_PACKAGE_MANAGER_UPDATE_CMD\": \"apt-get update -y\",\n    \"+CM_HOST_OS_DEFAULT_LIBRARY_PATH\": [\n      \"/usr/local/lib/x86_64-linux-gnu\",\n      \"/lib/x86_64-linux-gnu\",\n      \"/usr/lib/x86_64-linux-gnu\",\n      \"/usr/lib/x86_64-linux-gnu64\",\n      \"/usr/local/lib64\",\n      \"/lib64\",\n      \"/usr/lib64\",\n      \"/usr/local/lib\",\n      \"/lib\",\n      \"/usr/lib\",\n      \"/usr/x86_64-linux-gnu/lib64\",\n      \"/usr/x86_64-linux-gnu/lib\"\n    ],\n    \"CM_HOST_PLATFORM_FLAVOR\": \"x86_64\",\n    \"CM_HOST_PYTHON_BITS\": \"64\",\n    \"CM_HOST_SYSTEM_NAME\": \"intel-spr-i9\"\n}\n</code></pre> <p>For more details on CM scripts, see the CM documentation.</p>"},{"location":"getting-started/#adding-new-cm-scripts","title":"Adding New CM Scripts","text":"<p>CM aims to provide lightweight connectors between existing automation scripts and tools without substituting them. You can add your own scripts to CM with the following command, which creates a script named <code>hello-world</code>:</p> <pre><code>cm add script hello-world --tags=hello-world,display,test\n</code></pre> <p>This command initializes a CM script in the local repository with the following structure:</p> <pre><code>\u2514\u2500\u2500 CM\n    \u251c\u2500\u2500 index.json\n    \u251c\u2500\u2500 repos\n    \u2502   \u251c\u2500\u2500 local\n    \u2502   \u2502   \u251c\u2500\u2500 cfg\n    \u2502   \u2502   \u251c\u2500\u2500 cache\n    \u2502   \u2502   \u251c\u2500\u2500 cmr.yaml\n    \u2502   \u2502   \u2514\u2500\u2500 script\n    \u2502   \u2502       \u2514\u2500\u2500 hello-world\n    \u2502   \u2502           \u251c\u2500\u2500 _cm.yaml\n    \u2502   \u2502           \u251c\u2500\u2500 customize.py\n    \u2502   \u2502           \u251c\u2500\u2500 README-extra.md\n    \u2502   \u2502           \u251c\u2500\u2500 run.bat\n    \u2502   \u2502           \u2514\u2500\u2500 run.sh\n    \u2502   \u2514\u2500\u2500 mlcommons@cm4mlops\n    \u2514\u2500\u2500 repos.json\n</code></pre> <p>You can also execute the script from Python as follows:</p> <pre><code>import cmind\noutput = cmind.access({'action':'run', 'automation':'script', 'tags':'hello-world,display,test'})\nif output['return'] == 0:\n    print(output)\n</code></pre> <p>If you discover that your new script is similar to an existing script in any CM repository, you can clone an existing script using the following command:</p> <pre><code>cm copy script &lt;source_script&gt; .:&lt;target_script&gt;\n</code></pre> <p>Here, <code>&lt;source_script&gt;</code> is the name of the existing script, and <code>&lt;target_script&gt;</code> is the name of the new script you're creating. Existing script names in the <code>cm4mlops</code> repository can be found here.</p>"},{"location":"getting-started/#caching-and-reusing-cm-script-outputs","title":"Caching and Reusing CM Script Outputs","text":"<p>By default, CM scripts run in the current directory and record all new files there. For example, a universal download script might download an image to the current directory:</p> <pre><code>cm run script --tags=download,file,_wget --url=https://cKnowledge.org/ai/data/computer_mouse.jpg --verify=no --env.CM_DOWNLOAD_CHECKSUM=45ae5c940233892c2f860efdf0b66e7e\n</code></pre> <p>To cache and reuse the output of scripts, CM offers a <code>cache</code> automation feature similar to <code>script</code>. When <code>\"cache\":true</code> is specified in a script's metadata, CM will create a <code>cache</code> directory in <code>$HOME/CM/repos/local</code> with a unique ID and the same tags as <code>script</code>, and execute the script there.</p> <p>Subsequent executions of the same script will reuse files from the cache, avoiding redundancy. This is especially useful for large files or data sets.</p> <p>You can manage cache entries and find specific ones using commands like:</p> <pre><code>cm show cache\ncm show cache --tags=get,ml-model,resnet50,_onnx\ncm find cache --tags=download,file,ml-model,resnet50,_onnx\ncm info cache --tags=download,file,ml-model,resnet50,_onnx\n</code></pre> <p>To clean cache entries:</p> <pre><code>cm rm cache --tags=ml-model,resnet50\ncm rm cache -f  # Clean all entries\n</code></pre> <p>You can completely reset the CM framework by removing the <code>$HOME/CM</code> directory, which deletes all downloaded repositories and cached entries.</p>"},{"location":"getting-started/#integration-with-containers","title":"Integration with Containers","text":"<p>CM scripts are designed to run natively or inside containers with the same commands. You can substitute <code>cm run script</code> with <code>cm docker script</code> to execute a script inside an automatically-generated container:</p> <pre><code>cm docker script --tags=python,app,image-classification,onnx,_cpu\n</code></pre> <p>CM automatically handles the generation of Dockerfiles, building of containers, and execution within containers, providing a seamless experience whether running scripts natively or in containers. </p> <p>This approach simplifies the development process by eliminating the need for separate Dockerfile maintenance and allows for the use of native scripts and workflows directly within containers.</p>"},{"location":"scripts/","title":"Index","text":"<ul> <li>AI-ML-datasets</li> <li>AI-ML-frameworks</li> <li>AI-ML-models</li> <li>AI-ML-optimization</li> <li>Cloud-automation</li> <li>CM-automation</li> <li>CM-Interface</li> <li>CM-interface-prototyping</li> <li>Collective-benchmarking</li> <li>Compiler-automation</li> <li>CUDA-automation</li> <li>Dashboard-automation</li> <li>Detection-or-installation-of-tools-and-artifacts</li> <li>DevOps-automation</li> <li>Docker-automation</li> <li>GUI</li> <li>Legacy-CK-support</li> <li>MLPerf-benchmark-support</li> <li>Modular-AI-ML-application-pipeline</li> <li>Modular-application-pipeline</li> <li>Modular-MLPerf-benchmarks</li> <li>Modular-MLPerf-inference-benchmark-pipeline</li> <li>Modular-MLPerf-training-benchmark-pipeline</li> <li>Platform-information</li> <li>Python-automation</li> <li>Remote-automation</li> <li>Reproduce-MLPerf-benchmarks</li> <li>Reproducibility-and-artifact-evaluation</li> <li>Tests</li> <li>TinyML-automation</li> </ul>"},{"location":"scripts/AI-ML-datasets/","title":"AI-ML-datasets","text":"<ul> <li>get-croissant</li> <li>get-dataset-cifar10</li> <li>get-dataset-cnndm</li> <li>get-dataset-coco</li> <li>get-dataset-coco2014</li> <li>get-dataset-criteo</li> <li>get-dataset-imagenet-aux</li> <li>get-dataset-imagenet-calibration</li> <li>get-dataset-imagenet-helper</li> <li>get-dataset-imagenet-train</li> <li>get-dataset-imagenet-val</li> <li>get-dataset-kits19</li> <li>get-dataset-librispeech</li> <li>get-dataset-openimages</li> <li>get-dataset-openimages-annotations</li> <li>get-dataset-openimages-calibration</li> <li>get-dataset-openorca</li> <li>get-dataset-squad</li> <li>get-dataset-squad-vocab</li> <li>get-preprocessed-dataset-criteo</li> <li>get-preprocessed-dataset-imagenet</li> <li>get-preprocessed-dataset-kits19</li> <li>get-preprocessed-dataset-librispeech</li> <li>get-preprocessed-dataset-openimages</li> <li>get-preprocessed-dataset-openorca</li> <li>get-preprocessed-dataset-squad</li> <li>get-preprocessed-dataset-generic</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-croissant/","title":"get-croissant","text":"<p>Automatically generated README for this automation recipe: get-croissant</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-croissant/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-croissant/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-croissant/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-croissant/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlcommons croissant\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-croissant/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-datasets/get-croissant/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlcommons,croissant \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-croissant/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlcommons croissant \" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-croissant/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlcommons,croissant'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-croissant/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlcommons croissant\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-croissant/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-croissant/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlcommons croissant \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/","title":"get-dataset-cifar10","text":"<p>Automatically generated README for this automation recipe: get-dataset-cifar10</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset cifar10 image-classification validation training\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,cifar10,image-classification,validation,training[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset cifar10 image-classification validation training [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,cifar10,image-classification,validation,training'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset cifar10 image-classification validation training[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_tiny</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CONVERT_TO_TINYMLPERF: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"data_format\"      Click here to expand this section. <ul> <li><code>_python</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>CIFAR10</code></li> <li>CM_DATASET_FILENAME: <code>cifar-10-python.tar.gz</code></li> <li>CM_DATASET_FILENAME1: <code>cifar-10-python.tar</code></li> <li>CM_DATASET_CIFAR10: <code>https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#default-variations","title":"Default variations","text":"<p><code>_python</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cifar10/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset cifar10 image-classification validation training [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/","title":"get-dataset-cnndm","text":"<p>Automatically generated README for this automation recipe: get-dataset-cnndm</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset gpt-j cnndm cnn-dailymail original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,gpt-j,cnndm,cnn-dailymail,original[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset gpt-j cnndm cnn-dailymail original [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,gpt-j,cnndm,cnn-dailymail,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset gpt-j cnndm cnn-dailymail original[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_intel</code></li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#default-variations","title":"Default variations","text":"<p><code>_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-intel.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-cnndm/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset gpt-j cnndm cnn-dailymail original [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/","title":"get-dataset-coco","text":"<p>Automatically generated README for this automation recipe: get-dataset-coco</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset object-detection coco\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,object-detection,coco[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset object-detection coco [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,object-detection,coco'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset object-detection coco[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#variations","title":"Variations","text":"<ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_complete</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO_SIZE: <code>complete</code></li> </ul> </li> </ul> </li> <li><code>_small</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO_SIZE: <code>small</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"type\"      Click here to expand this section. <ul> <li><code>_train</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO_TYPE: <code>train</code></li> </ul> </li> </ul> </li> <li><code>_val</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO_TYPE: <code>val</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_2017</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO_VERSION: <code>2017</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#default-variations","title":"Default variations","text":"<p><code>_2017,_complete,_val</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--from=value</code>  \u2192  <code>CM_FROM=value</code></li> <li><code>--home=value</code>  \u2192  <code>CM_HOME_DIR=value</code></li> <li><code>--store=value</code>  \u2192  <code>CM_STORE=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_TO=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset object-detection coco [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/","title":"get-dataset-coco2014","text":"<p>Automatically generated README for this automation recipe: get-dataset-coco2014</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset coco2014 object-detection original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,coco2014,object-detection,original[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset coco2014 object-detection original [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,coco2014,object-detection,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset coco2014 object-detection original[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#variations","title":"Variations","text":"<ul> <li> <p>Group \"annotations\"      Click here to expand this section. <ul> <li><code>_custom-annotations</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO2014_CUSTOM_ANNOTATIONS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_default-annotations</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_COCO2014_CUSTOM_ANNOTATIONS: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: ``</li> </ul> </li> </ul> </li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#default-variations","title":"Default variations","text":"<p><code>_50,_default-annotations,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-coco2014/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset coco2014 object-detection original [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/","title":"get-dataset-criteo","text":"<p>Automatically generated README for this automation recipe: get-dataset-criteo</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset criteo original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,criteo,original[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset criteo original [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,criteo,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset criteo original[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_backup</code><ul> <li>ENV variables:<ul> <li>CM_BACKUP_ZIPS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_fake</code><ul> <li>ENV variables:<ul> <li>CM_CRITEO_FAKE: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--criteo_path=value</code>  \u2192  <code>CM_CRITEO_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BACKUP_ZIPS: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-criteo/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset criteo original [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/","title":"get-dataset-imagenet-aux","text":"<p>Automatically generated README for this automation recipe: get-dataset-imagenet-aux</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get aux dataset-aux image-classification imagenet-aux\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,aux,dataset-aux,image-classification,imagenet-aux[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get aux dataset-aux image-classification imagenet-aux [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,aux,dataset-aux,image-classification,imagenet-aux'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get aux dataset-aux image-classification imagenet-aux[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_2012</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_AUX_VER: <code>2012</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-source\"      Click here to expand this section. <ul> <li><code>_from.berkeleyvision</code><ul> <li>ENV variables:<ul> <li>CM_WGET_URL: <code>http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz</code></li> </ul> </li> </ul> </li> <li><code>_from.dropbox</code> (default)<ul> <li>ENV variables:<ul> <li>CM_WGET_URL: <code>https://www.dropbox.com/s/92n2fyej3lzy3s3/caffe_ilsvrc12.tar.gz</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#default-variations","title":"Default variations","text":"<p><code>_from.dropbox</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-aux/#script-output","title":"Script output","text":"<pre><code>cmr \"get aux dataset-aux image-classification imagenet-aux [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/","title":"get-dataset-imagenet-calibration","text":"<p>Automatically generated README for this automation recipe: get-dataset-imagenet-calibration</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset imagenet calibration\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,imagenet,calibration[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset imagenet calibration [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,imagenet,calibration'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset imagenet calibration[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#variations","title":"Variations","text":"<ul> <li> <p>Group \"calibration-option\"      Click here to expand this section. <ul> <li><code>_mlperf.option1</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_IMAGENET_CALIBRATION_OPTION: <code>one</code></li> <li>CM_DOWNLOAD_CHECKSUM: <code>f09719174af3553119e2c621157773a6</code></li> </ul> </li> </ul> </li> <li><code>_mlperf.option2</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_IMAGENET_CALIBRATION_OPTION: <code>two</code></li> <li>CM_DOWNLOAD_CHECKSUM: <code>e44582af00e3b4fc3fac30efd6bdd05f</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#default-variations","title":"Default variations","text":"<p><code>_mlperf.option1</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-calibration/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset imagenet calibration [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/","title":"get-dataset-imagenet-helper","text":"<p>Automatically generated README for this automation recipe: get-dataset-imagenet-helper</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get imagenet helper imagenet-helper\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,imagenet,helper,imagenet-helper \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get imagenet helper imagenet-helper \" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,imagenet,helper,imagenet-helper'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get imagenet helper imagenet-helper\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-helper/#script-output","title":"Script output","text":"<pre><code>cmr \"get imagenet helper imagenet-helper \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/","title":"get-dataset-imagenet-train","text":"<p>Automatically generated README for this automation recipe: get-dataset-imagenet-train</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get imagenet train dataset original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,imagenet,train,dataset,original [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get imagenet train dataset original \" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,imagenet,train,dataset,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get imagenet train dataset original\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>IMAGENET_TRAIN_PATH=value</code></li> <li><code>--torrent=value</code>  \u2192  <code>CM_DATASET_IMAGENET_TRAIN_TORRENT_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-train/#script-output","title":"Script output","text":"<pre><code>cmr \"get imagenet train dataset original \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/","title":"get-dataset-imagenet-val","text":"<p>Automatically generated README for this automation recipe: get-dataset-imagenet-val</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get val validation dataset imagenet ILSVRC image-classification original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,val,validation,dataset,imagenet,ILSVRC,image-classification,original[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get val validation dataset imagenet ILSVRC image-classification original [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,val,validation,dataset,imagenet,ILSVRC,image-classification,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get val validation dataset imagenet ILSVRC image-classification original[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_2012-500</code></li> <li><code>_2012-full</code></li> <li><code>_run-during-docker-build</code></li> </ul> <li> <p>Group \"count\"      Click here to expand this section. <ul> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50000</code></li> <li>CM_IMAGENET_FULL: <code>yes</code></li> <li>CM_DAE_FILENAME: <code>ILSVRC2012_img_val.tar</code></li> <li>CM_DAE_DOWNLOADED_CHECKSUM: <code>29b22e2961454d5413ddabcf34fc5622</code></li> </ul> </li> </ul> </li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_size.500</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> <li>CM_DAE_FILENAME: <code>ILSVRC2012_img_val_500.tar</code></li> <li>CM_DAE_URL: <code>http://cKnowledge.org/ai/data/ILSVRC2012_img_val_500.tar</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-version\"      Click here to expand this section. <ul> <li><code>_2012</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_VER: <code>2012</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#default-variations","title":"Default variations","text":"<p><code>_2012,_size.500</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--imagenet_path=value</code>  \u2192  <code>IMAGENET_PATH=value</code></li> <li><code>--torrent=value</code>  \u2192  <code>CM_DATASET_IMAGENET_VAL_TORRENT_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <p>No run file exists for Linux/macOS</p> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-imagenet-val/#script-output","title":"Script output","text":"<pre><code>cmr \"get val validation dataset imagenet ILSVRC image-classification original [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/","title":"get-dataset-kits19","text":"<p>Automatically generated README for this automation recipe: get-dataset-kits19</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset medical-imaging kits original kits19\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,medical-imaging,kits,original,kits19[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset medical-imaging kits original kits19 [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,medical-imaging,kits,original,kits19'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset medical-imaging kits original kits19[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_default</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: ``</li> </ul> </li> </ul> </li> <li><code>_no-recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> </ul> </li> </ul> </li> <li><code>_patch</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_short-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 5</code></li> </ul> </li> </ul> </li> <li><code>_validation</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_VALIDATION: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>master</code></li> <li>CM_GIT_DEPTH: <code>--depth 2</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> <li>CM_GIT_URL: <code>https://github.com/neheller/kits19</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>custom</code></li> <li><code>master</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-kits19/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset medical-imaging kits original kits19 [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/","title":"get-dataset-librispeech","text":"<p>Automatically generated README for this automation recipe: get-dataset-librispeech</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset speech speech-recognition librispeech validation audio training original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,speech,speech-recognition,librispeech,validation,audio,training,original \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset speech speech-recognition librispeech validation audio training original \" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,speech,speech-recognition,librispeech,validation,audio,training,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset speech speech-recognition librispeech validation audio training original\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#versions","title":"Versions","text":"<p>Default version: <code>dev-clean</code></p> <ul> <li><code>dev-clean</code></li> <li><code>dev-other</code></li> <li><code>test-clean</code></li> <li><code>test-other</code></li> <li><code>train-clean-100</code></li> <li><code>train-clean-360</code></li> <li><code>train-other-500</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-librispeech/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset speech speech-recognition librispeech validation audio training original \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/","title":"get-dataset-openimages","text":"<p>Automatically generated README for this automation recipe: get-dataset-openimages</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset openimages open-images object-detection original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,openimages,open-images,object-detection,original[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset openimages open-images object-detection original [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,openimages,open-images,object-detection,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset openimages open-images object-detection original[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_filter</code></li> <li><code>_filter-size.#</code></li> <li><code>_using-fiftyone</code></li> </ul> <li> <p>Group \"annotations\"      Click here to expand this section. <ul> <li><code>_custom-annotations</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_OPENIMAGES_CUSTOM_ANNOTATIONS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_default-annotations</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_OPENIMAGES_CUSTOM_ANNOTATIONS: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: ``</li> </ul> </li> </ul> </li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#default-variations","title":"Default variations","text":"<p><code>_50,_default-annotations,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset openimages open-images object-detection original [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/","title":"get-dataset-openimages-annotations","text":"<p>Automatically generated README for this automation recipe: get-dataset-openimages-annotations</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get aux dataset-aux object-detection openimages annotations\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,aux,dataset-aux,object-detection,openimages,annotations[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get aux dataset-aux object-detection openimages annotations [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,aux,dataset-aux,object-detection,openimages,annotations'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get aux dataset-aux object-detection openimages annotations[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#variations","title":"Variations","text":"<ul> <li> <p>Group \"download-source\"      Click here to expand this section. <ul> <li><code>_from.github</code> (default)<ul> <li>ENV variables:<ul> <li>CM_WGET_URL: <code>https://github.com/mlcommons/inference/releases/download/v2.1/openimages-mlperf_annotations_2.1.json.zip</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#default-variations","title":"Default variations","text":"<p><code>_from.github</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-annotations/#script-output","title":"Script output","text":"<pre><code>cmr \"get aux dataset-aux object-detection openimages annotations [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/","title":"get-dataset-openimages-calibration","text":"<p>Automatically generated README for this automation recipe: get-dataset-openimages-calibration</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset openimages calibration\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,openimages,calibration[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset openimages calibration [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,openimages,calibration'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset openimages calibration[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_filter</code><ul> <li>ENV variables:<ul> <li>CM_CALIBRATE_FILTER: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"calibration-option\"      Click here to expand this section. <ul> <li><code>_mlperf.option1</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_OPENIMAGES_CALIBRATION_OPTION: <code>one</code></li> <li>CM_DOWNLOAD_CHECKSUM1: <code>f09719174af3553119e2c621157773a6</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"filter-size\"      Click here to expand this section. <ul> <li><code>_filter-size.#</code><ul> <li>ENV variables:<ul> <li>CM_CALIBRATION_FILTER_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_filter-size.400</code><ul> <li>ENV variables:<ul> <li>CM_CALIBRATION_FILTER_SIZE: <code>400</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#default-variations","title":"Default variations","text":"<p><code>_mlperf.option1</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-filter.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openimages-calibration/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset openimages calibration [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/","title":"get-dataset-openorca","text":"<p>Automatically generated README for this automation recipe: get-dataset-openorca</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset openorca language-processing original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,openorca,language-processing,original[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset openorca language-processing original [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,openorca,language-processing,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset openorca language-processing original[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#variations","title":"Variations","text":"<ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_60</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>60</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>24576</code></li> </ul> </li> </ul> </li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#default-variations","title":"Default variations","text":"<p><code>_60,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-openorca/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset openorca language-processing original [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/","title":"get-dataset-squad","text":"<p>Automatically generated README for this automation recipe: get-dataset-squad</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset squad language-processing validation original\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,squad,language-processing,validation,original \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset squad language-processing validation original \" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,squad,language-processing,validation,original'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset squad language-processing validation original\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#versions","title":"Versions","text":"<p>Default version: <code>1.1</code></p> <ul> <li><code>1.1</code></li> <li><code>2.0</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset squad language-processing validation original \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/","title":"get-dataset-squad-vocab","text":"<p>Automatically generated README for this automation recipe: get-dataset-squad-vocab</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get aux dataset-aux language-processing squad-aux vocab squad-vocab\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,aux,dataset-aux,language-processing,squad-aux,vocab,squad-vocab[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get aux dataset-aux language-processing squad-aux vocab squad-vocab [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,aux,dataset-aux,language-processing,squad-aux,vocab,squad-vocab'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get aux dataset-aux language-processing squad-aux vocab squad-vocab[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#variations","title":"Variations","text":"<ul> <li> <p>Group \"download-source\"      Click here to expand this section. <ul> <li><code>_from.zenodo</code> (default)<ul> <li>ENV variables:<ul> <li>CM_WGET_URL: <code>https://zenodo.org/record/3733868/files/vocab.txt</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#default-variations","title":"Default variations","text":"<p><code>_from.zenodo</code></p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-dataset-squad-vocab/#script-output","title":"Script output","text":"<pre><code>cmr \"get aux dataset-aux language-processing squad-aux vocab squad-vocab [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/","title":"get-preprocessed-dataset-criteo","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-criteo</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset criteo recommendation dlrm preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,criteo,recommendation,dlrm,preprocessed[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset criteo recommendation dlrm preprocessed [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,criteo,recommendation,dlrm,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset criteo recommendation dlrm preprocessed[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_50</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_fake</code><ul> <li>ENV variables:<ul> <li>CM_CRITEO_FAKE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_full</code></li> <li><code>_validation</code></li> </ul> <li> <p>Group \"type\"      Click here to expand this section. <ul> <li><code>_multihot</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CRITEO_MULTIHOT: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#default-variations","title":"Default variations","text":"<p><code>_multihot</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_PATH=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_OUTPUT_PATH=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_PREPROCESS_THREADS=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-multihot.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-criteo/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset criteo recommendation dlrm preprocessed [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/","title":"get-preprocesser-script-generic","text":"<p>Automatically generated README for this automation recipe: get-preprocesser-script-generic</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get preprocessor generic image-preprocessor script\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,preprocessor,generic,image-preprocessor,script \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get preprocessor generic image-preprocessor script \" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,preprocessor,generic,image-preprocessor,script'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get preprocessor generic image-preprocessor script\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-generic/#script-output","title":"Script output","text":"<pre><code>cmr \"get preprocessor generic image-preprocessor script \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/","title":"get-preprocessed-dataset-imagenet","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-imagenet</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset imagenet ILSVRC image-classification preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,imagenet,ILSVRC,image-classification,preprocessed[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset imagenet ILSVRC image-classification preprocessed [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,imagenet,ILSVRC,image-classification,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset imagenet ILSVRC image-classification preprocessed[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_default</code></li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_PREPROCESS_PYTORCH: <code>yes</code></li> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_tflite_tpu</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> <li>CM_PREPROCESS_TFLITE_TPU: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"calibration-option\"      Click here to expand this section. <ul> <li><code>_mlperf.option1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION_OPTION: <code>one</code></li> </ul> </li> </ul> </li> <li><code>_mlperf.option2</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION_OPTION: <code>two</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_TYPE: <code>calibration</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_TYPE: <code>validation</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"extension\"      Click here to expand this section. <ul> <li><code>_rgb32</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>rgb32</code></li> </ul> </li> </ul> </li> <li><code>_rgb8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>rgb8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"interpolation-method\"      Click here to expand this section. <ul> <li><code>_inter.area</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_INTERPOLATION_METHOD: <code>INTER_AREA</code></li> </ul> </li> </ul> </li> <li><code>_inter.linear</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_INTERPOLATION_METHOD: <code>INTER_LINEAR</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"layout\"      Click here to expand this section. <ul> <li><code>_NCHW</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_LAYOUT: <code>NCHW</code></li> </ul> </li> </ul> </li> <li><code>_NHWC</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_LAYOUT: <code>NHWC</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_for.mobilenet</code></li> <li><code>_for.resnet50</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SUBTRACT_MEANS: <code>1</code></li> <li>CM_DATASET_GIVEN_CHANNEL_MEANS: <code>123.68 116.78 103.94</code></li> <li>CM_DATASET_NORMALIZE_DATA: <code>0</code></li> <li>CM_DATASET_INTERPOLATION_METHOD: <code>INTER_AREA</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_float32</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_TYPE: <code>float32</code></li> <li>CM_DATASET_QUANTIZE: <code>0</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_TYPE: <code>int8</code></li> <li>CM_DATASET_QUANTIZE: <code>1</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_TYPE: <code>uint8</code></li> <li>CM_DATASET_DATA_TYPE_INPUT: <code>float32</code></li> <li>CM_DATASET_QUANTIZE: <code>1</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"preprocessing-source\"      Click here to expand this section. <ul> <li><code>_generic-preprocessor</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_REFERENCE_PREPROCESSOR: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_mlcommons-reference-preprocessor</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_REFERENCE_PREPROCESSOR: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"resolution\"      Click here to expand this section. <ul> <li><code>_resolution.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_INPUT_SQUARE_SIDE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_resolution.224</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_INPUT_SQUARE_SIDE: <code>224</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50000</code></li> </ul> </li> </ul> </li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#default-variations","title":"Default variations","text":"<p><code>_NCHW,_mlcommons-reference-preprocessor,_resolution.224,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_PATH=value</code></li> <li><code>--imagenet_path=value</code>  \u2192  <code>CM_IMAGENET_PATH=value</code></li> <li><code>--imagenet_preprocessed_path=value</code>  \u2192  <code>CM_IMAGENET_PREPROCESSED_PATH=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_PREPROCESS_THREADS=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CROP_FACTOR: <code>87.5</code></li> <li>CM_DATASET_DATA_TYPE: <code>float32</code></li> <li>CM_DATASET_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_DATASET_QUANT_SCALE: <code>1</code></li> <li>CM_DATASET_QUANTIZE: <code>0</code></li> <li>CM_DATASET_QUANT_OFFSET: <code>0</code></li> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>npy</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>0</code></li> <li>CM_DATASET_REFERENCE_PREPROCESSOR: <code>1</code></li> <li>CM_PREPROCESS_VGG: <code>yes</code></li> <li>CM_MODEL: <code>resnet50</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-imagenet/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset imagenet ILSVRC image-classification preprocessed [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/","title":"get-preprocessed-dataset-kits19","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-kits19</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset medical-imaging kits19 preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,medical-imaging,kits19,preprocessed[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset medical-imaging kits19 preprocessed [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,medical-imaging,kits19,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset medical-imaging kits19 preprocessed[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_nvidia</code><ul> <li>ENV variables:<ul> <li>CM_PREPROCESSING_BY_NVIDIA: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-count\"      Click here to expand this section. <ul> <li><code>_1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_5</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>5</code></li> </ul> </li> </ul> </li> <li><code>_50</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: ``</li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>int8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PATH: <code>&lt;&lt;&lt;CM_CALIBRATION_DATASET_PATH&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#default-variations","title":"Default variations","text":"<p><code>_fp32,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_PATH=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_PREPROCESS_THREADS=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET: <code>kits19</code></li> <li>CM_DATASET_DTYPE: <code>fp32</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-kits19/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset medical-imaging kits19 preprocessed [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/","title":"get-preprocessed-dataset-librispeech","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-librispeech</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset speech-recognition librispeech preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,speech-recognition,librispeech,preprocessed[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset speech-recognition librispeech preprocessed [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,speech-recognition,librispeech,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset speech-recognition librispeech preprocessed[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#variations","title":"Variations","text":"<ul> <li> <p>Group \"dataset-count\"      Click here to expand this section. <ul> <li><code>_1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_5</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>5</code></li> </ul> </li> </ul> </li> <li><code>_50</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: ``</li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>int8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PATH: <code>&lt;&lt;&lt;CM_CALIBRATION_DATASET_PATH&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#default-variations","title":"Default variations","text":"<p><code>_fp32,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_PATH=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_PREPROCESS_THREADS=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET: <code>kits19</code></li> <li>CM_DATASET_DTYPE: <code>fp32</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-librispeech/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset speech-recognition librispeech preprocessed [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/","title":"get-preprocessed-dataset-openimages","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-openimages</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset openimages open-images object-detection preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,openimages,open-images,object-detection,preprocessed[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset openimages open-images object-detection preprocessed [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,openimages,open-images,object-detection,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset openimages open-images object-detection preprocessed[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_filter</code></li> <li><code>_for.retinanet.onnx</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_NAME: <code>retinanet</code></li> <li>CM_DATASET_SUBTRACT_MEANS: <code>1</code></li> <li>CM_DATASET_GIVEN_CHANNEL_MEANS: <code>0.485 0.456 0.406</code></li> <li>CM_DATASET_GIVEN_CHANNEL_STDS: <code>0.229 0.224 0.225</code></li> <li>CM_DATASET_NORMALIZE_DATA: <code>0</code></li> <li>CM_DATASET_NORMALIZE_LOWER: <code>0.0</code></li> <li>CM_DATASET_NORMALIZE_UPPER: <code>1.0</code></li> <li>CM_DATASET_CONVERT_TO_BGR: <code>0</code></li> <li>CM_DATASET_CROP_FACTOR: <code>100.0</code></li> </ul> </li> </ul> </li> <li><code>_nvidia</code><ul> <li>ENV variables:<ul> <li>CM_PREPROCESSING_BY_NVIDIA: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_quant-offset.#</code></li> <li><code>_quant-scale.#</code></li> </ul> <li> <p>Group \"annotations\"      Click here to expand this section. <ul> <li><code>_custom-annotations</code></li> <li><code>_default-annotations</code> (default)</li> </ul> <li> <p>Group \"dataset-count\"      Click here to expand this section. <ul> <li><code>_50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_500</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>500</code></li> </ul> </li> </ul> </li> <li><code>_full</code></li> <li><code>_size.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-layout\"      Click here to expand this section. <ul> <li><code>_NCHW</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_LAYOUT: <code>NCHW</code></li> </ul> </li> </ul> </li> <li><code>_NHWC</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DATA_LAYOUT: <code>NHWC</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>fp32</code></li> <li>CM_DATASET_INPUT_DTYPE: <code>fp32</code></li> <li>CM_DATASET_QUANTIZE: <code>0</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>int8</code></li> <li>CM_DATASET_INPUT_DTYPE: <code>fp32</code></li> <li>CM_DATASET_QUANTIZE: <code>1</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DTYPE: <code>uint8</code></li> <li>CM_DATASET_INPUT_DTYPE: <code>fp32</code></li> <li>CM_DATASET_QUANTIZE: <code>1</code></li> <li>CM_DATASET_CONVERT_TO_UNSIGNED: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PATH: <code>&lt;&lt;&lt;CM_CALIBRATION_DATASET_PATH&gt;&gt;&gt;</code></li> <li>CM_DATASET_ANNOTATIONS_FILE_PATH: <code>&lt;&lt;&lt;CM_DATASET_CALIBRATION_ANNOTATIONS_FILE_PATH&gt;&gt;&gt;</code></li> <li>CM_DATASET_TYPE: <code>calibration</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_TYPE: <code>validation</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"extension\"      Click here to expand this section. <ul> <li><code>_npy</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>npy</code></li> </ul> </li> </ul> </li> <li><code>_raw</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>raw</code></li> </ul> </li> </ul> </li> <li><code>_rgb32</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>rgb32</code></li> </ul> </li> </ul> </li> <li><code>_rgb8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_PREPROCESSED_EXTENSION: <code>rgb8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"filter-size\"      Click here to expand this section. <ul> <li><code>_filter-size.#</code></li> </ul> <li> <p>Group \"interpolation-method\"      Click here to expand this section. <ul> <li><code>_inter.area</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_INTERPOLATION_METHOD: <code>INTER_AREA</code></li> </ul> </li> </ul> </li> <li><code>_inter.linear</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_INTERPOLATION_METHOD: <code>INTER_LINEAR</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"preprocessing-source\"      Click here to expand this section. <ul> <li><code>_generic-preprocessor</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_REFERENCE_PREPROCESSOR: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_mlcommons-reference-preprocessor</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_REFERENCE_PREPROCESSOR: <code>1</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#default-variations","title":"Default variations","text":"<p><code>_50,_NCHW,_default-annotations,_fp32,_mlcommons-reference-preprocessor,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DATASET_PREPROCESSED_PATH=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_PREPROCESS_THREADS=value</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET: <code>OPENIMAGES</code></li> <li>CM_DATASET_DTYPE: <code>fp32</code></li> <li>CM_DATASET_INPUT_SQUARE_SIDE: <code>800</code></li> <li>CM_DATASET_CROP_FACTOR: <code>100.0</code></li> <li>CM_DATASET_QUANT_SCALE: <code>1</code></li> <li>CM_DATASET_QUANTIZE: <code>0</code></li> <li>CM_DATASET_QUANT_OFFSET: <code>0</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openimages/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset openimages open-images object-detection preprocessed [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/","title":"get-preprocessed-dataset-openorca","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-openorca</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset openorca language-processing preprocessed\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,openorca,language-processing,preprocessed[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset openorca language-processing preprocessed [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,openorca,language-processing,preprocessed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset openorca language-processing preprocessed[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#variations","title":"Variations","text":"<ul> <li> <p>Group \"dataset-type\"      Click here to expand this section. <ul> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_validation</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"size\"      Click here to expand this section. <ul> <li><code>_60</code> (default)</li> <li><code>_full</code></li> <li><code>_size.#</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#default-variations","title":"Default variations","text":"<p><code>_60,_validation</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_CALIBRATION: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-openorca/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset openorca language-processing preprocessed [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/","title":"get-preprocessed-dataset-squad","text":"<p>Automatically generated README for this automation recipe: get-preprocessed-dataset-squad</p> <p>Category: AI/ML datasets</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get dataset preprocessed tokenized squad\" --help</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,dataset,preprocessed,tokenized,squad[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get dataset preprocessed tokenized squad [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,dataset,preprocessed,tokenized,squad'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get dataset preprocessed tokenized squad[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#variations","title":"Variations","text":"<ul> <li> <p>Group \"calibration-set\"      Click here to expand this section. <ul> <li><code>_calib1</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_CALIBRATION_SET: <code>one</code></li> </ul> </li> </ul> </li> <li><code>_calib2</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_CALIBRATION_SET: <code>two</code></li> </ul> </li> </ul> </li> <li><code>_no-calib</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_CALIBRATION_SET: ``</li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"doc-stride\"      Click here to expand this section. <ul> <li><code>_doc-stride.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_DOC_STRIDE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_doc-stride.128</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_DOC_STRIDE: <code>128</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"packing\"      Click here to expand this section. <ul> <li><code>_packed</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_PACKED: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"raw\"      Click here to expand this section. <ul> <li><code>_pickle</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_RAW: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_raw</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_RAW: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"seq-length\"      Click here to expand this section. <ul> <li><code>_seq-length.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_MAX_SEQ_LENGTH: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_seq-length.384</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET_MAX_SEQ_LENGTH: <code>384</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#default-variations","title":"Default variations","text":"<p><code>_doc-stride.128,_no-calib,_raw,_seq-length.384</code></p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-packed.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-datasets/get-preprocessed-dataset-squad/#script-output","title":"Script output","text":"<pre><code>cmr \"get dataset preprocessed tokenized squad [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/","title":"AI-ML-frameworks","text":"<ul> <li>get-google-saxml</li> <li>get-onnxruntime-prebuilt</li> <li>get-qaic-apps-sdk</li> <li>get-qaic-platform-sdk</li> <li>get-qaic-software-kit</li> <li>get-rocm</li> <li>get-tvm</li> <li>install-qaic-compute-sdk-from-src</li> <li>install-rocm</li> <li>install-tensorflow-for-c</li> <li>install-tensorflow-from-src</li> <li>install-tflite-from-src</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/","title":"get-google-saxml","text":"<p>Automatically generated README for this automation recipe: get-google-saxml</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get google saxml\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,google,saxml \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get google saxml \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,google,saxml'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get google saxml\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-google-saxml/#script-output","title":"Script output","text":"<pre><code>cmr \"get google saxml \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/","title":"get-onnxruntime-prebuilt","text":"<p>Automatically generated README for this automation recipe: get-onnxruntime-prebuilt</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install onnxruntime get prebuilt lib lang-c lang-cpp\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,onnxruntime,get,prebuilt,lib,lang-c,lang-cpp[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install onnxruntime get prebuilt lib lang-c lang-cpp [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,onnxruntime,get,prebuilt,lib,lang-c,lang-cpp'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install onnxruntime get prebuilt lib lang-c lang-cpp[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#variations","title":"Variations","text":"<ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ONNXRUNTIME_DEVICE: ``</li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_ONNXRUNTIME_DEVICE: <code>gpu</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#default-variations","title":"Default variations","text":"<p><code>_cpu</code></p>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#versions","title":"Versions","text":"<p>Default version: <code>1.16.3</code></p>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-onnxruntime-prebuilt/#script-output","title":"Script output","text":"<pre><code>cmr \"install onnxruntime get prebuilt lib lang-c lang-cpp [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/","title":"get-qaic-apps-sdk","text":"<p>Automatically generated README for this automation recipe: get-qaic-apps-sdk</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get detect qaic apps sdk apps-sdk qaic-apps-sdk\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,detect,qaic,apps,sdk,apps-sdk,qaic-apps-sdk \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get detect qaic apps sdk apps-sdk qaic-apps-sdk \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,detect,qaic,apps,sdk,apps-sdk,qaic-apps-sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get detect qaic apps sdk apps-sdk qaic-apps-sdk\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-apps-sdk/#script-output","title":"Script output","text":"<pre><code>cmr \"get detect qaic apps sdk apps-sdk qaic-apps-sdk \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/","title":"get-qaic-platform-sdk","text":"<p>Automatically generated README for this automation recipe: get-qaic-platform-sdk</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get detect qaic platform sdk platform-sdk qaic-platform-sdk\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,detect,qaic,platform,sdk,platform-sdk,qaic-platform-sdk \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get detect qaic platform sdk platform-sdk qaic-platform-sdk \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,detect,qaic,platform,sdk,platform-sdk,qaic-platform-sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get detect qaic platform sdk platform-sdk qaic-platform-sdk\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-platform-sdk/#script-output","title":"Script output","text":"<pre><code>cmr \"get detect qaic platform sdk platform-sdk qaic-platform-sdk \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/","title":"get-qaic-software-kit","text":"<p>Automatically generated README for this automation recipe: get-qaic-software-kit</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get qaic software kit qaic-software-kit\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,qaic,software,kit,qaic-software-kit[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get qaic software kit qaic-software-kit [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,qaic,software,kit,qaic-software-kit'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get qaic software kit qaic-software-kit[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo-source\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.quic</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/quic/software-kit-for-qualcomm-cloud-ai-100</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#default-variations","title":"Default variations","text":"<p><code>_repo.quic</code></p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/get-qaic-software-kit/#script-output","title":"Script output","text":"<pre><code>cmr \"get qaic software kit qaic-software-kit [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-rocm/","title":"get-rocm","text":"<p>Automatically generated README for this automation recipe: get-rocm</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-rocm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get rocm get-rocm\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/get-rocm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,rocm,get-rocm \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get rocm get-rocm \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,rocm,get-rocm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get rocm get-rocm\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/get-rocm/#script-output","title":"Script output","text":"<pre><code>cmr \"get rocm get-rocm \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-tvm/","title":"get-tvm","text":"<p>Automatically generated README for this automation recipe: get-tvm</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/get-tvm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get tvm get-tvm\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-frameworks/get-tvm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,tvm,get-tvm[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get tvm get-tvm [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,tvm,get-tvm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get tvm get-tvm[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_TVM_USE_CUDA: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_openmp</code><ul> <li>ENV variables:<ul> <li>CM_TVM_USE_OPENMP: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"installation-type\"      Click here to expand this section. <ul> <li><code>_llvm</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TVM_USE_LLVM: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_pip-install</code><ul> <li>ENV variables:<ul> <li>CM_TVM_PIP_INSTALL: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#default-variations","title":"Default variations","text":"<p><code>_llvm</code></p>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>main</code></li> <li>CM_GIT_URL: <code>https://github.com/apache/tvm</code></li> <li>CM_TVM_PIP_INSTALL: <code>no</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#versions","title":"Versions","text":"<ul> <li><code>main</code></li> <li><code>v0.10.0</code></li> <li><code>v0.7.0</code></li> <li><code>v0.8.0</code></li> <li><code>v0.9.0</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/get-tvm/#script-output","title":"Script output","text":"<pre><code>cmr \"get tvm get-tvm [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/","title":"install-qaic-compute-sdk-from-src","text":"<p>Automatically generated README for this automation recipe: install-qaic-compute-sdk-from-src</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get qaic from.src software compute compute-sdk qaic-compute-sdk sdk\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,qaic,from.src,software,compute,compute-sdk,qaic-compute-sdk,sdk[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get qaic from.src software compute compute-sdk qaic-compute-sdk sdk [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,qaic,from.src,software,compute,compute-sdk,qaic-compute-sdk,sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get qaic from.src software compute compute-sdk qaic-compute-sdk sdk[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"installation-mode\"      Click here to expand this section. <ul> <li><code>_debug</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_COMPUTE_SDK_INSTALL_MODE: <code>debug</code></li> </ul> </li> </ul> </li> <li><code>_release</code> (default)<ul> <li>ENV variables:<ul> <li>CM_QAIC_COMPUTE_SDK_INSTALL_MODE: <code>release</code></li> </ul> </li> </ul> </li> <li><code>_release-assert</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_COMPUTE_SDK_INSTALL_MODE: <code>release-assert</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo-source\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.quic</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/quic/software-kit-for-qualcomm-cloud-ai-100-cc</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#default-variations","title":"Default variations","text":"<p><code>_release,_repo.quic</code></p>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/install-qaic-compute-sdk-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get qaic from.src software compute compute-sdk qaic-compute-sdk sdk [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-rocm/","title":"install-rocm","text":"<p>Automatically generated README for this automation recipe: install-rocm</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/install-rocm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install rocm install-rocm\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/install-rocm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,rocm,install-rocm \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install rocm install-rocm \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,rocm,install-rocm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install rocm install-rocm\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#versions","title":"Versions","text":"<p>Default version: <code>5.7.1</code></p>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-rhel.sh</li> <li>run-ubuntu.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/install-rocm/#script-output","title":"Script output","text":"<pre><code>cmr \"install rocm install-rocm \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/","title":"install-tensorflow-for-c","text":"<p>Automatically generated README for this automation recipe: install-tensorflow-for-c</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install tensorflow lib lang-c\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,tensorflow,lib,lang-c \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install tensorflow lib lang-c \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,tensorflow,lib,lang-c'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install tensorflow lib lang-c\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#versions","title":"Versions","text":"<p>Default version: <code>2.8.0</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-for-c/#script-output","title":"Script output","text":"<pre><code>cmr \"install tensorflow lib lang-c \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/","title":"install-tensorflow-from-src","text":"<p>Automatically generated README for this automation recipe: install-tensorflow-from-src</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get install tensorflow lib source from-source from-src src from.src\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,install,tensorflow,lib,source,from-source,from-src,src,from.src[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get install tensorflow lib source from-source from-src src from.src [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,install,tensorflow,lib,source,from-source,from-src,src,from.src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get install tensorflow lib source from-source from-src src from.src[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_TFLITE: <code>on</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_URL: <code>https://github.com/tensorflow/tensorflow</code></li> <li>CM_GIT_DEPTH: <code>1</code></li> <li>CM_TFLITE: <code>off</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>master</code></li> <li><code>v1.15.0</code></li> <li><code>v2.0.0</code></li> <li><code>v2.1.0</code></li> <li><code>v2.10.0</code></li> <li><code>v2.11.0</code></li> <li><code>v2.12.0</code></li> <li><code>v2.13.0</code></li> <li><code>v2.14.0</code></li> <li><code>v2.15.0</code></li> <li><code>v2.16.1</code></li> <li><code>v2.2.0</code></li> <li><code>v2.3.0</code></li> <li><code>v2.4.0</code></li> <li><code>v2.5.0</code></li> <li><code>v2.6.0</code></li> <li><code>v2.7.0</code></li> <li><code>v2.8.0</code></li> <li><code>v2.9.0</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/install-tensorflow-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get install tensorflow lib source from-source from-src src from.src [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/","title":"install-tflite-from-src","text":"<p>Automatically generated README for this automation recipe: install-tflite-from-src</p> <p>Category: AI/ML frameworks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get install tflite-cmake tensorflow-lite-cmake from-src\" --help</code></p>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,install,tflite-cmake,tensorflow-lite-cmake,from-src \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get install tflite-cmake tensorflow-lite-cmake from-src \" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,install,tflite-cmake,tensorflow-lite-cmake,from-src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get install tflite-cmake tensorflow-lite-cmake from-src\" \n</code></pre>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_DEPTH: <code>1</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>master</code></li> </ul>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-frameworks/install-tflite-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get install tflite-cmake tensorflow-lite-cmake from-src \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/","title":"AI-ML-models","text":"<ul> <li>convert-ml-model-huggingface-to-onnx</li> <li>get-bert-squad-vocab</li> <li>get-dlrm</li> <li>get-ml-model-3d-unet-kits19</li> <li>get-ml-model-bert-base-squad</li> <li>get-ml-model-bert-large-squad</li> <li>get-ml-model-dlrm-terabyte</li> <li>get-ml-model-efficientnet-lite</li> <li>get-ml-model-gptj</li> <li>get-ml-model-huggingface-zoo</li> <li>get-ml-model-llama2</li> <li>get-ml-model-mobilenet</li> <li>get-ml-model-neuralmagic-zoo</li> <li>get-ml-model-resnet50</li> <li>get-ml-model-retinanet</li> <li>get-ml-model-retinanet-nvidia</li> <li>get-ml-model-rnnt</li> <li>get-ml-model-stable-diffusion</li> <li>get-ml-model-tiny-resnet</li> <li>get-ml-model-using-imagenet-from-model-zoo</li> <li>get-tvm-model</li> </ul>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/","title":"convert-ml-model-huggingface-to-onnx","text":"<p>Automatically generated README for this automation recipe: convert-ml-model-huggingface-to-onnx</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"ml-model model huggingface-to-onnx onnx huggingface convert\" --help</code></p>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=ml-model,model,huggingface-to-onnx,onnx,huggingface,convert[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"ml-model model huggingface-to-onnx onnx huggingface convert [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'ml-model,model,huggingface-to-onnx,onnx,huggingface,convert'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"ml-model model huggingface-to-onnx onnx huggingface convert[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_model-path.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_HUGG_PATH: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/convert-ml-model-huggingface-to-onnx/#script-output","title":"Script output","text":"<pre><code>cmr \"ml-model model huggingface-to-onnx onnx huggingface convert [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/","title":"get-bert-squad-vocab","text":"<p>Automatically generated README for this automation recipe: get-bert-squad-vocab</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get bert squad bert-large bert-squad vocab\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,bert,squad,bert-large,bert-squad,vocab \n</code></pre>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get bert squad bert-large bert-squad vocab \" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,bert,squad,bert-large,bert-squad,vocab'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get bert squad bert-large bert-squad vocab\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-bert-squad-vocab/#script-output","title":"Script output","text":"<pre><code>cmr \"get bert squad bert-large bert-squad vocab \"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-dlrm/","title":"get-dlrm","text":"<p>Automatically generated README for this automation recipe: get-dlrm</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-dlrm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-dlrm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-dlrm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-dlrm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src dlrm\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-dlrm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-models/get-dlrm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,dlrm[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-dlrm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src dlrm [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-dlrm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,dlrm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-dlrm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src dlrm[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-dlrm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: ``</li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-dlrm/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_DEPTH: <code>--depth 10</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_URL: <code>https://github.com/facebookresearch/dlrm.git</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-dlrm/#versions","title":"Versions","text":"<p>Default version: <code>main</code></p> <ul> <li><code>main</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-dlrm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-dlrm/#script-output","title":"Script output","text":"<pre><code>cmr \"get src dlrm [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/","title":"get-ml-model-3d-unet-kits19","text":"<p>Automatically generated README for this automation recipe: get-ml-model-3d-unet-kits19</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model raw 3d-unet kits19 medical-imaging\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,raw,3d-unet,kits19,medical-imaging[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model raw 3d-unet kits19 medical-imaging [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,raw,3d-unet,kits19,medical-imaging'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model raw 3d-unet kits19 medical-imaging[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_weights</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_WEIGHTS_FILE: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnx</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>Aliases: <code>_tensorflow</code></li> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>tensorflow</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#default-variations","title":"Default variations","text":"<p><code>_fp32,_onnx</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-3d-unet-kits19/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model raw 3d-unet kits19 medical-imaging [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/","title":"get-ml-model-bert-base-squad","text":"<p>Automatically generated README for this automation recipe: get-ml-model-bert-base-squad</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model raw bert bert-base bert-squad language language-processing\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,raw,bert,bert-base,bert-squad,language,language-processing[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model raw bert bert-base bert-squad language language-processing [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,raw,bert,bert-base,bert-squad,language,language-processing'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model raw bert bert-base bert-squad language language-processing[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#variations","title":"Variations","text":"<ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>deepsparse</code></li> <li>CM_ML_MODEL_INPUT_IDS_NAME: <code>input_ids</code></li> <li>CM_ML_MODEL_INPUT_MASK_NAME: <code>input_mask</code></li> <li>CM_ML_MODEL_INPUT_SEGMENTS_NAME: <code>segment_ids</code></li> <li>CM_ML_MODEL_OUTPUT_END_LOGITS_NAME: <code>output_end_logits</code></li> <li>CM_ML_MODEL_OUTPUT_START_LOGITS_NAME: <code>output_start_logits</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_QUANTIZED: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#default-variations","title":"Default variations","text":"<p><code>_fp32</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-base-squad/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model raw bert bert-base bert-squad language language-processing [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/","title":"get-ml-model-bert-large-squad","text":"<p>Automatically generated README for this automation recipe: get-ml-model-bert-large-squad</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model raw bert bert-large bert-squad language language-processing\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,raw,bert,bert-large,bert-squad,language,language-processing[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model raw bert bert-large bert-squad language language-processing [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,raw,bert,bert-large,bert-squad,language,language-processing'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model raw bert bert-large bert-squad language language-processing[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_onnxruntime</code></li> <li><code>_tensorflow</code></li> </ul> <li> <p>Group \"download-source\"      Click here to expand this section. <ul> <li><code>_amazon-s3</code></li> <li><code>_armi</code></li> <li><code>_custom-url.#</code><ul> <li>ENV variables:<ul> <li>CM_PACKAGE_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_github</code></li> <li><code>_zenodo</code></li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>deepsparse</code></li> <li>CM_ML_MODEL_INPUT_IDS_NAME: <code>input_ids</code></li> <li>CM_ML_MODEL_INPUT_MASK_NAME: <code>input_mask</code></li> <li>CM_ML_MODEL_INPUT_SEGMENTS_NAME: <code>segment_ids</code></li> <li>CM_ML_MODEL_OUTPUT_END_LOGITS_NAME: <code>output_end_logits</code></li> <li>CM_ML_MODEL_OUTPUT_START_LOGITS_NAME: <code>output_start_logits</code></li> </ul> </li> </ul> </li> <li><code>_onnx</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> <li>CM_ML_MODEL_INPUT_IDS_NAME: <code>input_ids</code></li> <li>CM_ML_MODEL_INPUT_MASK_NAME: <code>input_mask</code></li> <li>CM_ML_MODEL_INPUT_SEGMENTS_NAME: <code>segment_ids</code></li> <li>CM_ML_MODEL_OUTPUT_END_LOGITS_NAME: <code>output_end_logits</code></li> <li>CM_ML_MODEL_OUTPUT_START_LOGITS_NAME: <code>output_start_logits</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> <li>CM_ML_MODEL_INPUT_IDS_NAME: <code>input_ids</code></li> <li>CM_ML_MODEL_INPUT_MASK_NAME: <code>input_mask</code></li> <li>CM_ML_MODEL_INPUT_SEGMENTS_NAME: <code>segment_ids</code></li> <li>CM_ML_MODEL_OUTPUT_END_LOGITS_NAME: <code>output_end_logits</code></li> <li>CM_ML_MODEL_OUTPUT_START_LOGITS_NAME: <code>output_start_logits</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>tf</code></li> <li>CM_ML_MODEL_INPUT_IDS_NAME: <code>input_ids</code></li> <li>CM_ML_MODEL_INPUT_MASK_NAME: <code>input_mask</code></li> <li>CM_ML_MODEL_INPUT_SEGMENTS_NAME: <code>segment_ids</code></li> <li>CM_ML_MODEL_OUTPUT_END_LOGITS_NAME: <code>output_end_logits</code></li> <li>CM_ML_MODEL_OUTPUT_START_LOGITS_NAME: <code>output_start_logits</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"packing\"      Click here to expand this section. <ul> <li><code>_packed</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BERT_PACKED: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_unpacked</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BERT_PACKED: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_QUANTIZED: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#default-variations","title":"Default variations","text":"<p><code>_fp32,_onnx,_unpacked</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-packed.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-bert-large-squad/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model raw bert bert-large bert-squad language language-processing [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/","title":"get-ml-model-dlrm-terabyte","text":"<p>Automatically generated README for this automation recipe: get-ml-model-dlrm-terabyte</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model dlrm raw terabyte criteo-terabyte criteo recommendation\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,dlrm,raw,terabyte,criteo-terabyte,criteo,recommendation[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model dlrm raw terabyte criteo-terabyte criteo recommendation [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,dlrm,raw,terabyte,criteo-terabyte,criteo,recommendation'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model dlrm raw terabyte criteo-terabyte criteo recommendation[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_debug</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DEBUG: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-tool\"      Click here to expand this section. <ul> <li><code>_rclone</code></li> <li><code>_wget</code></li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnx</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> <li>CM_TMP_MODEL_ADDITIONAL_NAME: <code>dlrm_terabyte.pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"type\"      Click here to expand this section. <ul> <li><code>_weight_sharded</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DLRM_MULTIHOT_MODEL: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#default-variations","title":"Default variations","text":"<p><code>_fp32,_pytorch,_weight_sharded</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--dir=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-dlrm-terabyte/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model dlrm raw terabyte criteo-terabyte criteo recommendation [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/","title":"get-ml-model-efficientnet-lite","text":"<p>Automatically generated README for this automation recipe: get-ml-model-efficientnet-lite</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model efficientnet raw ml-model-efficientnet ml-model-efficientnet-lite lite tflite image-classification\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,efficientnet,raw,ml-model-efficientnet,ml-model-efficientnet-lite,lite,tflite,image-classification[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model efficientnet raw ml-model-efficientnet ml-model-efficientnet-lite lite tflite image-classification [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,efficientnet,raw,ml-model-efficientnet,ml-model-efficientnet-lite,lite,tflite,image-classification'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model efficientnet raw ml-model-efficientnet ml-model-efficientnet-lite lite tflite image-classification[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_tflite</code></li> </ul> <li> <p>Group \"kind\"      Click here to expand this section. <ul> <li><code>_lite0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_KIND: <code>lite0</code></li> </ul> </li> </ul> </li> <li><code>_lite1</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_KIND: <code>lite1</code></li> </ul> </li> </ul> </li> <li><code>_lite2</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_KIND: <code>lite2</code></li> </ul> </li> </ul> </li> <li><code>_lite3</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_KIND: <code>lite3</code></li> </ul> </li> </ul> </li> <li><code>_lite4</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_KIND: <code>lite4</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>Aliases: <code>_int8</code></li> <li>ENV variables:<ul> <li>CM_ML_MODEL_EFFICIENTNET_LITE_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>uint8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"resolution\"      Click here to expand this section. <ul> <li><code>_resolution-224</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>224</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>224</code></li> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>224</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.224</code></li> </ul> </li> </ul> </li> <li><code>_resolution-240</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>240</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>240</code></li> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>240</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.240</code></li> </ul> </li> </ul> </li> <li><code>_resolution-260</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>260</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>260</code></li> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>260</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.260</code></li> </ul> </li> </ul> </li> <li><code>_resolution-280</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>280</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>280</code></li> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>280</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.280</code></li> </ul> </li> </ul> </li> <li><code>_resolution-300</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>300</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>300</code></li> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>300</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.300</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#default-variations","title":"Default variations","text":"<p><code>_fp32,_lite0,_resolution-224</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-efficientnet-lite/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model efficientnet raw ml-model-efficientnet ml-model-efficientnet-lite lite tflite image-classification [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/","title":"get-ml-model-gptj","text":"<p>Automatically generated README for this automation recipe: get-ml-model-gptj</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get raw ml-model gptj gpt-j large-language-model\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,raw,ml-model,gptj,gpt-j,large-language-model[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get raw ml-model gptj gpt-j large-language-model [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,raw,ml-model,gptj,gpt-j,large-language-model'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get raw ml-model gptj gpt-j large-language-model[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-tool\"      Click here to expand this section. <ul> <li><code>_rclone</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_FILENAME: <code>checkpoint</code></li> <li>CM_DOWNLOAD_URL: <code>&lt;&lt;&lt;CM_RCLONE_URL&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_wget</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_URL: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> <li>CM_DOWNLOAD_FILENAME: <code>checkpoint.zip</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> <li>CM_ML_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_saxml</code></li> </ul> <li> <p>Group \"model-provider\"      Click here to expand this section. <ul> <li><code>_intel</code></li> <li><code>_mlcommons</code> (default)</li> <li><code>_nvidia</code><ul> <li>ENV variables:<ul> <li>CM_TMP_ML_MODEL_PROVIDER: <code>nvidia</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_fp8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp8</code></li> </ul> </li> </ul> </li> <li><code>_int4</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int4</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int4</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#default-variations","title":"Default variations","text":"<p><code>_mlcommons,_pytorch,_rclone</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--checkpoint=value</code>  \u2192  <code>GPTJ_CHECKPOINT_PATH=value</code></li> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-int4-calibration.sh</li> <li>run-intel.sh</li> <li>run-nvidia.sh</li> <li>run-saxml-quantized.sh</li> <li>run-saxml.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-gptj/#script-output","title":"Script output","text":"<pre><code>cmr \"get raw ml-model gptj gpt-j large-language-model [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/","title":"get-ml-model-huggingface-zoo","text":"<p>Automatically generated README for this automation recipe: get-ml-model-huggingface-zoo</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model huggingface zoo\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,huggingface,zoo[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model huggingface zoo [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,huggingface,zoo'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model huggingface zoo[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_model-stub.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_onnx-subfolder</code><ul> <li>ENV variables:<ul> <li>CM_HF_SUBFOLDER: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_pierreguillou_bert_base_cased_squad_v1.1_portuguese</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>pierreguillou/bert-base-cased-squad-v1.1-portuguese</code></li> </ul> </li> </ul> </li> <li><code>_prune</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_TASK: <code>prune</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-type\"      Click here to expand this section. <ul> <li><code>_clone-repo</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CLONE_REPO: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--env_key=value</code>  \u2192  <code>CM_MODEL_ZOO_ENV_KEY=value</code></li> <li><code>--full_subfolder=value</code>  \u2192  <code>CM_HF_FULL_SUBFOLDER=value</code></li> <li><code>--model_filename=value</code>  \u2192  <code>CM_MODEL_ZOO_FILENAME=value</code></li> <li><code>--revision=value</code>  \u2192  <code>CM_HF_REVISION=value</code></li> <li><code>--subfolder=value</code>  \u2192  <code>CM_HF_SUBFOLDER=value</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-huggingface-zoo/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model huggingface zoo [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/","title":"get-ml-model-llama2","text":"<p>Automatically generated README for this automation recipe: get-ml-model-llama2</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get raw ml-model language-processing llama2 llama2-70b text-summarization\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,raw,ml-model,language-processing,llama2,llama2-70b,text-summarization[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get raw ml-model language-processing llama2 llama2-70b text-summarization [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,raw,ml-model,language-processing,llama2,llama2-70b,text-summarization'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get raw ml-model language-processing llama2 llama2-70b text-summarization[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"huggingface-stub\"      Click here to expand this section. <ul> <li><code>_meta-llama/Llama-2-70b-chat-hf</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_FOLDER: <code>Llama-2-70b-chat-hf</code></li> <li>CM_MODEL_ZOO_ENV_KEY: <code>LLAMA2</code></li> </ul> </li> </ul> </li> <li><code>_meta-llama/Llama-2-7b-chat-hf</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_FOLDER: <code>Llama-2-7b-chat-hf</code></li> <li>CM_MODEL_ZOO_ENV_KEY: <code>LLAMA2</code></li> </ul> </li> </ul> </li> <li><code>_stub.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_ENV_KEY: <code>LLAMA2</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#default-variations","title":"Default variations","text":"<p><code>_fp32,_meta-llama/Llama-2-70b-chat-hf,_pytorch</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--checkpoint=value</code>  \u2192  <code>LLAMA2_CHECKPOINT_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-llama2/#script-output","title":"Script output","text":"<pre><code>cmr \"get raw ml-model language-processing llama2 llama2-70b text-summarization [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/","title":"get-ml-model-mobilenet","text":"<p>Automatically generated README for this automation recipe: get-ml-model-mobilenet</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model mobilenet raw ml-model-mobilenet image-classification\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,mobilenet,raw,ml-model-mobilenet,image-classification[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model mobilenet raw ml-model-mobilenet image-classification [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,mobilenet,raw,ml-model-mobilenet,image-classification'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model mobilenet raw ml-model-mobilenet image-classification[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_tflite</code></li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnx</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_tf</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NHWC</code></li> <li>CM_ML_MODEL_NORMALIZE_DATA: <code>yes</code></li> <li>CM_ML_MODEL_SUBTRACT_MEANS: <code>no</code></li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: <code>input</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"kind\"      Click here to expand this section. <ul> <li><code>_large</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_KIND: <code>large</code></li> </ul> </li> </ul> </li> <li><code>_large-minimalistic</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_KIND: <code>large-minimalistic</code></li> </ul> </li> </ul> </li> <li><code>_small</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_KIND: <code>small</code></li> </ul> </li> </ul> </li> <li><code>_small-minimalistic</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_KIND: <code>small-minimalistic</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"multiplier\"      Click here to expand this section. <ul> <li><code>_multiplier-0.25</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER: <code>0.25</code></li> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER_PERCENTAGE: <code>25</code></li> </ul> </li> </ul> </li> <li><code>_multiplier-0.35</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER: <code>0.35</code></li> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER_PERCENTAGE: <code>35</code></li> </ul> </li> </ul> </li> <li><code>_multiplier-0.5</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER: <code>0.5</code></li> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER_PERCENTAGE: <code>50</code></li> </ul> </li> </ul> </li> <li><code>_multiplier-0.75</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER: <code>0.75</code></li> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER_PERCENTAGE: <code>75</code></li> </ul> </li> </ul> </li> <li><code>_multiplier-1.0</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER: <code>1.0</code></li> <li>CM_ML_MODEL_MOBILENET_MULTIPLIER_PERCENTAGE: <code>100</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"opset-version\"      Click here to expand this section. <ul> <li><code>_opset-11</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ONNX_OPSET: <code>11</code></li> </ul> </li> </ul> </li> <li><code>_opset-8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ONNX_OPSET: <code>8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_MOBILENET_PRECISION: <code>float</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_MOBILENET_PRECISION: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>uint8</code></li> <li>CM_ML_MODEL_MOBILENET_PRECISION: <code>uint8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"resolution\"      Click here to expand this section. <ul> <li><code>_resolution-128</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>128</code></li> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>128</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>128</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.128</code></li> </ul> </li> </ul> </li> <li><code>_resolution-160</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>160</code></li> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>160</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>160</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.160</code></li> </ul> </li> </ul> </li> <li><code>_resolution-192</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>192</code></li> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>192</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>192</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.192</code></li> </ul> </li> </ul> </li> <li><code>_resolution-224</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_RESOLUTION: <code>224</code></li> <li>CM_ML_MODEL_IMAGE_HEIGHT: <code>224</code></li> <li>CM_ML_MODEL_IMAGE_WIDTH: <code>224</code></li> <li>CM_DATASET_PREPROCESSED_IMAGENET_DEP_TAGS: <code>_resolution.224</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"source\"      Click here to expand this section. <ul> <li><code>_from.google</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_SOURCE: <code>google</code></li> </ul> </li> </ul> </li> <li><code>_from.zenodo</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_SOURCE: <code>zenodo</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_v1</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_VERSION: <code>1</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilenet-v1-precision_&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_PRECISION&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_MULTIPLIER&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_RESOLUTION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_v2</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_VERSION: <code>2</code></li> <li>CM_ML_MODEL_VER: <code>2</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilenet-v2-precision_&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_PRECISION&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_MULTIPLIER&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_RESOLUTION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_v3</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MOBILENET_VERSION: <code>3</code></li> <li>CM_ML_MODEL_VER: <code>3</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilenet-v3-precision_&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_PRECISION&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_KIND&gt;&gt;&gt;-&lt;&lt;&lt;CM_ML_MODEL_MOBILENET_RESOLUTION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#default-variations","title":"Default variations","text":"<p><code>_fp32,_tf,_v3</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ML_MODEL: <code>mobilenet</code></li> <li>CM_ML_MODEL_DATASET: <code>imagenet2012-val</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>no</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_MOBILENET_NAME_SUFFIX: ``</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-mobilenet/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model mobilenet raw ml-model-mobilenet image-classification [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/","title":"get-ml-model-neuralmagic-zoo","text":"<p>Automatically generated README for this automation recipe: get-ml-model-neuralmagic-zoo</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model model zoo deepsparse model-zoo sparse-zoo neuralmagic neural-magic\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,model,zoo,deepsparse,model-zoo,sparse-zoo,neuralmagic,neural-magic[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model model zoo deepsparse model-zoo sparse-zoo neuralmagic neural-magic [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,model,zoo,deepsparse,model-zoo,sparse-zoo,neuralmagic,neural-magic'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model model zoo deepsparse model-zoo sparse-zoo neuralmagic neural-magic[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_bert-base-pruned90-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/pruned90-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/pruned90-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>bert-base-pruned90-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-base-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_bert-base-pruned95_obs_quant-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/pruned95_obs_quant-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/bert-base/pytorch/huggingface/squad/pruned95_obs_quant-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>bert-base-pruned95_obs_quant-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-base-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_bert-base_cased-pruned90-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/bert-base_cased/pytorch/huggingface/squad/pruned90-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/bert-base_cased/pytorch/huggingface/squad/pruned90-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>bert-base_cased-pruned90-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-base-cased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_bert-large-base-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/bert-large/pytorch/huggingface/squad/base-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/bert-large/pytorch/huggingface/squad/base-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>bert-large-base-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_bert-large-pruned80_quant-none-vnni</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/bert-large/pytorch/huggingface/squad/pruned80_quant-none-vnni</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/bert-large/pytorch/huggingface/squad/pruned80_quant-none-vnni</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>bert-large-pruned80_quant-none-vnni-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_mobilebert-14layer_pruned50-none-vnni</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/14layer_pruned50-none-vnni</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/14layer_pruned50-none-vnni</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilebert-14layer_pruned50-none-vnni-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://storage.googleapis.com/cloud-tpu-checkpoints/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT.tar.gz</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_mobilebert-14layer_pruned50_quant-none-vnni</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/14layer_pruned50_quant-none-vnni</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/14layer_pruned50_quant-none-vnni</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilebert-14layer_pruned50_quant-none-vnni-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://storage.googleapis.com/cloud-tpu-checkpoints/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT.tar.gz</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_mobilebert-base_quant-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/base_quant-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/base_quant-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilebert-base_quant-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://storage.googleapis.com/cloud-tpu-checkpoints/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT.tar.gz</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_mobilebert-none-base-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/base-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/mobilebert-none/pytorch/huggingface/squad/base-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>mobilebert-none-base-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://storage.googleapis.com/cloud-tpu-checkpoints/mobilebert/uncased_L-24_H-128_B-512_A-4_F-4_OPT.tar.gz</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_model-stub.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_obert-base-pruned90-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-base/pytorch/huggingface/squad/pruned90-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-base/pytorch/huggingface/squad/pruned90-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-base-pruned90-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_obert-large-base-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/base-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/base-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-large-base-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_obert-large-pruned95-none-vnni</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned95-none-vnni</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned95-none-vnni</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-large-pruned95-none-vnni-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_obert-large-pruned95_quant-none-vnni</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned95_quant-none-vnni</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned95_quant-none-vnni</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-large-pruned95_quant-none-vnni-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_obert-large-pruned97-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned97-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned97-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-large-pruned97-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_obert-large-pruned97-quant-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned97_quant-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/obert-large/pytorch/huggingface/squad/pruned97_quant-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>obert-large-pruned97-quant-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/bert-large-uncased</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_oberta-base-pruned90-quant-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/oberta-base/pytorch/huggingface/squad/pruned90_quant-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/oberta-base/pytorch/huggingface/squad/pruned90_quant-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>oberta-base-pruned90-quant-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/roberta-base</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_roberta-base-pruned85-quant-none</code><ul> <li>Aliases: <code>_model-stub.zoo:nlp/question_answering/roberta-base/pytorch/huggingface/squad/pruned85_quant-none</code></li> <li>ENV variables:<ul> <li>CM_MODEL_ZOO_STUB: <code>zoo:nlp/question_answering/roberta-base/pytorch/huggingface/squad/pruned85_quant-none</code></li> <li>CM_ML_MODEL_FULL_NAME: <code>roberta-base-pruned85-quant-none-bert-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://huggingface.co/roberta-base</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, unstructured pruning</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int64</code></li> <li>CM_ML_MODEL_RETRAINING: <code>no</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-neuralmagic-zoo/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model model zoo deepsparse model-zoo sparse-zoo neuralmagic neural-magic [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/","title":"get-ml-model-resnet50","text":"<p>Automatically generated README for this automation recipe: get-ml-model-resnet50</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get raw ml-model resnet50 ml-model-resnet50 image-classification\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,raw,ml-model,resnet50,ml-model-resnet50,image-classification[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get raw ml-model resnet50 ml-model-resnet50 image-classification [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,raw,ml-model,resnet50,ml-model-resnet50,image-classification'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get raw ml-model resnet50 ml-model-resnet50 image-classification[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_batch_size.1</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_fix-input-shape</code></li> <li><code>_from-tf</code></li> <li><code>_huggingface_default</code><ul> <li>ENV variables:<ul> <li>CM_PACKAGE_URL: <code>https://huggingface.co/ctuning/mlperf-inference-resnet50-onnx-fp32-imagenet2012-v1.0/resolve/main/resnet50_v1.onnx</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_ncnn</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>ncnn</code></li> </ul> </li> </ul> </li> <li><code>_onnx</code> (default)<ul> <li>Aliases: <code>_onnxruntime</code></li> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> <li>CM_ML_MODEL_INPUT_LAYERS: <code>input_tensor:0</code></li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: <code>input_tensor:0</code></li> <li>CM_ML_MODEL_INPUT_SHAPES: <code>\\\"input_tensor:0\\\": (BATCH_SIZE, 3, 224, 224)</code></li> <li>CM_ML_MODEL_OUTPUT_LAYERS: <code>softmax_tensor:0</code></li> <li>CM_ML_MODEL_OUTPUT_LAYER_NAME: <code>softmax_tensor:0</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> <li>CM_ML_MODEL_VER: <code>1.5</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> <li>CM_ML_MODEL_GIVEN_CHANNEL_MEANS: <code>?</code></li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: <code>input_tensor:0</code></li> <li>CM_ML_MODEL_INPUT_SHAPES: <code>\\\"input_tensor:0\\\": [BATCH_SIZE, 3, 224, 224]</code></li> <li>CM_ML_MODEL_OUTPUT_LAYERS: <code>output</code></li> <li>CM_ML_MODEL_OUTPUT_LAYER_NAME: <code>?</code></li> <li>CM_ML_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tensorflow</code><ul> <li>Aliases: <code>_tf</code></li> <li>ENV variables:<ul> <li>CM_ML_MODEL_ACCURACY: <code>76.456</code></li> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NHWC</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>tensorflow</code></li> <li>CM_ML_MODEL_GIVEN_CHANNEL_MEANS: <code>123.68 116.78 103.94</code></li> <li>CM_ML_MODEL_INPUT_LAYERS: <code>input_tensor</code></li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: <code>input_tensor</code></li> <li>CM_ML_MODEL_INPUT_SHAPES: <code>\\\"input_tensor:0\\\": (BATCH_SIZE, 3, 224, 224)</code></li> <li>CM_ML_MODEL_NORMALIZE_DATA: <code>0</code></li> <li>CM_ML_MODEL_OUTPUT_LAYERS: <code>softmax_tensor</code></li> <li>CM_ML_MODEL_OUTPUT_LAYER_NAME: <code>softmax_tensor</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> <li>CM_ML_MODEL_SUBTRACT_MEANS: <code>YES</code></li> <li>CM_PACKAGE_URL: <code>https://zenodo.org/record/2535873/files/resnet50_v1.pb</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ACCURACY: <code>76.456</code></li> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NHWC</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>tflite</code></li> <li>CM_ML_MODEL_GIVEN_CHANNEL_MEANS: <code>123.68 116.78 103.94</code></li> <li>CM_ML_MODEL_INPUT_LAYERS: <code>input_tensor</code></li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: <code>input_tensor</code></li> <li>CM_ML_MODEL_INPUT_SHAPES: <code>\\\"input_tensor 2\\\": (BATCH_SIZE, 224, 224, 3)</code></li> <li>CM_ML_MODEL_NORMALIZE_DATA: <code>0</code></li> <li>CM_ML_MODEL_OUTPUT_LAYERS: <code>softmax_tensor</code></li> <li>CM_ML_MODEL_OUTPUT_LAYER_NAME: <code>softmax_tensor</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> <li>CM_ML_MODEL_SUBTRACT_MEANS: <code>YES</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model-output\"      Click here to expand this section. <ul> <li><code>_argmax</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_OUTPUT_LAYER_ARGMAX: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_no-argmax</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_OUTPUT_LAYER_ARGMAX: <code>no</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"opset-version\"      Click here to expand this section. <ul> <li><code>_opset-11</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ONNX_OPSET: <code>11</code></li> </ul> </li> </ul> </li> <li><code>_opset-8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ONNX_OPSET: <code>8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#default-variations","title":"Default variations","text":"<p><code>_argmax,_fp32,_onnx</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-fix-input.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-resnet50/#script-output","title":"Script output","text":"<pre><code>cmr \"get raw ml-model resnet50 ml-model-resnet50 image-classification [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/","title":"get-ml-model-retinanet","text":"<p>Automatically generated README for this automation recipe: get-ml-model-retinanet</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model raw resnext50 retinanet object-detection\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,raw,resnext50,retinanet,object-detection[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model raw resnext50 retinanet object-detection [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,raw,resnext50,retinanet,object-detection'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model raw resnext50 retinanet object-detection[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_no-nms</code><ul> <li>ENV variables:<ul> <li>CM_TMP_ML_MODEL_RETINANET_NO_NMS: <code>yes</code></li> <li>CM_ML_MODEL_RETINANET_NO_NMS: <code>yes</code></li> <li>CM_QAIC_PRINT_NODE_PRECISION_INFO: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_weights</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_WEIGHTS_FILE: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnx</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NCHW</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#default-variations","title":"Default variations","text":"<p><code>_fp32,_onnx</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-no-nms.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model raw resnext50 retinanet object-detection [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/","title":"get-ml-model-retinanet-nvidia","text":"<p>Automatically generated README for this automation recipe: get-ml-model-retinanet-nvidia</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model nvidia-retinanet nvidia\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,nvidia-retinanet,nvidia[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model nvidia-retinanet nvidia [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,nvidia-retinanet,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model nvidia-retinanet nvidia[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_efficient-nms</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_EFFICIENT_NMS: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_TORCH_DEVICE: <code>cpu</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-retinanet-nvidia/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model nvidia-retinanet nvidia [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/","title":"get-ml-model-rnnt","text":"<p>Automatically generated README for this automation recipe: get-ml-model-rnnt</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model rnnt raw librispeech speech-recognition\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,rnnt,raw,librispeech,speech-recognition[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model rnnt raw librispeech speech-recognition [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,rnnt,raw,librispeech,speech-recognition'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model rnnt raw librispeech speech-recognition[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_weights</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_WEIGHTS_FILE: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-src\"      Click here to expand this section. <ul> <li><code>_amazon-s3</code></li> <li><code>_zenodo</code> (default)</li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#default-variations","title":"Default variations","text":"<p><code>_fp32,_pytorch,_zenodo</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-rnnt/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model rnnt raw librispeech speech-recognition [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/","title":"get-ml-model-stable-diffusion","text":"<p>Automatically generated README for this automation recipe: get-ml-model-stable-diffusion</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get raw ml-model stable-diffusion sdxl text-to-image\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,raw,ml-model,stable-diffusion,sdxl,text-to-image[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get raw ml-model stable-diffusion sdxl text-to-image [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,raw,ml-model,stable-diffusion,sdxl,text-to-image'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get raw ml-model stable-diffusion sdxl text-to-image[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-source\"      Click here to expand this section. <ul> <li><code>_huggingface</code></li> <li><code>_mlcommons</code> (default)</li> </ul> <li> <p>Group \"download-tool\"      Click here to expand this section. <ul> <li><code>_git</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>git</code></li> </ul> </li> </ul> </li> <li><code>_rclone</code><ul> <li>ENV variables:<ul> <li>CM_RCLONE_CONFIG_CMD: <code>rclone config create mlc-inference s3 provider=Cloudflare access_key_id=f65ba5eef400db161ea49967de89f47b secret_access_key=fbea333914c292b854f14d3fe232bad6c5407bf0ab1bebf78833c2b359bdfd2b endpoint=https://c2686074cb2caf5cbaf6d134bdba8b47.r2.cloudflarestorage.com</code></li> <li>CM_DOWNLOAD_TOOL: <code>rclone</code></li> </ul> </li> </ul> </li> <li><code>_wget</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>wget</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp16</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp16</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp16</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#default-variations","title":"Default variations","text":"<p><code>_fp32,_mlcommons,_pytorch</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--checkpoint=value</code>  \u2192  <code>SDXL_CHECKPOINT_PATH=value</code></li> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-stable-diffusion/#script-output","title":"Script output","text":"<pre><code>cmr \"get raw ml-model stable-diffusion sdxl text-to-image [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/","title":"get-ml-model-tiny-resnet","text":"<p>Automatically generated README for this automation recipe: get-ml-model-tiny-resnet</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get raw ml-model resnet pretrained tiny model ic ml-model-tiny-resnet image-classification\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,raw,ml-model,resnet,pretrained,tiny,model,ic,ml-model-tiny-resnet,image-classification[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get raw ml-model resnet pretrained tiny model ic ml-model-tiny-resnet image-classification [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,raw,ml-model,resnet,pretrained,tiny,model,ic,ml-model-tiny-resnet,image-classification'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get raw ml-model resnet pretrained tiny model ic ml-model-tiny-resnet image-classification[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnx</code><ul> <li>ENV variables:<ul> <li>CM_TMP_ML_MODEL_TF2ONNX: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_ACCURACY: <code>85</code></li> <li>CM_ML_MODEL_DATA_LAYOUT: <code>NHWC</code></li> <li>CM_ML_MODEL_FRAMEWORK: <code>tflite</code></li> <li>CM_ML_MODEL_GIVEN_CHANNEL_MEANS: ``</li> <li>CM_ML_MODEL_INPUT_LAYERS: ``</li> <li>CM_ML_MODEL_INPUT_LAYER_NAME: ``</li> <li>CM_ML_MODEL_INPUT_SHAPES: ``</li> <li>CM_ML_MODEL_NORMALIZE_DATA: <code>0</code></li> <li>CM_ML_MODEL_OUTPUT_LAYERS: ``</li> <li>CM_ML_MODEL_OUTPUT_LAYER_NAME: ``</li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>&lt;&lt;&lt;CM_PACKAGE_URL&gt;&gt;&gt;</code></li> <li>CM_ML_MODEL_SUBTRACT_MEANS: <code>YES</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>fp32</code></li> <li>CM_ML_MODEL_PRECISION: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>fp32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>int8</code></li> <li>CM_ML_MODEL_PRECISION: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_INPUT_DATA_TYPES: <code>uint8</code></li> <li>CM_ML_MODEL_PRECISION: <code>uint8</code></li> <li>CM_ML_MODEL_WEIGHT_DATA_TYPES: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#default-variations","title":"Default variations","text":"<p><code>_int8,_tflite</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-ml-model-tiny-resnet/#script-output","title":"Script output","text":"<pre><code>cmr \"get raw ml-model resnet pretrained tiny model ic ml-model-tiny-resnet image-classification [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/","title":"get-ml-model-using-imagenet-from-model-zoo","text":"<p>Automatically generated README for this automation recipe: get-ml-model-using-imagenet-from-model-zoo</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model model-zoo zoo imagenet image-classification\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model,model-zoo,zoo,imagenet,image-classification[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model model-zoo zoo imagenet image-classification [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model,model-zoo,zoo,imagenet,image-classification'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model model-zoo zoo imagenet image-classification[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#variations","title":"Variations","text":"<ul> <li> <p>Group \"model-source\"      Click here to expand this section. <ul> <li><code>_model.#</code></li> <li><code>_model.resnet101-pytorch-base</code></li> <li><code>_model.resnet50-pruned95-uniform-quant</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-ml-model-using-imagenet-from-model-zoo/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model model-zoo zoo imagenet image-classification [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-models/get-tvm-model/","title":"get-tvm-model","text":"<p>Automatically generated README for this automation recipe: get-tvm-model</p> <p>Category: AI/ML models</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-models/get-tvm-model/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-models/get-tvm-model/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-models/get-tvm-model/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-models/get-tvm-model/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ml-model-tvm tvm-model\" --help</code></p>"},{"location":"scripts/AI-ML-models/get-tvm-model/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/AI-ML-models/get-tvm-model/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ml-model-tvm,tvm-model[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-models/get-tvm-model/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ml-model-tvm tvm-model [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-tvm-model/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ml-model-tvm,tvm-model'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-models/get-tvm-model/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ml-model-tvm tvm-model[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-models/get-tvm-model/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_tune-model</code><ul> <li>ENV variables:<ul> <li>CM_TUNE_TVM_MODEL: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batchsize\"      Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_MAX_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"frontend\"      Click here to expand this section. <ul> <li><code>_onnx</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TVM_FRONTEND_FRAMEWORK: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>Aliases: <code>_torch</code></li> <li>ENV variables:<ul> <li>CM_TVM_FRONTEND_FRAMEWORK: <code>pytorch</code></li> </ul> </li> </ul> </li> <li><code>_tensorflow</code><ul> <li>Aliases: <code>_tf</code></li> <li>ENV variables:<ul> <li>CM_TVM_FRONTEND_FRAMEWORK: <code>tensorflow</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_TVM_FRONTEND_FRAMEWORK: <code>tflite</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_model.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)</li> <li><code>_int8</code></li> <li><code>_uint8</code></li> </ul> <li> <p>Group \"runtime\"      Click here to expand this section. <ul> <li><code>_graph_executor</code><ul> <li>ENV variables:<ul> <li>CM_TVM_USE_VM: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_virtual_machine</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TVM_USE_VM: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-models/get-tvm-model/#default-variations","title":"Default variations","text":"<p><code>_fp32,_onnx,_virtual_machine</code></p>"},{"location":"scripts/AI-ML-models/get-tvm-model/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ML_MODEL_MAX_BATCH_SIZE: <code>1</code></li> <li>CM_TUNE_TVM_MODEL: <code>no</code></li> <li>CM_TVM_USE_VM: <code>yes</code></li> <li>CM_TVM_FRONTEND_FRAMEWORK: <code>onnx</code></li> </ul>"},{"location":"scripts/AI-ML-models/get-tvm-model/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-models/get-tvm-model/#script-output","title":"Script output","text":"<pre><code>cmr \"get ml-model-tvm tvm-model [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-optimization/","title":"AI-ML-optimization","text":"<ul> <li>calibrate-model-for.qaic</li> <li>compile-model-for.qaic</li> <li>prune-bert-models</li> </ul>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/","title":"calibrate-model-for.qaic","text":"<p>Automatically generated README for this automation recipe: calibrate-model-for.qaic</p> <p>Category: AI/ML optimization</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"qaic calibrate profile qaic-profile qaic-calibrate\" --help</code></p>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=qaic,calibrate,profile,qaic-profile,qaic-calibrate[,variations] \n</code></pre>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"qaic calibrate profile qaic-profile qaic-calibrate [variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'qaic,calibrate,profile,qaic-profile,qaic-calibrate'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"qaic calibrate profile qaic-profile qaic-calibrate[variations]\" \n</code></pre>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_first.#</code></li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_bs.#</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_BATCH_SIZE: <code>#</code></li> <li>CM_CREATE_INPUT_BATCH: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_bs.1</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_BATCH_SIZE: <code>1</code></li> <li>CM_CREATE_INPUT_BATCH: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"calib-dataset-filter-size\"      Click here to expand this section. <ul> <li><code>_filter-size.#</code></li> </ul> <li> <p>Group \"calibration-option\"      Click here to expand this section. <ul> <li><code>_mlperf.option1</code></li> <li><code>_mlperf.option2</code></li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_CALIBRATE_SQUAD: <code>yes</code></li> <li>CM_QAIC_COMPILER_ARGS: ``</li> <li>CM_QAIC_COMPILER_PARAMS: <code>-onnx-define-symbol=batch_size,1 -onnx-define-symbol=seg_length,&lt;&lt;&lt;CM_DATASET_SQUAD_TOKENIZED_MAX_SEQ_LENGTH&gt;&gt;&gt; -input-list-file=&lt;&lt;&lt;CM_DATASET_SQUAD_TOKENIZED_PACKED_FILENAMES_FILE&gt;&gt;&gt; -num-histogram-bins=512 -profiling-threads=&lt;&lt;&lt;CM_HOST_CPU_PHYSICAL_CORES_PER_SOCKET&gt;&gt;&gt;</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>calibrate_bert_mlperf</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_NAME: <code>resnet50</code></li> <li>CM_CALIBRATE_IMAGENET: <code>yes</code></li> <li>CM_QAIC_COMPILER_ARGS: ``</li> <li>CM_QAIC_COMPILER_PARAMS: <code>-output-node-name=ArgMax -profiling-threads=&lt;&lt;&lt;CM_HOST_CPU_PHYSICAL_CORES_PER_SOCKET&gt;&gt;&gt;</code></li> <li>CM_QAIC_OUTPUT_NODE_NAME: <code>-output-node-name=ArgMax</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>calibrate_resnet50_tf</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_NAME: <code>retinanet</code></li> <li>CM_CALIBRATE_OPENIMAGES: <code>yes</code></li> <li>CM_QAIC_COMPILER_ARGS: ``</li> <li>CM_QAIC_COMPILER_PARAMS: <code>-enable-channelwise -profiling-threads=&lt;&lt;&lt;CM_HOST_CPU_PHYSICAL_CORES_PER_SOCKET&gt;&gt;&gt; -onnx-define-symbol=batch_size,&lt;&lt;&lt;CM_QAIC_MODEL_BATCH_SIZE&gt;&gt;&gt; -node-precision-info=&lt;&lt;&lt;CM_ML_MODEL_RETINANET_QAIC_NODE_PRECISION_INFO_FILE_PATH&gt;&gt;&gt;</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>calibrate_retinanet_no_nms_mlperf</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model-framework\"      Click here to expand this section. <ul> <li><code>_tf</code></li> </ul> <li> <p>Group \"seq-length\"      Click here to expand this section. <ul> <li><code>_seq.#</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_TOKENIZED_MAX_SEQ_LENGTH: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_seq.384</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_SQUAD_TOKENIZED_MAX_SEQ_LENGTH: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-optimization/calibrate-model-for.qaic/#script-output","title":"Script output","text":"<pre><code>cmr \"qaic calibrate profile qaic-profile qaic-calibrate [variations]\"  -j\n</code></pre>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/","title":"compile-model-for.qaic","text":"<p>Automatically generated README for this automation recipe: compile-model-for.qaic</p> <p>Category: AI/ML optimization</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"qaic compile model model-compile qaic-compile\" --help</code></p>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=qaic,compile,model,model-compile,qaic-compile[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"qaic compile model model-compile qaic-compile [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'qaic,compile,model,model-compile,qaic-compile'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"qaic compile model model-compile qaic-compile[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_COMPILE_BERT: <code>on</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>calibrate_bert_mlperf</code></li> <li>CM_QAIC_MODEL_COMPILER_PARAMS_BASE: <code>-aic-hw -aic-hw-version=2.0 -execute-nodes-in-fp16=Add,Div,Erf,Softmax -quantization-schema=symmetric_with_uint8 -quantization-precision=Int8 -quantization-precision-bias=Int32 -vvv -compile-only -onnx-define-symbol=batch_size,1 -onnx-define-symbol=seg_length,384 -multicast-weights -combine-inputs=false -combine-outputs=false</code></li> <li>CM_QAIC_MODEL_COMPILER_ARGS: ``</li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_COMPILE_BERT: <code>on</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>bert_mlperf</code></li> <li>CM_QAIC_MODEL_COMPILER_PARAMS_BASE: <code>-aic-hw -aic-hw-version=2.0 -convert-to-fp16 -vvv -compile-only -onnx-define-symbol=batch_size,1 -onnx-define-symbol=seg_length,384 -combine-inputs=false -combine-outputs=false</code></li> <li>CM_QAIC_MODEL_COMPILER_ARGS: ``</li> </ul> </li> </ul> </li> <li><code>_resnet50</code><ul> <li>ENV variables:<ul> <li>CM_COMPILE_RESNET: <code>on</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>compile_resnet50_tf</code></li> <li>CM_QAIC_MODEL_COMPILER_PARAMS_BASE: <code>-aic-hw -aic-hw-version=2.0 -quantization-schema=symmetric_with_uint8 -quantization-precision=Int8 -output-node-name=ArgMax -vvv -compile-only -use-producer-dma=1</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_COMPILE_RETINANET: <code>on</code></li> <li>CM_QAIC_MODEL_TO_CONVERT: <code>calibrate_retinanet_no_nms_mlperf</code></li> <li>CM_QAIC_MODEL_COMPILER_ARGS: <code>-aic-enable-depth-first</code></li> <li>CM_QAIC_MODEL_COMPILER_PARAMS_BASE: <code>-aic-hw -aic-hw-version=2.0 -compile-only -enable-channelwise -onnx-define-symbol=batch_size,1 -node-precision-info=&lt;&lt;&lt;CM_ML_MODEL_RETINANET_QAIC_NODE_PRECISION_INFO_FILE_PATH&gt;&gt;&gt; -quantization-schema-constants=symmetric_with_uint8 -quantization-schema-activations=asymmetric -quantization-calibration=None</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_bs.#</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_bs.1</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_BATCH_SIZE: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"calib-dataset-filter-size\"      Click here to expand this section. <ul> <li><code>_filter-size.#</code></li> </ul> <li> <p>Group \"mlperf-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code></li> <li><code>_offline</code></li> <li><code>_server</code></li> <li><code>_singlestream</code> (default)</li> </ul> <li> <p>Group \"model-framework\"      Click here to expand this section. <ul> <li><code>_tf</code></li> </ul> <li> <p>Group \"nsp\"      Click here to expand this section. <ul> <li><code>_nsp.14</code></li> <li><code>_nsp.16</code></li> <li><code>_nsp.8</code></li> <li><code>_nsp.9</code></li> </ul> <li> <p>Group \"percentile-calibration\"      Click here to expand this section. <ul> <li><code>_pc.#</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_COMPILER_PERCENTILE_CALIBRATION_VALUE: <code>#</code></li> <li>CM_QAIC_MODEL_COMPILER_QUANTIZATION_PARAMS: <code>-quantization-calibration=Percentile  -percentile-calibration-value=&lt;&lt;&lt;CM_QAIC_MODEL_COMPILER_PERCENTILE_CALIBRATION_VALUE&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"quantization\"      Click here to expand this section. <ul> <li><code>_no-quantized</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_QUANTIZATION: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_quantized</code> (default)<ul> <li>ENV variables:<ul> <li>CM_QAIC_MODEL_QUANTIZATION: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#default-variations","title":"Default variations","text":"<p><code>_quantized,_singlestream</code></p>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--register=value</code>  \u2192  <code>CM_REGISTER_CACHE=value</code></li> </ul>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-optimization/compile-model-for.qaic/#script-output","title":"Script output","text":"<pre><code>cmr \"qaic compile model model-compile qaic-compile [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/","title":"prune-bert-models","text":"<p>Automatically generated README for this automation recipe: prune-bert-models</p> <p>Category: AI/ML optimization</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/AI-ML-optimization/prune-bert-models/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"prune bert-models bert-prune prune-bert-models\" --help</code></p>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=prune,bert-models,bert-prune,prune-bert-models[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"prune bert-models bert-prune prune-bert-models [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'prune,bert-models,bert-prune,prune-bert-models'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"prune bert-models bert-prune prune-bert-models[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_model.#</code><ul> <li>ENV variables:<ul> <li>CM_BERT_PRUNE_MODEL_NAME: <code>#</code></li> <li>CM_MODEL_ZOO_STUB: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_path.#</code><ul> <li>ENV variables:<ul> <li>CM_BERT_PRUNE_CKPT_PATH: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_task.#</code><ul> <li>ENV variables:<ul> <li>CM_BERT_PRUNE_TASK: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--constraint=value</code>  \u2192  <code>CM_BERT_PRUNE_CONSTRAINT=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_BERT_PRUNE_OUTPUT_DIR=value</code></li> </ul>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BERT_PRUNE_TASK: <code>squad</code></li> <li>CM_BERT_PRUNE_MODEL_NAME: <code>bert-large-uncased</code></li> <li>CM_MODEL_ZOO_STUB: <code>bert-large-uncased</code></li> <li>CM_BERT_PRUNE_CONSTRAINT: <code>0.5</code></li> </ul>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/AI-ML-optimization/prune-bert-models/#script-output","title":"Script output","text":"<pre><code>cmr \"prune bert-models bert-prune prune-bert-models [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/CM-Interface/","title":"CM-Interface","text":"<ul> <li>get-cache-dir</li> </ul>"},{"location":"scripts/CM-Interface/get-cache-dir/","title":"get-cache-dir","text":"<p>Automatically generated README for this automation recipe: get-cache-dir</p> <p>Category: CM Interface</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CM-Interface/get-cache-dir/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CM-Interface/get-cache-dir/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CM-Interface/get-cache-dir/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CM-Interface/get-cache-dir/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cache dir directory\" --help</code></p>"},{"location":"scripts/CM-Interface/get-cache-dir/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/CM-Interface/get-cache-dir/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cache,dir,directory[,variations] \n</code></pre>"},{"location":"scripts/CM-Interface/get-cache-dir/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cache dir directory [variations]\" \n</code></pre>"},{"location":"scripts/CM-Interface/get-cache-dir/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cache,dir,directory'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CM-Interface/get-cache-dir/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cache dir directory[variations]\" \n</code></pre>"},{"location":"scripts/CM-Interface/get-cache-dir/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_name.#</code><ul> <li>ENV variables:<ul> <li>CM_CACHE_DIR_NAME: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/CM-Interface/get-cache-dir/#script-output","title":"Script output","text":"<pre><code>cmr \"get cache dir directory [variations]\"  -j\n</code></pre>"},{"location":"scripts/CM-automation/","title":"CM-automation","text":"<ul> <li>create-custom-cache-entry</li> </ul>"},{"location":"scripts/CM-automation/create-custom-cache-entry/","title":"create-custom-cache-entry","text":"<p>Automatically generated README for this automation recipe: create-custom-cache-entry</p> <p>Category: CM automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CM-automation/create-custom-cache-entry/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"create custom cache entry\" --help</code></p>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/CM-automation/create-custom-cache-entry/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=create,custom,cache,entry [--input_flags]\n</code></pre>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"create custom cache entry \" [--input_flags]\n</code></pre>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'create,custom,cache,entry'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"create custom cache entry\" [--input_flags]\n</code></pre>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--env_key=value</code>  \u2192  <code>CM_CUSTOM_CACHE_ENTRY_ENV_KEY=value</code></li> <li><code>--env_key2=value</code>  \u2192  <code>CM_CUSTOM_CACHE_ENTRY_ENV_KEY2=value</code></li> <li><code>--path=value</code>  \u2192  <code>CM_CUSTOM_CACHE_ENTRY_PATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_CUSTOM_CACHE_ENTRY_PATH=value</code></li> </ul>"},{"location":"scripts/CM-automation/create-custom-cache-entry/#script-output","title":"Script output","text":"<pre><code>cmr \"create custom cache entry \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/CM-interface-prototyping/","title":"CM-interface-prototyping","text":"<ul> <li>test-debug</li> <li>test-mlperf-inference-retinanet</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-debug/","title":"test-debug","text":"<p>Automatically generated README for this automation recipe: test-debug</p> <p>Category: CM interface prototyping</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-debug/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CM-interface-prototyping/test-debug/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-debug/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CM-interface-prototyping/test-debug/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test cm-debug\" --help</code></p>"},{"location":"scripts/CM-interface-prototyping/test-debug/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/CM-interface-prototyping/test-debug/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,cm-debug \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-debug/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test cm-debug \" \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-debug/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,cm-debug'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-debug/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test cm-debug\" \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-debug/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-debug/#script-output","title":"Script output","text":"<pre><code>cmr \"test cm-debug \"  -j\n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/","title":"test-mlperf-inference-retinanet","text":"<p>Automatically generated README for this automation recipe: test-mlperf-inference-retinanet</p> <p>Category: CM interface prototyping</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test mlperf-inference-win retinanet windows\" --help</code></p>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,mlperf-inference-win,retinanet,windows \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test mlperf-inference-win retinanet windows \" \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,mlperf-inference-win,retinanet,windows'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test mlperf-inference-win retinanet windows\" \n</code></pre>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/CM-interface-prototyping/test-mlperf-inference-retinanet/#script-output","title":"Script output","text":"<pre><code>cmr \"test mlperf-inference-win retinanet windows \"  -j\n</code></pre>"},{"location":"scripts/CUDA-automation/","title":"CUDA-automation","text":"<ul> <li>get-cuda</li> <li>get-cuda-devices</li> <li>get-cudnn</li> <li>get-tensorrt</li> <li>install-cuda-package-manager</li> <li>install-cuda-prebuilt</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/","title":"get-cuda","text":"<p>Automatically generated README for this automation recipe: get-cuda</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li>Notes from the authors, contributors and users: README-extra</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#system-dependencies","title":"System dependencies","text":"<ul> <li>Download CUDA toolkit.</li> <li>Download cuDNN.</li> <li> <p>Download TensorRT.</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/get-cuda/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/get-cuda/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cuda cuda-compiler cuda-lib toolkit lib nvcc get-nvcc get-cuda 46d133d9ef92422d\" --help</code></p>"},{"location":"scripts/CUDA-automation/get-cuda/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/CUDA-automation/get-cuda/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cuda,cuda-compiler,cuda-lib,toolkit,lib,nvcc,get-nvcc,get-cuda,46d133d9ef92422d[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cuda cuda-compiler cuda-lib toolkit lib nvcc get-nvcc get-cuda 46d133d9ef92422d [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cuda,cuda-compiler,cuda-lib,toolkit,lib,nvcc,get-nvcc,get-cuda,46d133d9ef92422d'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cuda cuda-compiler cuda-lib toolkit lib nvcc get-nvcc get-cuda 46d133d9ef92422d[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cudnn</code><ul> <li>ENV variables:<ul> <li>CM_CUDA_NEEDS_CUDNN: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_package-manager</code><ul> <li>ENV variables:<ul> <li>CM_CUDA_PACKAGE_MANAGER_INSTALL: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"installation-mode\"      Click here to expand this section. <ul> <li><code>_lib-only</code><ul> <li>ENV variables:<ul> <li>CM_CUDA_FULL_TOOLKIT_INSTALL: <code>no</code></li> <li>CM_TMP_FILE_TO_CHECK_UNIX: <code>libcudart.so</code></li> <li>CM_TMP_FILE_TO_CHECK_WINDOWS: <code>libcudart.dll</code></li> </ul> </li> </ul> </li> <li><code>_toolkit</code> (default)<ul> <li>ENV variables:<ul> <li>CM_CUDA_FULL_TOOLKIT_INSTALL: <code>yes</code></li> <li>CM_TMP_FILE_TO_CHECK_UNIX: <code>nvcc</code></li> <li>CM_TMP_FILE_TO_CHECK_WINDOWS: <code>nvcc.exe</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#default-variations","title":"Default variations","text":"<p><code>_toolkit</code></p>"},{"location":"scripts/CUDA-automation/get-cuda/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--cudnn_tar_file=value</code>  \u2192  <code>CM_CUDNN_TAR_FILE_PATH=value</code></li> <li><code>--cudnn_tar_path=value</code>  \u2192  <code>CM_CUDNN_TAR_FILE_PATH=value</code></li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_CUDA_PATH_LIB_CUDNN_EXISTS: <code>no</code></li> <li>CM_REQUIRE_INSTALL: <code>no</code></li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda/#script-output","title":"Script output","text":"<pre><code>cmr \"get cuda cuda-compiler cuda-lib toolkit lib nvcc get-nvcc get-cuda 46d133d9ef92422d [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda-devices/","title":"get-cuda-devices","text":"<p>Automatically generated README for this automation recipe: get-cuda-devices</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/get-cuda-devices/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cuda-devices\" --help</code></p>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/CUDA-automation/get-cuda-devices/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cuda-devices \n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cuda-devices \" \n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cuda-devices'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cuda-devices\" \n</code></pre>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/CUDA-automation/get-cuda-devices/#script-output","title":"Script output","text":"<pre><code>cmr \"get cuda-devices \"  -j\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cudnn/","title":"get-cudnn","text":"<p>Automatically generated README for this automation recipe: get-cudnn</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CUDA-automation/get-cudnn/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/get-cudnn/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/get-cudnn/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/get-cudnn/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cudnn nvidia\" --help</code></p>"},{"location":"scripts/CUDA-automation/get-cudnn/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input FlagsInput Flag MappingDefault environment"},{"location":"scripts/CUDA-automation/get-cudnn/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cudnn,nvidia [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cudnn/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cudnn nvidia \" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cudnn/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cudnn,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cudnn/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cudnn nvidia\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-cudnn/#input-flags","title":"Input Flags","text":"<ul> <li>--input: Full path to the installed cuDNN library</li> <li>--tar_file: Full path to the cuDNN Tar file downloaded from Nvidia website (https://developer.nvidia.com/cudnn)</li> </ul>"},{"location":"scripts/CUDA-automation/get-cudnn/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_INPUT=value</code></li> <li><code>--tar_file=value</code>  \u2192  <code>CM_CUDNN_TAR_FILE_PATH=value</code></li> </ul>"},{"location":"scripts/CUDA-automation/get-cudnn/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_INPUT: ``</li> <li>CM_SUDO: <code>sudo</code></li> </ul>"},{"location":"scripts/CUDA-automation/get-cudnn/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/CUDA-automation/get-cudnn/#script-output","title":"Script output","text":"<pre><code>cmr \"get cudnn nvidia \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/CUDA-automation/get-tensorrt/","title":"get-tensorrt","text":"<p>Automatically generated README for this automation recipe: get-tensorrt</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CUDA-automation/get-tensorrt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/get-tensorrt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/get-tensorrt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/get-tensorrt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get tensorrt nvidia\" --help</code></p>"},{"location":"scripts/CUDA-automation/get-tensorrt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag Mapping"},{"location":"scripts/CUDA-automation/get-tensorrt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,tensorrt,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-tensorrt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get tensorrt nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-tensorrt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,tensorrt,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/get-tensorrt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get tensorrt nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/get-tensorrt/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_dev</code><ul> <li>ENV variables:<ul> <li>CM_TENSORRT_REQUIRE_DEV: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/CUDA-automation/get-tensorrt/#input-flags","title":"Input Flags","text":"<ul> <li>--input: Full path to the installed TensorRT library (nvinfer)</li> <li>--tar_file: Full path to the TensorRT Tar file downloaded from the Nvidia website (https://developer.nvidia.com/tensorrt)</li> </ul>"},{"location":"scripts/CUDA-automation/get-tensorrt/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_INPUT=value</code></li> <li><code>--tar_file=value</code>  \u2192  <code>CM_TENSORRT_TAR_FILE_PATH=value</code></li> </ul>"},{"location":"scripts/CUDA-automation/get-tensorrt/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/CUDA-automation/get-tensorrt/#script-output","title":"Script output","text":"<pre><code>cmr \"get tensorrt nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/","title":"install-cuda-package-manager","text":"<p>Automatically generated README for this automation recipe: install-cuda-package-manager</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install package-manager cuda package-manager-cuda install-pm-cuda\" --help</code></p>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,package-manager,cuda,package-manager-cuda,install-pm-cuda \n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install package-manager cuda package-manager-cuda install-pm-cuda \" \n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,package-manager,cuda,package-manager-cuda,install-pm-cuda'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install package-manager cuda package-manager-cuda install-pm-cuda\" \n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/CUDA-automation/install-cuda-package-manager/#script-output","title":"Script output","text":"<pre><code>cmr \"install package-manager cuda package-manager-cuda install-pm-cuda \"  -j\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/","title":"install-cuda-prebuilt","text":"<p>Automatically generated README for this automation recipe: install-cuda-prebuilt</p> <p>Category: CUDA automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install prebuilt cuda prebuilt-cuda install-prebuilt-cuda\" --help</code></p>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,prebuilt,cuda,prebuilt-cuda,install-prebuilt-cuda[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install prebuilt cuda prebuilt-cuda install-prebuilt-cuda [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,prebuilt,cuda,prebuilt-cuda,install-prebuilt-cuda'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install prebuilt cuda prebuilt-cuda install-prebuilt-cuda[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#variations","title":"Variations","text":"<ul> <li> <p>Group \"install-driver\"      Click here to expand this section. <ul> <li><code>_driver</code><ul> <li>ENV variables:<ul> <li>CM_CUDA_INSTALL_DRIVER: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_no-driver</code> (default)<ul> <li>ENV variables:<ul> <li>CM_CUDA_INSTALL_DRIVER: <code>no</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#default-variations","title":"Default variations","text":"<p><code>_no-driver</code></p>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--local_run_file_path=value</code>  \u2192  <code>CUDA_RUN_FILE_LOCAL_PATH=value</code></li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SUDO: <code>sudo</code></li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#versions","title":"Versions","text":"<p>Default version: <code>11.8.0</code></p> <ul> <li><code>11.7.0</code></li> <li><code>11.8.0</code></li> <li><code>12.0.0</code></li> <li><code>12.1.1</code></li> <li><code>12.2.0</code></li> <li><code>12.3.2</code></li> <li><code>12.4.1</code></li> </ul>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/CUDA-automation/install-cuda-prebuilt/#script-output","title":"Script output","text":"<pre><code>cmr \"install prebuilt cuda prebuilt-cuda install-prebuilt-cuda [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Cloud-automation/","title":"Cloud-automation","text":"<ul> <li>destroy-terraform</li> <li>get-aws-cli</li> <li>get-terraform</li> <li>install-aws-cli</li> <li>install-terraform-from-src</li> <li>run-terraform</li> </ul>"},{"location":"scripts/Cloud-automation/destroy-terraform/","title":"destroy-terraform","text":"<p>Automatically generated README for this automation recipe: destroy-terraform</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Cloud-automation/destroy-terraform/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/destroy-terraform/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/destroy-terraform/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/destroy-terraform/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"destroy terraform cmd\" --help</code></p>"},{"location":"scripts/Cloud-automation/destroy-terraform/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Cloud-automation/destroy-terraform/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=destroy,terraform,cmd \n</code></pre>"},{"location":"scripts/Cloud-automation/destroy-terraform/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"destroy terraform cmd \" \n</code></pre>"},{"location":"scripts/Cloud-automation/destroy-terraform/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'destroy,terraform,cmd'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/destroy-terraform/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"destroy terraform cmd\" \n</code></pre>"},{"location":"scripts/Cloud-automation/destroy-terraform/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Cloud-automation/destroy-terraform/#script-output","title":"Script output","text":"<pre><code>cmr \"destroy terraform cmd \"  -j\n</code></pre>"},{"location":"scripts/Cloud-automation/get-aws-cli/","title":"get-aws-cli","text":"<p>Automatically generated README for this automation recipe: get-aws-cli</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Cloud-automation/get-aws-cli/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/get-aws-cli/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/get-aws-cli/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/get-aws-cli/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get aws-cli aws cli\" --help</code></p>"},{"location":"scripts/Cloud-automation/get-aws-cli/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Cloud-automation/get-aws-cli/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,aws-cli,aws,cli \n</code></pre>"},{"location":"scripts/Cloud-automation/get-aws-cli/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get aws-cli aws cli \" \n</code></pre>"},{"location":"scripts/Cloud-automation/get-aws-cli/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,aws-cli,aws,cli'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/get-aws-cli/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get aws-cli aws cli\" \n</code></pre>"},{"location":"scripts/Cloud-automation/get-aws-cli/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Cloud-automation/get-aws-cli/#script-output","title":"Script output","text":"<pre><code>cmr \"get aws-cli aws cli \"  -j\n</code></pre>"},{"location":"scripts/Cloud-automation/get-terraform/","title":"get-terraform","text":"<p>Automatically generated README for this automation recipe: get-terraform</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Cloud-automation/get-terraform/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/get-terraform/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/get-terraform/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/get-terraform/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get terraform get-terraform\" --help</code></p>"},{"location":"scripts/Cloud-automation/get-terraform/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Cloud-automation/get-terraform/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,terraform,get-terraform \n</code></pre>"},{"location":"scripts/Cloud-automation/get-terraform/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get terraform get-terraform \" \n</code></pre>"},{"location":"scripts/Cloud-automation/get-terraform/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,terraform,get-terraform'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/get-terraform/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get terraform get-terraform\" \n</code></pre>"},{"location":"scripts/Cloud-automation/get-terraform/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Cloud-automation/get-terraform/#script-output","title":"Script output","text":"<pre><code>cmr \"get terraform get-terraform \"  -j\n</code></pre>"},{"location":"scripts/Cloud-automation/install-aws-cli/","title":"install-aws-cli","text":"<p>Automatically generated README for this automation recipe: install-aws-cli</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Cloud-automation/install-aws-cli/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/install-aws-cli/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/install-aws-cli/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/install-aws-cli/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install script aws-cli aws cli\" --help</code></p>"},{"location":"scripts/Cloud-automation/install-aws-cli/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Cloud-automation/install-aws-cli/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,script,aws-cli,aws,cli \n</code></pre>"},{"location":"scripts/Cloud-automation/install-aws-cli/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install script aws-cli aws cli \" \n</code></pre>"},{"location":"scripts/Cloud-automation/install-aws-cli/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,script,aws-cli,aws,cli'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/install-aws-cli/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install script aws-cli aws cli\" \n</code></pre>"},{"location":"scripts/Cloud-automation/install-aws-cli/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Cloud-automation/install-aws-cli/#script-output","title":"Script output","text":"<pre><code>cmr \"install script aws-cli aws cli \"  -j\n</code></pre>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/","title":"install-terraform-from-src","text":"<p>Automatically generated README for this automation recipe: install-terraform-from-src</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/install-terraform-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install terraform from-src\" --help</code></p>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,terraform,from-src \n</code></pre>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install terraform from-src \" \n</code></pre>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,terraform,from-src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install terraform from-src\" \n</code></pre>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#versions","title":"Versions","text":"<p>Default version: <code>main</code></p> <ul> <li><code>main</code></li> </ul>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Cloud-automation/install-terraform-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install terraform from-src \"  -j\n</code></pre>"},{"location":"scripts/Cloud-automation/run-terraform/","title":"run-terraform","text":"<p>Automatically generated README for this automation recipe: run-terraform</p> <p>Category: Cloud automation</p> <p>License: Apache 2.0</p> <ul> <li>Notes from the authors, contributors and users: README-extra</li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#setup-for-google-cloud-instances","title":"Setup for Google Cloud Instances","text":"<pre><code>sudo snap install google-cloud-cli --classic\ngcloud auth application-default login\n</code></pre> <p>The above two commands will install google-cloud-cli and authorizes the user to access it. Once done, you can start creating gcp instance using CM commands like below. To destroy an instance just repeat the same command with <code>--destroy</code> option.</p> <p><pre><code>cm run script --tags=run,terraform,_gcp,_gcp_project.mlperf-inference-tests --cminit\n</code></pre> Here, <code>mlperf-inference-tests</code> is the name of the google project as created in Google cloud console</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Cloud-automation/run-terraform/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Cloud-automation/run-terraform/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run terraform\" --help</code></p>"},{"location":"scripts/Cloud-automation/run-terraform/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Cloud-automation/run-terraform/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,terraform[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Cloud-automation/run-terraform/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run terraform [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Cloud-automation/run-terraform/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,terraform'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Cloud-automation/run-terraform/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run terraform[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Cloud-automation/run-terraform/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_amazon-linux-2-kernel.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE_OS: <code>amazon-linux-2-kernel.#</code></li> </ul> </li> </ul> </li> <li><code>_graviton</code><ul> <li>ENV variables:<ul> <li>CM_TERRAFORM_AWS_GRAVITON_INSTANCE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_inferentia</code><ul> <li>ENV variables:<ul> <li>CM_TERRAFORM_AWS_INFERENTIA_INSTANCE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_rhel.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE_OS: <code>rhel.#</code></li> </ul> </li> </ul> </li> <li><code>_ubuntu.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE_OS: <code>ubuntu.#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"aws-instance-image\"      Click here to expand this section. <ul> <li><code>_amazon-linux-2-kernel.510,arm64,us-west-2</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-0f1a5f5ada0e7da53</code></li> </ul> </li> </ul> </li> <li><code>_aws_instance_image.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_aws_instance_image.ami-0735c191cf914754d</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-0735c191cf914754d</code></li> </ul> </li> </ul> </li> <li><code>_aws_instance_image.ami-0a0d8589b597d65b3</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-0a0d8589b597d65b3</code></li> </ul> </li> </ul> </li> <li><code>_rhel.9,x86,us-west-2</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-0dda7e535b65b6469</code></li> </ul> </li> </ul> </li> <li><code>_ubuntu.2204,arm64,us-west-2</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-079f51a7bcca65b92</code></li> </ul> </li> </ul> </li> <li><code>_ubuntu.2204,x86,us-west-2</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ami-0735c191cf914754d</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"aws-instance-type\"      Click here to expand this section. <ul> <li><code>_a1.2xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>a1.2xlarge</code></li> </ul> </li> </ul> </li> <li><code>_a1.metal</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>a1.metal</code></li> </ul> </li> </ul> </li> <li><code>_a1.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>a1.xlarge</code></li> </ul> </li> </ul> </li> <li><code>_aws_instance_type.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_c5.12xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>c5.12xlarge</code></li> </ul> </li> </ul> </li> <li><code>_c5.4xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>c5.4xlarge</code></li> </ul> </li> </ul> </li> <li><code>_c5d.9xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>c5d.9xlarge</code></li> </ul> </li> </ul> </li> <li><code>_g4dn.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>g4dn.xlarge</code></li> </ul> </li> </ul> </li> <li><code>_inf1.2xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>inf1.2xlarge</code></li> </ul> </li> </ul> </li> <li><code>_inf1.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>inf1.xlarge</code></li> </ul> </li> </ul> </li> <li><code>_inf2.8xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>inf2.8xlarge</code></li> </ul> </li> </ul> </li> <li><code>_inf2.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>inf2.xlarge</code></li> </ul> </li> </ul> </li> <li><code>_m7g.2xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>m7g.2xlarge</code></li> </ul> </li> </ul> </li> <li><code>_m7g.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>m7g.xlarge</code></li> </ul> </li> </ul> </li> <li><code>_t2.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.#</code></li> </ul> </li> </ul> </li> <li><code>_t2.2xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.2xlarge</code></li> </ul> </li> </ul> </li> <li><code>_t2.large</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.large</code></li> </ul> </li> </ul> </li> <li><code>_t2.medium</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.medium</code></li> </ul> </li> </ul> </li> <li><code>_t2.micro</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.micro</code></li> </ul> </li> </ul> </li> <li><code>_t2.nano</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.nano</code></li> </ul> </li> </ul> </li> <li><code>_t2.small</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.small</code></li> </ul> </li> </ul> </li> <li><code>_t2.xlarge</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>t2.xlarge</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"cloud-provider\"      Click here to expand this section. <ul> <li><code>_aws</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TERRAFORM_CONFIG_DIR_NAME: <code>aws</code></li> </ul> </li> </ul> </li> <li><code>_gcp</code><ul> <li>ENV variables:<ul> <li>CM_TERRAFORM_CONFIG_DIR_NAME: <code>gcp</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"gcp-instance-image\"      Click here to expand this section. <ul> <li><code>_debian-cloud/debian-11</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>debian-cloud/debian-11</code></li> </ul> </li> </ul> </li> <li><code>_gcp_instance_image.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_ubuntu-2204-jammy-v20230114</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_IMAGE: <code>ubuntu-2204-jammy-v20230114</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"gcp-instance-type\"      Click here to expand this section. <ul> <li><code>_f1-micro</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>f1-micro</code></li> </ul> </li> </ul> </li> <li><code>_gcp_instance_type.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_n1-highmem.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>n1-highmem-#</code></li> </ul> </li> </ul> </li> <li><code>_n1-standard.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_TYPE: <code>n1-highmem-#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"gcp-project\"      Click here to expand this section. <ul> <li><code>_gcp_project.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_GCP_PROJECT: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"instance-name\"      Click here to expand this section. <ul> <li><code>_instance_name.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_NAME: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"platform\"      Click here to expand this section. <ul> <li><code>_arm64</code><ul> <li>ENV variables:<ul> <li>CM_INSTANCE_PLATFORM: <code>arm64</code></li> </ul> </li> </ul> </li> <li><code>_x86</code> (default)<ul> <li>ENV variables:<ul> <li>CM_INSTANCE_PLATFORM: <code>x86</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"region\"      Click here to expand this section. <ul> <li><code>_region.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_REGION: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_us-west-2</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_REGION: <code>us-west-2</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"storage-size\"      Click here to expand this section. <ul> <li><code>_storage_size.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_DISK_GBS: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_storage_size.8</code><ul> <li>ENV variables:<ul> <li>TF_VAR_DISK_GBS: <code>8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"zone\"      Click here to expand this section. <ul> <li><code>_zone.#</code><ul> <li>ENV variables:<ul> <li>TF_VAR_INSTANCE_ZONE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#default-variations","title":"Default variations","text":"<p><code>_aws,_x86</code></p>"},{"location":"scripts/Cloud-automation/run-terraform/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--cminit=value</code>  \u2192  <code>CM_TERRAFORM_CM_INIT=value</code></li> <li><code>--destroy=value</code>  \u2192  <code>CM_DESTROY_TERRAFORM=value</code></li> <li><code>--gcp_credentials_json_file=value</code>  \u2192  <code>CM_GCP_CREDENTIALS_JSON_PATH=value</code></li> <li><code>--key_file=value</code>  \u2192  <code>CM_SSH_KEY_FILE=value</code></li> <li><code>--run_cmds=value</code>  \u2192  <code>CM_TERRAFORM_RUN_COMMANDS=value</code></li> <li><code>--ssh_key_file=value</code>  \u2192  <code>CM_SSH_KEY_FILE=value</code></li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>TF_VAR_SECURITY_GROUP_ID: <code>sg-0783752c97d2e011d</code></li> <li>TF_VAR_CPU_COUNT: <code>1</code></li> </ul>"},{"location":"scripts/Cloud-automation/run-terraform/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Cloud-automation/run-terraform/#script-output","title":"Script output","text":"<pre><code>cmr \"run terraform [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Collective-benchmarking/","title":"Collective-benchmarking","text":"<ul> <li>launch-benchmark</li> </ul>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/","title":"launch-benchmark","text":"<p>Automatically generated README for this automation recipe: launch-benchmark</p> <p>Category: Collective benchmarking</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Collective-benchmarking/launch-benchmark/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"launch benchmark\" --help</code></p>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=launch,benchmark \n</code></pre>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"launch benchmark \" \n</code></pre>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'launch,benchmark'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"launch benchmark\" \n</code></pre>"},{"location":"scripts/Collective-benchmarking/launch-benchmark/#script-output","title":"Script output","text":"<pre><code>cmr \"launch benchmark \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/","title":"Compiler-automation","text":"<ul> <li>get-aocl</li> <li>get-cl</li> <li>get-compiler-flags</li> <li>get-compiler-rust</li> <li>get-gcc</li> <li>get-go</li> <li>get-llvm</li> <li>install-gcc-src</li> <li>install-ipex-from-src</li> <li>install-llvm-prebuilt</li> <li>install-llvm-src</li> <li>install-onednn-from-src</li> <li>install-onnxruntime-from-src</li> <li>install-pytorch-from-src</li> <li>install-pytorch-kineto-from-src</li> <li>install-torchvision-from-src</li> <li>install-tpp-pytorch-extension</li> <li>install-transformers-from-src</li> </ul>"},{"location":"scripts/Compiler-automation/get-aocl/","title":"get-aocl","text":"<p>Automatically generated README for this automation recipe: get-aocl</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? true</li> </ul>"},{"location":"scripts/Compiler-automation/get-aocl/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-aocl/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-aocl/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-aocl/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get lib aocl amd-optimized amd\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-aocl/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-aocl/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,lib,aocl,amd-optimized,amd \n</code></pre>"},{"location":"scripts/Compiler-automation/get-aocl/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get lib aocl amd-optimized amd \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-aocl/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,lib,aocl,amd-optimized,amd'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-aocl/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get lib aocl amd-optimized amd\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-aocl/#versions","title":"Versions","text":"<p>Default version: <code>4.0</code></p> <ul> <li><code>4.0</code></li> <li><code>master</code></li> </ul>"},{"location":"scripts/Compiler-automation/get-aocl/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/get-aocl/#script-output","title":"Script output","text":"<pre><code>cmr \"get lib aocl amd-optimized amd \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-cl/","title":"Detect or install Microsoft C compiler","text":"<p>Automatically generated README for this automation recipe: get-cl</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/get-cl/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-cl/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-cl/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-cl/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cl compiler c-compiler cpp-compiler get-cl\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-cl/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-cl/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cl,compiler,c-compiler,cpp-compiler,get-cl \n</code></pre>"},{"location":"scripts/Compiler-automation/get-cl/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cl compiler c-compiler cpp-compiler get-cl \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-cl/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cl,compiler,c-compiler,cpp-compiler,get-cl'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-cl/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cl compiler c-compiler cpp-compiler get-cl\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-cl/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <p>No run file exists for Linux/macOS</p> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Compiler-automation/get-cl/#script-output","title":"Script output","text":"<pre><code>cmr \"get cl compiler c-compiler cpp-compiler get-cl \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-flags/","title":"get-compiler-flags","text":"<p>Automatically generated README for this automation recipe: get-compiler-flags</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-compiler-flags/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get compiler-flags\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-compiler-flags/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,compiler-flags \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get compiler-flags \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,compiler-flags'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get compiler-flags\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-flags/#script-output","title":"Script output","text":"<pre><code>cmr \"get compiler-flags \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-rust/","title":"get-compiler-rust","text":"<p>Automatically generated README for this automation recipe: get-compiler-rust</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-compiler-rust/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get rust-compiler\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-compiler-rust/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,rust-compiler \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get rust-compiler \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,rust-compiler'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get rust-compiler\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/get-compiler-rust/#script-output","title":"Script output","text":"<pre><code>cmr \"get rust-compiler \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-gcc/","title":"Detect or install GCC compiler","text":"<p>Automatically generated README for this automation recipe: get-gcc</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/get-gcc/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-gcc/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-gcc/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-gcc/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get gcc compiler c-compiler cpp-compiler get-gcc\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-gcc/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-gcc/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,gcc,compiler,c-compiler,cpp-compiler,get-gcc \n</code></pre>"},{"location":"scripts/Compiler-automation/get-gcc/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get gcc compiler c-compiler cpp-compiler get-gcc \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-gcc/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,gcc,compiler,c-compiler,cpp-compiler,get-gcc'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-gcc/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get gcc compiler c-compiler cpp-compiler get-gcc\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-gcc/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Compiler-automation/get-gcc/#script-output","title":"Script output","text":"<pre><code>cmr \"get gcc compiler c-compiler cpp-compiler get-gcc \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-go/","title":"get-go","text":"<p>Automatically generated README for this automation recipe: get-go</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/get-go/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-go/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-go/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-go/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get tool go get-go\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-go/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/get-go/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,tool,go,get-go \n</code></pre>"},{"location":"scripts/Compiler-automation/get-go/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get tool go get-go \" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-go/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,tool,go,get-go'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-go/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get tool go get-go\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-go/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/get-go/#script-output","title":"Script output","text":"<pre><code>cmr \"get tool go get-go \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/get-llvm/","title":"Detect or install LLVM compiler","text":"<p>Automatically generated README for this automation recipe: get-llvm</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/get-llvm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/get-llvm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/get-llvm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/get-llvm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get llvm compiler c-compiler cpp-compiler get-llvm\" --help</code></p>"},{"location":"scripts/Compiler-automation/get-llvm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/get-llvm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,llvm,compiler,c-compiler,cpp-compiler,get-llvm[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/get-llvm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get llvm compiler c-compiler cpp-compiler get-llvm [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-llvm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,llvm,compiler,c-compiler,cpp-compiler,get-llvm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/get-llvm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get llvm compiler c-compiler cpp-compiler get-llvm[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/get-llvm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_from-prebuilt</code></li> <li><code>_from-src</code></li> </ul>"},{"location":"scripts/Compiler-automation/get-llvm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Compiler-automation/get-llvm/#script-output","title":"Script output","text":"<pre><code>cmr \"get llvm compiler c-compiler cpp-compiler get-llvm [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-gcc-src/","title":"install-gcc-src","text":"<p>Automatically generated README for this automation recipe: install-gcc-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-gcc-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-gcc-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-gcc-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-gcc-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src gcc src-gcc\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-gcc-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/install-gcc-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,gcc,src-gcc \n</code></pre>"},{"location":"scripts/Compiler-automation/install-gcc-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src gcc src-gcc \" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-gcc-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,gcc,src-gcc'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-gcc-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src gcc src-gcc\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-gcc-src/#versions","title":"Versions","text":"<p>Default version: <code>12</code></p> <ul> <li><code>master</code></li> </ul>"},{"location":"scripts/Compiler-automation/install-gcc-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-gcc-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src gcc src-gcc \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/","title":"Build IPEX from sources","text":"<p>Automatically generated README for this automation recipe: install-ipex-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-ipex-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src ipex src-ipex\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,ipex,src-ipex[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src ipex src-ipex [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,ipex,src-ipex'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src ipex src-ipex[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-gptj</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/intel/intel-extension-for-pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/intel/intel-extension-for-pytorch</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/intel/intel-extension-for-pytorch</code></p>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-ipex-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src ipex src-ipex [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/","title":"Install prebuilt LLVM compiler","text":"<p>Automatically generated README for this automation recipe: install-llvm-prebuilt</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install prebuilt llvm prebuilt-llvm install-prebuilt-llvm\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,prebuilt,llvm,prebuilt-llvm,install-prebuilt-llvm \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install prebuilt llvm prebuilt-llvm install-prebuilt-llvm \" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,prebuilt,llvm,prebuilt-llvm,install-prebuilt-llvm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install prebuilt llvm prebuilt-llvm install-prebuilt-llvm\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#versions","title":"Versions","text":"<p>Default version: <code>15.0.6</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-prebuilt/#script-output","title":"Script output","text":"<pre><code>cmr \"install prebuilt llvm prebuilt-llvm install-prebuilt-llvm \"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-src/","title":"Build LLVM compiler from sources (can take &gt;30 min)","text":"<p>Automatically generated README for this automation recipe: install-llvm-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-llvm-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src llvm from.src src-llvm\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-llvm-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,llvm,from.src,src-llvm[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src llvm from.src src-llvm [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,llvm,from.src,src-llvm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src llvm from.src src-llvm[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-llvm-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-bert</code><ul> <li>ENV variables:<ul> <li>CM_LLVM_CONDA_ENV: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-gptj</code><ul> <li>ENV variables:<ul> <li>CM_LLVM_CONDA_ENV: <code>yes</code></li> <li>CM_LLVM_16_INTEL_MLPERF_INFERENCE: <code>yes</code></li> <li>USE_CUDA: <code>0</code></li> <li>CUDA_VISIBLE_DEVICES: ``</li> </ul> </li> </ul> </li> <li><code>_full-history</code></li> <li><code>_runtimes.#</code><ul> <li>ENV variables:<ul> <li>CM_LLVM_ENABLE_RUNTIMES: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"build-type\"      Click here to expand this section. <ul> <li><code>_debug</code><ul> <li>ENV variables:<ul> <li>CM_LLVM_BUILD_TYPE: <code>debug</code></li> </ul> </li> </ul> </li> <li><code>_release</code> (default)<ul> <li>ENV variables:<ul> <li>CM_LLVM_BUILD_TYPE: <code>release</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"clang\"      Click here to expand this section. <ul> <li><code>_clang</code> (default)<ul> <li>ENV variables:<ul> <li>CM_LLVM_ENABLE_PROJECTS: <code>clang</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-llvm-src/#default-variations","title":"Default variations","text":"<p><code>_clang,_release</code></p>"},{"location":"scripts/Compiler-automation/install-llvm-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-llvm-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src llvm from.src src-llvm [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/","title":"Build oneDNN from sources","text":"<p>Automatically generated README for this automation recipe: install-onednn-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-onednn-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src onednn src-onednn\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,onednn,src-onednn[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src onednn src-onednn [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,onednn,src-onednn'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src onednn src-onednn[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-bert</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV: <code>yes</code></li> <li>CM_FOR_INTEL_MLPERF_INFERENCE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/oneapi-src/oneDNN</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/oneapi-src/oneDNN</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/oneapi-src/oneDNN</code></p>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-intel-mlperf-inference.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-onednn-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src onednn src-onednn [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/","title":"Build onnxruntime from sources","text":"<p>Automatically generated README for this automation recipe: install-onnxruntime-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src onnxruntime src-onnxruntime\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,onnxruntime,src-onnxruntime[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src onnxruntime src-onnxruntime [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,onnxruntime,src-onnxruntime'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src onnxruntime src-onnxruntime[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_ONNXRUNTIME_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.https://github.com/Microsoft/onnxruntime</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/Microsoft/onnxruntime</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/Microsoft/onnxruntime</code></p>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-onnxruntime-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src onnxruntime src-onnxruntime [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/","title":"Build pytorch from sources","text":"<p>Automatically generated README for this automation recipe: install-pytorch-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src pytorch src-pytorch\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,pytorch,src-pytorch[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src pytorch src-pytorch [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,pytorch,src-pytorch'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src pytorch src-pytorch[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CUDA_HOME: <code>&lt;&lt;&lt;CM_CUDA_INSTALLED_PATH&gt;&gt;&gt;</code></li> <li>CUDNN_LIBRARY_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_LIB_CUDNN&gt;&gt;&gt;</code></li> <li>CUDNN_INCLUDE_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_INCLUDE_CUDNN&gt;&gt;&gt;</code></li> <li>CUDA_NVCC_EXECUTABLE: <code>&lt;&lt;&lt;CM_NVCC_BIN_WITH_PATH&gt;&gt;&gt;</code></li> <li>USE_CUDA: <code>1</code></li> <li>USE_CUDNN: <code>1</code></li> <li>TORCH_CUDA_ARCH_LIST: <code>Ampere Ada Hopper</code></li> <li>TORCH_CXX_FLAGS: <code>-D_GLIBCXX_USE_CXX11_ABI=1</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-bert</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV: <code>yes</code></li> <li>CM_MLPERF_INFERENCE_INTEL: <code>yes</code></li> <li>USE_CUDA: <code>0</code></li> </ul> </li> </ul> </li> <li><code>_for-nvidia-mlperf-inference-v3.1</code></li> <li><code>_for-nvidia-mlperf-inference-v4.0</code></li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/pytorch/pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/pytorch/pytorch</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/pytorch/pytorch</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-intel-mlperf-inference-v3_1.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-pytorch-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src pytorch src-pytorch [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/","title":"Build pytorch kineto from sources","text":"<p>Automatically generated README for this automation recipe: install-pytorch-kineto-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src pytorch-kineto kineto src-pytorch-kineto\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,pytorch-kineto,kineto,src-pytorch-kineto[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src pytorch-kineto kineto src-pytorch-kineto [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,pytorch-kineto,kineto,src-pytorch-kineto'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src pytorch-kineto kineto src-pytorch-kineto[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CUDA_HOME: <code>&lt;&lt;&lt;CM_CUDA_INSTALLED_PATH&gt;&gt;&gt;</code></li> <li>CUDA_NVCC_EXECUTABLE: <code>&lt;&lt;&lt;CM_NVCC_BIN_WITH_PATH&gt;&gt;&gt;</code></li> <li>CUDNN_INCLUDE_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_INCLUDE_CUDNN&gt;&gt;&gt;</code></li> <li>CUDNN_LIBRARY_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_LIB_CUDNN&gt;&gt;&gt;</code></li> <li>TORCH_CUDA_ARCH_LIST: <code>Ampere Ada Hopper</code></li> <li>TORCH_CXX_FLAGS: <code>-D_GLIBCXX_USE_CXX11_ABI=1</code></li> <li>USE_CUDA: <code>1</code></li> <li>USE_CUDNN: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/pytorch/kineto</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/pytorch/kineto</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/pytorch/kineto</code></p>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-pytorch-kineto-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src pytorch-kineto kineto src-pytorch-kineto [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/","title":"Build pytorchvision from sources","text":"<p>Automatically generated README for this automation recipe: install-torchvision-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src pytorchvision torchvision src-pytorchvision\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,pytorchvision,torchvision,src-pytorchvision[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src pytorchvision torchvision src-pytorchvision [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,pytorchvision,torchvision,src-pytorchvision'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src pytorchvision torchvision src-pytorchvision[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CUDA_HOME: <code>&lt;&lt;&lt;CM_CUDA_INSTALLED_PATH&gt;&gt;&gt;</code></li> <li>CUDA_NVCC_EXECUTABLE: <code>&lt;&lt;&lt;CM_NVCC_BIN_WITH_PATH&gt;&gt;&gt;</code></li> <li>CUDNN_INCLUDE_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_INCLUDE_CUDNN&gt;&gt;&gt;</code></li> <li>CUDNN_LIBRARY_PATH: <code>&lt;&lt;&lt;CM_CUDA_PATH_LIB_CUDNN&gt;&gt;&gt;</code></li> <li>USE_CUDA: <code>1</code></li> <li>USE_CUDNN: <code>1</code></li> <li>TORCH_CUDA_ARCH_LIST: <code>Ampere Ada Hopper</code></li> <li>TORCH_CXX_FLAGS: <code>-D_GLIBCXX_USE_CXX11_ABI=1</code></li> </ul> </li> </ul> </li> <li><code>_for-nvidia-mlperf-inference-v3.1</code></li> <li><code>_for-nvidia-mlperf-inference-v4.0</code></li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/pytorch/vision</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/pytorch/vision</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/pytorch/vision</code></p>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-torchvision-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src pytorchvision torchvision src-pytorchvision [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/","title":"Build TPP-PEX from sources","text":"<p>Automatically generated README for this automation recipe: install-tpp-pytorch-extension</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install get src from.src tpp-pex src-tpp-pex\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,get,src,from.src,tpp-pex,src-tpp-pex[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install get src from.src tpp-pex src-tpp-pex [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,get,src,from.src,tpp-pex,src-tpp-pex'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install get src from.src tpp-pex src-tpp-pex[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-gptj</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/libxsmm/tpp-pytorch-extension</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/libxsmm/tpp-pytorch-extension</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/libxsmm/tpp-pytorch-extension</code></p>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-tpp-pytorch-extension/#script-output","title":"Script output","text":"<pre><code>cmr \"install get src from.src tpp-pex src-tpp-pex [variations]\"  -j\n</code></pre>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/","title":"Build transformers from sources","text":"<p>Automatically generated README for this automation recipe: install-transformers-from-src</p> <p>Category: Compiler automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Compiler-automation/install-transformers-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src from.src transformers src-transformers\" --help</code></p>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,from.src,transformers,src-transformers[,variations] \n</code></pre>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src from.src transformers src-transformers [variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,from.src,transformers,src-transformers'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src from.src transformers src-transformers[variations]\" \n</code></pre>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v3.1-bert</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/pytorch/pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/huggingface/transformers</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/pytorch/pytorch</code></p>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Compiler-automation/install-transformers-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src from.src transformers src-transformers [variations]\"  -j\n</code></pre>"},{"location":"scripts/Dashboard-automation/","title":"Dashboard-automation","text":"<ul> <li>publish-results-to-dashboard</li> </ul>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/","title":"publish-results-to-dashboard","text":"<p>Automatically generated README for this automation recipe: publish-results-to-dashboard</p> <p>Category: Dashboard automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"publish-results dashboard\" --help</code></p>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=publish-results,dashboard \n</code></pre>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"publish-results dashboard \" \n</code></pre>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'publish-results,dashboard'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"publish-results dashboard\" \n</code></pre>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Dashboard-automation/publish-results-to-dashboard/#script-output","title":"Script output","text":"<pre><code>cmr \"publish-results dashboard \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/","title":"Detection-or-installation-of-tools-and-artifacts","text":"<ul> <li>get-android-sdk</li> <li>get-aria2</li> <li>get-bazel</li> <li>get-blis</li> <li>get-brew</li> <li>get-cmake</li> <li>get-cmsis_5</li> <li>get-docker</li> <li>get-generic-sys-util</li> <li>get-google-test</li> <li>get-java</li> <li>get-javac</li> <li>get-lib-armnn</li> <li>get-lib-dnnl</li> <li>get-lib-protobuf</li> <li>get-lib-qaic-api</li> <li>get-nvidia-docker</li> <li>get-openssl</li> <li>get-rclone</li> <li>get-sys-utils-cm</li> <li>get-sys-utils-min</li> <li>get-xilinx-sdk</li> <li>get-zendnn</li> <li>install-bazel</li> <li>install-cmake-prebuilt</li> <li>install-gflags</li> <li>install-github-cli</li> <li>install-intel-neural-speed-from-src</li> <li>install-numactl-from-src</li> <li>install-openssl</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/","title":"get-android-sdk","text":"<p>Automatically generated README for this automation recipe: get-android-sdk</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get android sdk android-sdk\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,android,sdk,android-sdk [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get android sdk android-sdk \" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,android,sdk,android-sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get android sdk android-sdk\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--android_cmake_version=value</code>  \u2192  <code>CM_ANDROID_CMAKE_VERSION=value</code></li> <li><code>--android_ndk_version=value</code>  \u2192  <code>CM_ANDROID_NDK_VERSION=value</code></li> <li><code>--android_version=value</code>  \u2192  <code>CM_ANDROID_VERSION=value</code></li> <li><code>--build_tools_version=value</code>  \u2192  <code>CM_ANDROID_BUILD_TOOLS_VERSION=value</code></li> <li><code>--cmdline_tools_version=value</code>  \u2192  <code>CM_ANDROID_CMDLINE_TOOLS_VERSION=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ANDROID_BUILD_TOOLS_VERSION: <code>29.0.3</code></li> <li>CM_ANDROID_CMAKE_VERSION: <code>3.6.4111459</code></li> <li>CM_ANDROID_CMDLINE_TOOLS_URL: <code>https://dl.google.com/android/repository/commandlinetools-${CM_ANDROID_CMDLINE_TOOLS_OS}-${CM_ANDROID_CMDLINE_TOOLS_VERSION}_latest.zip</code></li> <li>CM_ANDROID_CMDLINE_TOOLS_VERSION: <code>9123335</code></li> <li>CM_ANDROID_NDK_VERSION: <code>21.3.6528147</code></li> <li>CM_ANDROID_VERSION: <code>30</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-android-sdk/#script-output","title":"Script output","text":"<pre><code>cmr \"get android sdk android-sdk \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/","title":"get-aria2","text":"<p>Automatically generated README for this automation recipe: get-aria2</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get aria2 get-aria2\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,aria2,get-aria2 [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get aria2 get-aria2 \" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,aria2,get-aria2'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get aria2 get-aria2\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--install=value</code>  \u2192  <code>CM_FORCE_INSTALL=value</code></li> <li><code>--src=value</code>  \u2192  <code>CM_ARIA2_BUILD_FROM_SRC=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-aria2/#script-output","title":"Script output","text":"<pre><code>cmr \"get aria2 get-aria2 \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/","title":"get-bazel","text":"<p>Automatically generated README for this automation recipe: get-bazel</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get bazel get-bazel\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,bazel,get-bazel \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get bazel get-bazel \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,bazel,get-bazel'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get bazel get-bazel\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-bazel/#script-output","title":"Script output","text":"<pre><code>cmr \"get bazel get-bazel \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/","title":"get-blis","text":"<p>Automatically generated README for this automation recipe: get-blis</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get lib blis\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,lib,blis[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get lib blis [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,lib,blis'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get lib blis[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#variations","title":"Variations","text":"<ul> <li> <p>Group \"source\"      Click here to expand this section. <ul> <li><code>_amd</code></li> <li><code>_flame</code> (default)</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#default-variations","title":"Default variations","text":"<p><code>_flame</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>0.9.0</code></li> <li><code>master</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-blis/#script-output","title":"Script output","text":"<pre><code>cmr \"get lib blis [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/","title":"get-brew","text":"<p>Automatically generated README for this automation recipe: get-brew</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get brew\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,brew \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get brew \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,brew'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get brew\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-brew/#script-output","title":"Script output","text":"<pre><code>cmr \"get brew \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/","title":"get-cmake","text":"<p>Automatically generated README for this automation recipe: get-cmake</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cmake get-cmake\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cmake,get-cmake \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cmake get-cmake \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cmake,get-cmake'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cmake get-cmake\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmake/#script-output","title":"Script output","text":"<pre><code>cmr \"get cmake get-cmake \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/","title":"get-cmsis_5","text":"<p>Automatically generated README for this automation recipe: get-cmsis_5</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get cmsis cmsis_5 arm-software\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,cmsis,cmsis_5,arm-software[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get cmsis cmsis_5 arm-software [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,cmsis,cmsis_5,arm-software'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get cmsis cmsis_5 arm-software[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: <code>--recurse-submodules</code></li> </ul> </li> </ul> </li> <li><code>_short-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 10</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_DEPTH: ``</li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_URL: <code>https://github.com/ARM-software/CMSIS_5.git</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#versions","title":"Versions","text":"<p>Default version: <code>custom</code></p> <ul> <li><code>custom</code></li> <li><code>develop</code></li> <li><code>master</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-cmsis_5/#script-output","title":"Script output","text":"<pre><code>cmr \"get cmsis cmsis_5 arm-software [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/","title":"get-docker","text":"<p>Automatically generated README for this automation recipe: get-docker</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get install docker engine\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,install,docker,engine \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get install docker engine \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,install,docker,engine'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get install docker engine\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-docker/#script-output","title":"Script output","text":"<pre><code>cmr \"get install docker engine \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/","title":"get-generic-sys-util","text":"<p>Automatically generated README for this automation recipe: get-generic-sys-util</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get sys-util generic generic-sys-util\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,sys-util,generic,generic-sys-util[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get sys-util generic generic-sys-util [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,sys-util,generic,generic-sys-util'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get sys-util generic generic-sys-util[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_g++-12</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>g++12</code></li> </ul> </li> </ul> </li> <li><code>_gflags-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>gflags-dev</code></li> </ul> </li> </ul> </li> <li><code>_git-lfs</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>git-lfs</code></li> </ul> </li> </ul> </li> <li><code>_glog-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>glog-dev</code></li> </ul> </li> </ul> </li> <li><code>_libboost-all-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libboost-all-dev</code></li> </ul> </li> </ul> </li> <li><code>_libbz2-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libbz2_dev</code></li> </ul> </li> </ul> </li> <li><code>_libev-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libev_dev</code></li> </ul> </li> </ul> </li> <li><code>_libffi-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libffi_dev</code></li> </ul> </li> </ul> </li> <li><code>_libffi7</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libffi7</code></li> </ul> </li> </ul> </li> <li><code>_libgdbm-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libgdbm_dev</code></li> </ul> </li> </ul> </li> <li><code>_libgmock-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libgmock-dev</code></li> </ul> </li> </ul> </li> <li><code>_liblzma-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>liblzma_dev</code></li> </ul> </li> </ul> </li> <li><code>_libmpfr-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libmpfr-dev</code></li> </ul> </li> </ul> </li> <li><code>_libncurses-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libncurses_dev</code></li> </ul> </li> </ul> </li> <li><code>_libnuma-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libnuma-dev</code></li> </ul> </li> </ul> </li> <li><code>_libpci-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libpci-dev</code></li> </ul> </li> </ul> </li> <li><code>_libre2-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libre2-dev</code></li> </ul> </li> </ul> </li> <li><code>_libreadline-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libreadline_dev</code></li> </ul> </li> </ul> </li> <li><code>_libsqlite3-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libsqlite3_dev</code></li> </ul> </li> </ul> </li> <li><code>_libssl-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libssl_dev</code></li> </ul> </li> </ul> </li> <li><code>_libudev-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>libudev-dev</code></li> </ul> </li> </ul> </li> <li><code>_ninja-build</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>ninja-build</code></li> </ul> </li> </ul> </li> <li><code>_nlohmann-json3-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>nlohmann_json3_dev</code></li> </ul> </li> </ul> </li> <li><code>_ntpdate</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>ntpdate</code></li> </ul> </li> </ul> </li> <li><code>_numactl</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>numactl</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-cuda-toolkit</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>nvidia-cuda-toolkit</code></li> </ul> </li> </ul> </li> <li><code>_rapidjson-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>rapidjson-dev</code></li> </ul> </li> </ul> </li> <li><code>_rsync</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>rsync</code></li> </ul> </li> </ul> </li> <li><code>_screen</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>screen</code></li> </ul> </li> </ul> </li> <li><code>_sox</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>sox</code></li> </ul> </li> </ul> </li> <li><code>_tk-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>tk_dev</code></li> </ul> </li> </ul> </li> <li><code>_transmission</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>transmission</code></li> </ul> </li> </ul> </li> <li><code>_wget</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>wget</code></li> </ul> </li> </ul> </li> <li><code>_zlib</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>zlib</code></li> </ul> </li> </ul> </li> <li><code>_zlib1g-dev</code><ul> <li>ENV variables:<ul> <li>CM_SYS_UTIL_NAME: <code>zlib1g_dev</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_CLEAN_DIRS: <code>bin</code></li> <li>CM_SUDO: <code>sudo</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-generic-sys-util/#script-output","title":"Script output","text":"<pre><code>cmr \"get sys-util generic generic-sys-util [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/","title":"get-google-test","text":"<p>Automatically generated README for this automation recipe: get-google-test</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get google-test googletest gtest test google\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,google-test,googletest,gtest,test,google \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get google-test googletest gtest test google \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,google-test,googletest,gtest,test,google'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get google-test googletest gtest test google\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#versions","title":"Versions","text":"<p>Default version: <code>1.14.0</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-google-test/#script-output","title":"Script output","text":"<pre><code>cmr \"get google-test googletest gtest test google \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/","title":"get-java","text":"<p>Automatically generated README for this automation recipe: get-java</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get java\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,java[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get java [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,java'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get java[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_install</code><ul> <li>ENV variables:<ul> <li>CM_JAVA_PREBUILT_INSTALL: <code>on</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--install=value</code>  \u2192  <code>CM_JAVA_PREBUILT_INSTALL=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_JAVA_PREBUILT_VERSION: <code>19</code></li> <li>CM_JAVA_PREBUILT_BUILD: <code>36</code></li> <li>CM_JAVA_PREBUILT_URL: <code>https://download.java.net/openjdk/jdk${CM_JAVA_PREBUILT_VERSION}/ri/</code></li> <li>CM_JAVA_PREBUILT_FILENAME: <code>openjdk-${CM_JAVA_PREBUILT_VERSION}+${CM_JAVA_PREBUILT_BUILD}_${CM_JAVA_PREBUILT_HOST_OS}-x64_bin</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-java/#script-output","title":"Script output","text":"<pre><code>cmr \"get java [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/","title":"get-javac","text":"<p>Automatically generated README for this automation recipe: get-javac</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get javac\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,javac[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get javac [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,javac'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get javac[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_install</code><ul> <li>ENV variables:<ul> <li>CM_JAVAC_PREBUILT_INSTALL: <code>on</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--install=value</code>  \u2192  <code>CM_JAVAC_PREBUILT_INSTALL=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_JAVAC_PREBUILT_VERSION: <code>19</code></li> <li>CM_JAVAC_PREBUILT_BUILD: <code>36</code></li> <li>CM_JAVAC_PREBUILT_URL: <code>https://download.java.net/openjdk/jdk${CM_JAVAC_PREBUILT_VERSION}/ri/</code></li> <li>CM_JAVAC_PREBUILT_FILENAME: <code>openjdk-${CM_JAVAC_PREBUILT_VERSION}+${CM_JAVAC_PREBUILT_BUILD}_${CM_JAVAC_PREBUILT_HOST_OS}-x64_bin</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-javac/#script-output","title":"Script output","text":"<pre><code>cmr \"get javac [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/","title":"get-lib-armnn","text":"<p>Automatically generated README for this automation recipe: get-lib-armnn</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get lib-armnn lib armnn\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,lib-armnn,lib,armnn \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get lib-armnn lib armnn \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,lib-armnn,lib,armnn'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get lib-armnn lib armnn\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#versions","title":"Versions","text":"<p>Default version: <code>23.11</code></p> <ul> <li><code>22.11</code></li> <li><code>23.05</code></li> <li><code>23.11</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-armnn/#script-output","title":"Script output","text":"<pre><code>cmr \"get lib-armnn lib armnn \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/","title":"get-lib-dnnl","text":"<p>Automatically generated README for this automation recipe: get-lib-dnnl</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get lib-dnnl lib dnnl\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,lib-dnnl,lib,dnnl \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get lib-dnnl lib dnnl \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,lib-dnnl,lib,dnnl'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get lib-dnnl lib dnnl\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#versions","title":"Versions","text":"<p>Default version: <code>dev</code></p> <ul> <li><code>2.2.4</code></li> <li><code>dev</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-dnnl/#script-output","title":"Script output","text":"<pre><code>cmr \"get lib-dnnl lib dnnl \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/","title":"get-lib-protobuf","text":"<p>Automatically generated README for this automation recipe: get-lib-protobuf</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get google-protobuf protobuf lib lib-protobuf google\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,google-protobuf,protobuf,lib,lib-protobuf,google[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get google-protobuf protobuf lib lib-protobuf google [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,google-protobuf,protobuf,lib,lib-protobuf,google'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get google-protobuf protobuf lib lib-protobuf google[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_TMP_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#versions","title":"Versions","text":"<p>Default version: <code>1.13.0</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-protobuf/#script-output","title":"Script output","text":"<pre><code>cmr \"get google-protobuf protobuf lib lib-protobuf google [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/","title":"get-lib-qaic-api","text":"<p>Automatically generated README for this automation recipe: get-lib-qaic-api</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get api lib-qaic-api lib qaic\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,api,lib-qaic-api,lib,qaic \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get api lib-qaic-api lib qaic \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,api,lib-qaic-api,lib,qaic'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get api lib-qaic-api lib qaic\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>master</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-lib-qaic-api/#script-output","title":"Script output","text":"<pre><code>cmr \"get api lib-qaic-api lib qaic \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/","title":"get-nvidia-docker","text":"<p>Automatically generated README for this automation recipe: get-nvidia-docker</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get install nvidia nvidia-container-toolkit nvidia-docker engine\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,install,nvidia,nvidia-container-toolkit,nvidia-docker,engine \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get install nvidia nvidia-container-toolkit nvidia-docker engine \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,install,nvidia,nvidia-container-toolkit,nvidia-docker,engine'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get install nvidia nvidia-container-toolkit nvidia-docker engine\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-nvidia-docker/#script-output","title":"Script output","text":"<pre><code>cmr \"get install nvidia nvidia-container-toolkit nvidia-docker engine \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/","title":"get-openssl","text":"<p>Automatically generated README for this automation recipe: get-openssl</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get openssl lib lib-openssl\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,openssl,lib,lib-openssl \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get openssl lib lib-openssl \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,openssl,lib,lib-openssl'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get openssl lib lib-openssl\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-openssl/#script-output","title":"Script output","text":"<pre><code>cmr \"get openssl lib lib-openssl \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/","title":"get-rclone","text":"<p>Automatically generated README for this automation recipe: get-rclone</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get rclone\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,rclone[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get rclone [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,rclone'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get rclone[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_gdrive</code><ul> <li>ENV variables:<ul> <li>CM_RCLONE_GDRIVE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_system</code><ul> <li>ENV variables:<ul> <li>CM_RCLONE_SYSTEM: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#versions","title":"Versions","text":"<p>Default version: <code>1.65.2</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-rclone/#script-output","title":"Script output","text":"<pre><code>cmr \"get rclone [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/","title":"get-sys-utils-cm","text":"<p>Automatically generated README for this automation recipe: get-sys-utils-cm</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get sys-utils-cm\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,sys-utils-cm[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get sys-utils-cm [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,sys-utils-cm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get sys-utils-cm[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_user</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_PIP_USER: <code>--user</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--skip=value</code>  \u2192  <code>CM_SKIP_SYS_UTILS=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-arch.sh</li> <li>run-debian.sh</li> <li>run-macos.sh</li> <li>run-rhel.sh</li> <li>run-sles.sh</li> <li>run-ubuntu.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-cm/#script-output","title":"Script output","text":"<pre><code>cmr \"get sys-utils-cm [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/","title":"get-sys-utils-min","text":"<p>Automatically generated README for this automation recipe: get-sys-utils-min</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get sys-utils-min\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,sys-utils-min \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get sys-utils-min \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,sys-utils-min'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get sys-utils-min\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-sys-utils-min/#script-output","title":"Script output","text":"<pre><code>cmr \"get sys-utils-min \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/","title":"get-xilinx-sdk","text":"<p>Automatically generated README for this automation recipe: get-xilinx-sdk</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get xilinx sdk\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,xilinx,sdk [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get xilinx sdk \" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,xilinx,sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get xilinx sdk\" [--input_flags]\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_XILINX_SDK_FILE_PATH=value</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#versions","title":"Versions","text":"<p>Default version: <code>2019.1</code></p> <ul> <li><code>2019.1</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-xilinx-sdk/#script-output","title":"Script output","text":"<pre><code>cmr \"get xilinx sdk \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/","title":"get-zendnn","text":"<p>Automatically generated README for this automation recipe: get-zendnn</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get zendnn amd from.src\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,zendnn,amd,from.src \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get zendnn amd from.src \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,zendnn,amd,from.src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get zendnn amd from.src\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/get-zendnn/#script-output","title":"Script output","text":"<pre><code>cmr \"get zendnn amd from.src \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/","title":"install-bazel","text":"<p>Automatically generated README for this automation recipe: install-bazel</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install script bazel\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,script,bazel \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install script bazel \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,script,bazel'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install script bazel\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#versions","title":"Versions","text":"<p>Default version: <code>7.0.2</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-aarch64.sh</li> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-bazel/#script-output","title":"Script output","text":"<pre><code>cmr \"install script bazel \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/","title":"install-cmake-prebuilt","text":"<p>Automatically generated README for this automation recipe: install-cmake-prebuilt</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install prebuilt cmake prebuilt-cmake install-prebuilt-cmake\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,prebuilt,cmake,prebuilt-cmake,install-prebuilt-cmake \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install prebuilt cmake prebuilt-cmake install-prebuilt-cmake \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,prebuilt,cmake,prebuilt-cmake,install-prebuilt-cmake'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install prebuilt cmake prebuilt-cmake install-prebuilt-cmake\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#versions","title":"Versions","text":"<p>Default version: <code>3.28.3</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-cmake-prebuilt/#script-output","title":"Script output","text":"<pre><code>cmr \"install prebuilt cmake prebuilt-cmake install-prebuilt-cmake \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/","title":"install-gflags","text":"<p>Automatically generated README for this automation recipe: install-gflags</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src get gflags\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,get,gflags \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src get gflags \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,get,gflags'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src get gflags\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#versions","title":"Versions","text":"<p>Default version: <code>2.2.2</code></p> <ul> <li><code>2.2.2</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-gflags/#script-output","title":"Script output","text":"<pre><code>cmr \"install src get gflags \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/","title":"install-github-cli","text":"<p>Automatically generated README for this automation recipe: install-github-cli</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install gh github cli github-cli\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,gh,github,cli,github-cli \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install gh github cli github-cli \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,gh,github,cli,github-cli'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install gh github cli github-cli\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-macos.sh</li> <li>run-rhel.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-github-cli/#script-output","title":"Script output","text":"<pre><code>cmr \"install gh github cli github-cli \"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/","title":"Build Intel Neural Speed from sources","text":"<p>Automatically generated README for this automation recipe: install-intel-neural-speed-from-src</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src from.src neural-speed intel-neural-speed\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,from.src,neural-speed,intel-neural-speed[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src from.src neural-speed intel-neural-speed [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,from.src,neural-speed,intel-neural-speed'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src from.src neural-speed intel-neural-speed[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_for-intel-mlperf-inference-v4.0-gptj</code></li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/intel/neural-speed</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/intel/neural-speed</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/intel/neural-speed</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-intel-neural-speed-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src from.src neural-speed intel-neural-speed [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/","title":"Build numactl from sources","text":"<p>Automatically generated README for this automation recipe: install-numactl-from-src</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src from.src numactl src-numactl\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,from.src,numactl,src-numactl[,variations] \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src from.src numactl src-numactl [variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,from.src,numactl,src-numactl'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src from.src numactl src-numactl[variations]\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_repo.https://github.com/numactl/numactl</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/numactl/numactl</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#default-variations","title":"Default variations","text":"<p><code>_repo.https://github.com/numactl/numactl</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-numactl-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src from.src numactl src-numactl [variations]\"  -j\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/","title":"install-openssl","text":"<p>Automatically generated README for this automation recipe: install-openssl</p> <p>Category: Detection or installation of tools and artifacts</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src openssl openssl-lib\" --help</code></p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,openssl,openssl-lib \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src openssl openssl-lib \" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,openssl,openssl-lib'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src openssl openssl-lib\" \n</code></pre>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#versions","title":"Versions","text":"<p>Default version: <code>1.1.1</code></p> <ul> <li><code>1.1.1</code></li> </ul>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Detection-or-installation-of-tools-and-artifacts/install-openssl/#script-output","title":"Script output","text":"<pre><code>cmr \"install src openssl openssl-lib \"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/","title":"DevOps-automation","text":"<ul> <li>benchmark-program</li> <li>compile-program</li> <li>convert-csv-to-md</li> <li>copy-to-clipboard</li> <li>create-conda-env</li> <li>create-patch</li> <li>detect-sudo</li> <li>download-and-extract</li> <li>download-file</li> <li>download-torrent</li> <li>extract-file</li> <li>fail</li> <li>get-conda</li> <li>get-git-repo</li> <li>get-github-cli</li> <li>pull-git-repo</li> <li>push-csv-to-spreadsheet</li> <li>set-device-settings-qaic</li> <li>set-echo-off-win</li> <li>set-performance-mode</li> <li>set-sqlite-dir</li> <li>tar-my-folder</li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/","title":"benchmark-program","text":"<p>Automatically generated README for this automation recipe: benchmark-program</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/benchmark-program/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/benchmark-program/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"benchmark program\" --help</code></p>"},{"location":"scripts/DevOps-automation/benchmark-program/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/DevOps-automation/benchmark-program/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=benchmark,program[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/benchmark-program/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"benchmark program [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/benchmark-program/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'benchmark,program'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/benchmark-program/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"benchmark program[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/benchmark-program/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_numactl</code></li> <li><code>_numactl-interleave</code></li> <li><code>_profile</code></li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ENABLE_NUMACTL: <code>0</code></li> <li>CM_ENABLE_PROFILING: <code>0</code></li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/benchmark-program/#script-output","title":"Script output","text":"<pre><code>cmr \"benchmark program [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/compile-program/","title":"compile-program","text":"<p>Automatically generated README for this automation recipe: compile-program</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/compile-program/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/compile-program/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/compile-program/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/compile-program/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"compile program c-program cpp-program compile-program compile-c-program compile-cpp-program\" --help</code></p>"},{"location":"scripts/DevOps-automation/compile-program/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/DevOps-automation/compile-program/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=compile,program,c-program,cpp-program,compile-program,compile-c-program,compile-cpp-program \n</code></pre>"},{"location":"scripts/DevOps-automation/compile-program/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"compile program c-program cpp-program compile-program compile-c-program compile-cpp-program \" \n</code></pre>"},{"location":"scripts/DevOps-automation/compile-program/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'compile,program,c-program,cpp-program,compile-program,compile-c-program,compile-cpp-program'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/compile-program/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"compile program c-program cpp-program compile-program compile-c-program compile-cpp-program\" \n</code></pre>"},{"location":"scripts/DevOps-automation/compile-program/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>SKIP_RECOMPILE: <code>no</code></li> </ul>"},{"location":"scripts/DevOps-automation/compile-program/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/compile-program/#script-output","title":"Script output","text":"<pre><code>cmr \"compile program c-program cpp-program compile-program compile-c-program compile-cpp-program \"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/","title":"convert-csv-to-md","text":"<p>Automatically generated README for this automation recipe: convert-csv-to-md</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/convert-csv-to-md/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"csv-to-md convert to-md from-csv\" --help</code></p>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=csv-to-md,convert,to-md,from-csv [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"csv-to-md convert to-md from-csv \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'csv-to-md,convert,to-md,from-csv'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"csv-to-md convert to-md from-csv\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--csv_file=value</code>  \u2192  <code>CM_CSV_FILE=value</code></li> <li><code>--md_file=value</code>  \u2192  <code>CM_MD_FILE=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/convert-csv-to-md/#script-output","title":"Script output","text":"<pre><code>cmr \"csv-to-md convert to-md from-csv \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/","title":"copy-to-clipboard","text":"<p>Automatically generated README for this automation recipe: copy-to-clipboard</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/copy-to-clipboard/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"copy to clipboard copy-to-clipboard\" --help</code></p>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=copy,to,clipboard,copy-to-clipboard [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"copy to clipboard copy-to-clipboard \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'copy,to,clipboard,copy-to-clipboard'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"copy to clipboard copy-to-clipboard\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--add_quotes=value</code>  \u2192  <code>CM_COPY_TO_CLIPBOARD_TEXT_ADD_QUOTES=value</code></li> <li><code>--q=value</code>  \u2192  <code>CM_COPY_TO_CLIPBOARD_TEXT_ADD_QUOTES=value</code></li> <li><code>--t=value</code>  \u2192  <code>CM_COPY_TO_CLIPBOARD_TEXT=value</code></li> <li><code>--text=value</code>  \u2192  <code>CM_COPY_TO_CLIPBOARD_TEXT=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/copy-to-clipboard/#script-output","title":"Script output","text":"<pre><code>cmr \"copy to clipboard copy-to-clipboard \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/create-conda-env/","title":"create-conda-env","text":"<p>Automatically generated README for this automation recipe: create-conda-env</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/create-conda-env/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/create-conda-env/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/create-conda-env/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/create-conda-env/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"create get env conda-env conda-environment create-conda-environment\" --help</code></p>"},{"location":"scripts/DevOps-automation/create-conda-env/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/DevOps-automation/create-conda-env/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=create,get,env,conda-env,conda-environment,create-conda-environment[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/create-conda-env/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"create get env conda-env conda-environment create-conda-environment [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/create-conda-env/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'create,get,env,conda-env,conda-environment,create-conda-environment'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/create-conda-env/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"create get env conda-env conda-environment create-conda-environment[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/create-conda-env/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_name.#</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_ENV_NAME: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/create-conda-env/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/create-conda-env/#script-output","title":"Script output","text":"<pre><code>cmr \"create get env conda-env conda-environment create-conda-environment [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/create-patch/","title":"create-patch","text":"<p>Automatically generated README for this automation recipe: create-patch</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/create-patch/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/create-patch/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/create-patch/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/create-patch/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"create patch\" --help</code></p>"},{"location":"scripts/DevOps-automation/create-patch/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/create-patch/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=create,patch [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/create-patch/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"create patch \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/create-patch/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'create,patch'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/create-patch/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"create patch\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/create-patch/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--exclude=value</code>  \u2192  <code>CM_CREATE_PATCH_EXCLUDE=value</code></li> <li><code>--new=value</code>  \u2192  <code>CM_CREATE_PATCH_NEW=value</code></li> <li><code>--old=value</code>  \u2192  <code>CM_CREATE_PATCH_OLD=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/create-patch/#script-output","title":"Script output","text":"<pre><code>cmr \"create patch \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/detect-sudo/","title":"detect-sudo","text":"<p>Automatically generated README for this automation recipe: detect-sudo</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/detect-sudo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/detect-sudo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/detect-sudo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/detect-sudo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"detect sudo access\" --help</code></p>"},{"location":"scripts/DevOps-automation/detect-sudo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/DevOps-automation/detect-sudo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=detect,sudo,access \n</code></pre>"},{"location":"scripts/DevOps-automation/detect-sudo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"detect sudo access \" \n</code></pre>"},{"location":"scripts/DevOps-automation/detect-sudo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'detect,sudo,access'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/detect-sudo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"detect sudo access\" \n</code></pre>"},{"location":"scripts/DevOps-automation/detect-sudo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/detect-sudo/#script-output","title":"Script output","text":"<pre><code>cmr \"detect sudo access \"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/download-and-extract/","title":"download-and-extract","text":"<p>Automatically generated README for this automation recipe: download-and-extract</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/download-and-extract/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/download-and-extract/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/download-and-extract/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/download-and-extract/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"download-and-extract file\" --help</code></p>"},{"location":"scripts/DevOps-automation/download-and-extract/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/DevOps-automation/download-and-extract/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=download-and-extract,file[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-and-extract/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"download-and-extract file [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-and-extract/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'download-and-extract,file'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/download-and-extract/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"download-and-extract file[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-and-extract/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_extract</code><ul> <li>ENV variables:<ul> <li>CM_DAE_EXTRACT_DOWNLOADED: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_keep</code><ul> <li>ENV variables:<ul> <li>CM_EXTRACT_REMOVE_EXTRACTED: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_no-remove-extracted</code><ul> <li>ENV variables:<ul> <li>CM_EXTRACT_REMOVE_EXTRACTED: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_url.#</code><ul> <li>ENV variables:<ul> <li>CM_DAE_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-tool\"      Click here to expand this section. <ul> <li><code>_cmutil</code> (default)</li> <li><code>_curl</code></li> <li><code>_gdown</code></li> <li><code>_rclone</code></li> <li><code>_torrent</code><ul> <li>ENV variables:<ul> <li>CM_DAE_DOWNLOAD_USING_TORRENT: <code>yes</code></li> <li>CM_TORRENT_DOWNLOADED_FILE_NAME: <code>&lt;&lt;&lt;CM_DAE_FILENAME&gt;&gt;&gt;</code></li> <li>CM_TORRENT_DOWNLOADED_PATH_ENV_KEY: <code>CM_DAE_FILEPATH</code></li> <li>CM_TORRENT_WAIT_UNTIL_COMPLETED: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_wget</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-and-extract/#default-variations","title":"Default variations","text":"<p><code>_cmutil</code></p>"},{"location":"scripts/DevOps-automation/download-and-extract/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--extra_folder=value</code>  \u2192  <code>CM_EXTRACT_TO_FOLDER=value</code></li> <li><code>--extract_path=value</code>  \u2192  <code>CM_EXTRACT_PATH=value</code></li> <li><code>--from=value</code>  \u2192  <code>CM_DOWNLOAD_LOCAL_FILE_PATH=value</code></li> <li><code>--local_path=value</code>  \u2192  <code>CM_DOWNLOAD_LOCAL_FILE_PATH=value</code></li> <li><code>--store=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_EXTRACT_PATH=value</code></li> <li><code>--url=value</code>  \u2192  <code>CM_DAE_URL=value</code></li> <li><code>--verify=value</code>  \u2192  <code>CM_VERIFY_SSL=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-and-extract/#script-output","title":"Script output","text":"<pre><code>cmr \"download-and-extract file [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/download-file/","title":"download-file","text":"<p>Automatically generated README for this automation recipe: download-file</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/download-file/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/download-file/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"download file\" --help</code></p>"},{"location":"scripts/DevOps-automation/download-file/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/DevOps-automation/download-file/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=download,file[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-file/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"download file [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-file/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'download,file'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/download-file/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"download file[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-file/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_url.#</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"download-tool\"      Click here to expand this section. <ul> <li><code>_cmutil</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>cmutil</code></li> </ul> </li> </ul> </li> <li><code>_curl</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>curl</code></li> </ul> </li> </ul> </li> <li><code>_gdown</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>gdown</code></li> </ul> </li> </ul> </li> <li><code>_rclone</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>rclone</code></li> </ul> </li> </ul> </li> <li><code>_wget</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_TOOL: <code>wget</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#default-variations","title":"Default variations","text":"<p><code>_cmutil</code></p>"},{"location":"scripts/DevOps-automation/download-file/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--download_path=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--from=value</code>  \u2192  <code>CM_DOWNLOAD_LOCAL_FILE_PATH=value</code></li> <li><code>--local_path=value</code>  \u2192  <code>CM_DOWNLOAD_LOCAL_FILE_PATH=value</code></li> <li><code>--md5sum=value</code>  \u2192  <code>CM_DOWNLOAD_CHECKSUM=value</code></li> <li><code>--output_file=value</code>  \u2192  <code>CM_DOWNLOAD_FILENAME=value</code></li> <li><code>--store=value</code>  \u2192  <code>CM_DOWNLOAD_PATH=value</code></li> <li><code>--url=value</code>  \u2192  <code>CM_DOWNLOAD_URL=value</code></li> <li><code>--verify=value</code>  \u2192  <code>CM_VERIFY_SSL=value</code></li> <li><code>--verify_ssl=value</code>  \u2192  <code>CM_VERIFY_SSL=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_RCLONE_COPY_USING: <code>sync</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/download-file/#script-output","title":"Script output","text":"<pre><code>cmr \"download file [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/download-torrent/","title":"download-torrent","text":"<p>Automatically generated README for this automation recipe: download-torrent</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/download-torrent/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/download-torrent/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/download-torrent/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/download-torrent/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"download torrent download-torrent\" --help</code></p>"},{"location":"scripts/DevOps-automation/download-torrent/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/DevOps-automation/download-torrent/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=download,torrent,download-torrent[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-torrent/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"download torrent download-torrent [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-torrent/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'download,torrent,download-torrent'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/download-torrent/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"download torrent download-torrent[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/download-torrent/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_torrent.#</code><ul> <li>ENV variables:<ul> <li>CM_TORRENT_FILE: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/download-torrent/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--wait=value</code>  \u2192  <code>CM_TORRENT_WAIT_UNTIL_COMPLETED=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-torrent/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_TORRENT_WAIT_UNTIL_COMPLETED: <code>no</code></li> </ul>"},{"location":"scripts/DevOps-automation/download-torrent/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/download-torrent/#script-output","title":"Script output","text":"<pre><code>cmr \"download torrent download-torrent [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/extract-file/","title":"extract-file","text":"<p>Automatically generated README for this automation recipe: extract-file</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/extract-file/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/extract-file/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/extract-file/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/extract-file/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"extract file\" --help</code></p>"},{"location":"scripts/DevOps-automation/extract-file/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/DevOps-automation/extract-file/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=extract,file[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/extract-file/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"extract file [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/extract-file/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'extract,file'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/extract-file/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"extract file[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/extract-file/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_keep</code><ul> <li>ENV variables:<ul> <li>CM_EXTRACT_REMOVE_EXTRACTED: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_no-remove-extracted</code><ul> <li>ENV variables:<ul> <li>CM_EXTRACT_REMOVE_EXTRACTED: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_path.#</code><ul> <li>ENV variables:<ul> <li>CM_EXTRACT_FILEPATH: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/extract-file/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--extra_folder=value</code>  \u2192  <code>CM_EXTRACT_TO_FOLDER=value</code></li> <li><code>--extract_path=value</code>  \u2192  <code>CM_EXTRACT_PATH=value</code></li> <li><code>--input=value</code>  \u2192  <code>CM_EXTRACT_FILEPATH=value</code></li> <li><code>--to=value</code>  \u2192  <code>CM_EXTRACT_PATH=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/extract-file/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/extract-file/#script-output","title":"Script output","text":"<pre><code>cmr \"extract file [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/fail/","title":"fail","text":"<p>Automatically generated README for this automation recipe: fail</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/fail/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/fail/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/fail/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/fail/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"fail filter\" --help</code></p>"},{"location":"scripts/DevOps-automation/fail/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/DevOps-automation/fail/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=fail,filter[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/fail/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"fail filter [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/fail/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'fail,filter'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/fail/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"fail filter[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/fail/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_windows</code><ul> <li>ENV variables:<ul> <li>CM_FAIL_WINDOWS: <code>True</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/fail/#script-output","title":"Script output","text":"<pre><code>cmr \"fail filter [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/get-conda/","title":"get-conda","text":"<p>Automatically generated README for this automation recipe: get-conda</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/get-conda/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/get-conda/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/get-conda/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/get-conda/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get conda get-conda\" --help</code></p>"},{"location":"scripts/DevOps-automation/get-conda/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/DevOps-automation/get-conda/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,conda,get-conda[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/get-conda/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get conda get-conda [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/get-conda/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,conda,get-conda'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/get-conda/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get conda get-conda[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/get-conda/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_name.#</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_PREFIX_NAME: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"conda-python\"      Click here to expand this section. <ul> <li><code>_python-3.#</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_PYTHON_VERSION: <code>3.#</code></li> </ul> </li> </ul> </li> <li><code>_python-3.8</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_PYTHON_VERSION: <code>3.8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/get-conda/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/get-conda/#script-output","title":"Script output","text":"<pre><code>cmr \"get conda get-conda [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/get-git-repo/","title":"get-git-repo","text":"<p>Automatically generated README for this automation recipe: get-git-repo</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/get-git-repo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/get-git-repo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get git repo repository clone\" --help</code></p>"},{"location":"scripts/DevOps-automation/get-git-repo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/DevOps-automation/get-git-repo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,git,repo,repository,clone[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/get-git-repo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get git repo repository clone [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/get-git-repo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,git,repo,repository,clone'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/get-git-repo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get git repo repository clone[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/get-git-repo/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_lfs</code><ul> <li>ENV variables:<ul> <li>CM_GIT_REPO_NEEDS_LFS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_no-recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> </ul> </li> </ul> </li> <li><code>_patch</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_submodules.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SUBMODULES: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"checkout\"      Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_BRANCH: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"git-history\"      Click here to expand this section. <ul> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: ``</li> </ul> </li> </ul> </li> <li><code>_short-history</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 5</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#default-variations","title":"Default variations","text":"<p><code>_short-history</code></p>"},{"location":"scripts/DevOps-automation/get-git-repo/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--branch=value</code>  \u2192  <code>CM_GIT_CHECKOUT=value</code></li> <li><code>--depth=value</code>  \u2192  <code>CM_GIT_DEPTH=value</code></li> <li><code>--env_key=value</code>  \u2192  <code>CM_GIT_ENV_KEY=value</code></li> <li><code>--folder=value</code>  \u2192  <code>CM_GIT_CHECKOUT_FOLDER=value</code></li> <li><code>--patch=value</code>  \u2192  <code>CM_GIT_PATCH=value</code></li> <li><code>--pull=value</code>  \u2192  <code>CM_GIT_REPO_PULL=value</code></li> <li><code>--submodules=value</code>  \u2192  <code>CM_GIT_RECURSE_SUBMODULES=value</code></li> <li><code>--update=value</code>  \u2192  <code>CM_GIT_REPO_PULL=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_DEPTH: <code>--depth 4</code></li> <li>CM_GIT_CHECKOUT_FOLDER: <code>repo</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: <code>--recurse-submodules</code></li> <li>CM_GIT_URL: <code>https://github.com/mlcommons/ck.git</code></li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/get-git-repo/#script-output","title":"Script output","text":"<pre><code>cmr \"get git repo repository clone [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/get-github-cli/","title":"get-github-cli","text":"<p>Automatically generated README for this automation recipe: get-github-cli</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/get-github-cli/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/get-github-cli/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/get-github-cli/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/get-github-cli/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get gh gh-cli github cli github-cli\" --help</code></p>"},{"location":"scripts/DevOps-automation/get-github-cli/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/DevOps-automation/get-github-cli/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,gh,gh-cli,github,cli,github-cli \n</code></pre>"},{"location":"scripts/DevOps-automation/get-github-cli/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get gh gh-cli github cli github-cli \" \n</code></pre>"},{"location":"scripts/DevOps-automation/get-github-cli/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,gh,gh-cli,github,cli,github-cli'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/get-github-cli/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get gh gh-cli github cli github-cli\" \n</code></pre>"},{"location":"scripts/DevOps-automation/get-github-cli/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/get-github-cli/#script-output","title":"Script output","text":"<pre><code>cmr \"get gh gh-cli github cli github-cli \"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/pull-git-repo/","title":"pull-git-repo","text":"<p>Automatically generated README for this automation recipe: pull-git-repo</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/pull-git-repo/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/pull-git-repo/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/pull-git-repo/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/pull-git-repo/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"pull git repo repository\" --help</code></p>"},{"location":"scripts/DevOps-automation/pull-git-repo/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/pull-git-repo/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=pull,git,repo,repository [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/pull-git-repo/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"pull git repo repository \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/pull-git-repo/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'pull,git,repo,repository'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/pull-git-repo/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"pull git repo repository\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/pull-git-repo/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--path=value</code>  \u2192  <code>CM_GIT_CHECKOUT_PATH=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/pull-git-repo/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/pull-git-repo/#script-output","title":"Script output","text":"<pre><code>cmr \"pull git repo repository \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/","title":"push-csv-to-spreadsheet","text":"<p>Automatically generated README for this automation recipe: push-csv-to-spreadsheet</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"push google-spreadsheet spreadsheet push-to-google-spreadsheet\" --help</code></p>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=push,google-spreadsheet,spreadsheet,push-to-google-spreadsheet [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"push google-spreadsheet spreadsheet push-to-google-spreadsheet \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'push,google-spreadsheet,spreadsheet,push-to-google-spreadsheet'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"push google-spreadsheet spreadsheet push-to-google-spreadsheet\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--csv_file=value</code>  \u2192  <code>CM_CSV_FILE_PATH=value</code></li> <li><code>--sheet_name=value</code>  \u2192  <code>CM_GOOGLE_SHEET_NAME=value</code></li> <li><code>--spreadsheet_id=value</code>  \u2192  <code>CM_GOOGLE_SPREADSHEET_ID=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GOOGLE_SPREADSHEET_ID: <code>1gMHjXmFmwZR4-waPPyxy5Pc3VARqX3kKUWxkP97Xa6Y</code></li> </ul>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/push-csv-to-spreadsheet/#script-output","title":"Script output","text":"<pre><code>cmr \"push google-spreadsheet spreadsheet push-to-google-spreadsheet \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/","title":"set-device-settings-qaic","text":"<p>Automatically generated README for this automation recipe: set-device-settings-qaic</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"set device qaic ai100 cloud performance power setting mode vc ecc\" --help</code></p>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=set,device,qaic,ai100,cloud,performance,power,setting,mode,vc,ecc[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"set device qaic ai100 cloud performance power setting mode vc ecc [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'set,device,qaic,ai100,cloud,performance,power,setting,mode,vc,ecc'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"set device qaic ai100 cloud performance power setting mode vc ecc[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_ecc</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_ECC: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_vc.#</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_VC: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_QAIC_DEVICES: <code>0</code></li> </ul>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/DevOps-automation/set-device-settings-qaic/#script-output","title":"Script output","text":"<pre><code>cmr \"set device qaic ai100 cloud performance power setting mode vc ecc [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/set-echo-off-win/","title":"set-echo-off-win","text":"<p>Automatically generated README for this automation recipe: set-echo-off-win</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/set-echo-off-win/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"set echo off win echo-off-win echo-off\" --help</code></p>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/DevOps-automation/set-echo-off-win/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=set,echo,off,win,echo-off-win,echo-off \n</code></pre>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"set echo off win echo-off-win echo-off \" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'set,echo,off,win,echo-off-win,echo-off'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"set echo off win echo-off-win echo-off\" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-echo-off-win/#script-output","title":"Script output","text":"<pre><code>cmr \"set echo off win echo-off-win echo-off \"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/set-performance-mode/","title":"set-performance-mode","text":"<p>Automatically generated README for this automation recipe: set-performance-mode</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/set-performance-mode/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/set-performance-mode/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/set-performance-mode/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/set-performance-mode/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"set system performance power mode\" --help</code></p>"},{"location":"scripts/DevOps-automation/set-performance-mode/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/DevOps-automation/set-performance-mode/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=set,system,performance,power,mode[,variations] \n</code></pre>"},{"location":"scripts/DevOps-automation/set-performance-mode/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"set system performance power mode [variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-performance-mode/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'set,system,performance,power,mode'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/set-performance-mode/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"set system performance power mode[variations]\" \n</code></pre>"},{"location":"scripts/DevOps-automation/set-performance-mode/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_reproducibility</code><ul> <li>ENV variables:<ul> <li>CM_SET_OS_PERFORMANCE_REPRODUCIBILITY_MODE: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_SET_PERFORMANCE_MODE_OF: <code>cpu</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"performance-mode\"      Click here to expand this section. <ul> <li><code>_performance</code> (default)<ul> <li>ENV variables:<ul> <li>CM_SET_PERFORMANCE_MODE: <code>performance</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"power\"      Click here to expand this section. <ul> <li><code>_power</code><ul> <li>ENV variables:<ul> <li>CM_SET_PERFORMANCE_MODE: <code>power</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/DevOps-automation/set-performance-mode/#default-variations","title":"Default variations","text":"<p><code>_cpu,_performance</code></p>"},{"location":"scripts/DevOps-automation/set-performance-mode/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/set-performance-mode/#script-output","title":"Script output","text":"<pre><code>cmr \"set system performance power mode [variations]\"  -j\n</code></pre>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/","title":"set-sqlite-dir","text":"<p>Automatically generated README for this automation recipe: set-sqlite-dir</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/set-sqlite-dir/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"set sqlite dir sqlite-dir\" --help</code></p>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=set,sqlite,dir,sqlite-dir [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"set sqlite dir sqlite-dir \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'set,sqlite,dir,sqlite-dir'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"set sqlite dir sqlite-dir\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--path=value</code>  \u2192  <code>CM_SQLITE_PATH=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/DevOps-automation/set-sqlite-dir/#script-output","title":"Script output","text":"<pre><code>cmr \"set sqlite dir sqlite-dir \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/DevOps-automation/tar-my-folder/","title":"tar-my-folder","text":"<p>Automatically generated README for this automation recipe: tar-my-folder</p> <p>Category: DevOps automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/DevOps-automation/tar-my-folder/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/DevOps-automation/tar-my-folder/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/DevOps-automation/tar-my-folder/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/DevOps-automation/tar-my-folder/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run tar\" --help</code></p>"},{"location":"scripts/DevOps-automation/tar-my-folder/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/DevOps-automation/tar-my-folder/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,tar [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/tar-my-folder/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run tar \" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/tar-my-folder/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,tar'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/DevOps-automation/tar-my-folder/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run tar\" [--input_flags]\n</code></pre>"},{"location":"scripts/DevOps-automation/tar-my-folder/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input_dir=value</code>  \u2192  <code>CM_TAR_INPUT_DIR=value</code></li> <li><code>--outfile=value</code>  \u2192  <code>CM_TAR_OUTFILE=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_TAR_OUTPUT_DIR=value</code></li> </ul>"},{"location":"scripts/DevOps-automation/tar-my-folder/#script-output","title":"Script output","text":"<pre><code>cmr \"run tar \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Docker-automation/","title":"Docker-automation","text":"<ul> <li>build-docker-image</li> <li>build-dockerfile</li> <li>prune-docker</li> <li>run-docker-container</li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/","title":"build-docker-image","text":"<p>Automatically generated README for this automation recipe: build-docker-image</p> <p>Category: Docker automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Docker-automation/build-docker-image/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Docker-automation/build-docker-image/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"build docker image docker-image dockerimage\" --help</code></p>"},{"location":"scripts/Docker-automation/build-docker-image/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/Docker-automation/build-docker-image/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=build,docker,image,docker-image,dockerimage [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-docker-image/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"build docker image docker-image dockerimage \" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-docker-image/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'build,docker,image,docker-image,dockerimage'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Docker-automation/build-docker-image/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"build docker image docker-image dockerimage\" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-docker-image/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--cache=value</code>  \u2192  <code>CM_DOCKER_CACHE=value</code></li> <li><code>--cm_repo=value</code>  \u2192  <code>CM_MLOPS_REPO=value</code></li> <li><code>--docker_os=value</code>  \u2192  <code>CM_DOCKER_OS=value</code></li> <li><code>--docker_os_version=value</code>  \u2192  <code>CM_DOCKER_OS_VERSION=value</code></li> <li><code>--dockerfile=value</code>  \u2192  <code>CM_DOCKERFILE_WITH_PATH=value</code></li> <li><code>--gh_token=value</code>  \u2192  <code>CM_GH_TOKEN=value</code></li> <li><code>--image_name=value</code>  \u2192  <code>CM_DOCKER_IMAGE_NAME=value</code></li> <li><code>--image_repo=value</code>  \u2192  <code>CM_DOCKER_IMAGE_REPO=value</code></li> <li><code>--image_tag=value</code>  \u2192  <code>CM_DOCKER_IMAGE_TAG=value</code></li> <li><code>--post_run_cmds=value</code>  \u2192  <code>CM_DOCKER_POST_RUN_COMMANDS=value</code></li> <li><code>--pre_run_cmds=value</code>  \u2192  <code>CM_DOCKER_PRE_RUN_COMMANDS=value</code></li> <li><code>--push_image=value</code>  \u2192  <code>CM_DOCKER_PUSH_IMAGE=value</code></li> <li><code>--real_run=value</code>  \u2192  <code>CM_REAL_RUN=value</code></li> <li><code>--script_tags=value</code>  \u2192  <code>CM_DOCKER_RUN_SCRIPT_TAGS=value</code></li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DOCKER_IMAGE_REPO: <code>local</code></li> <li>CM_DOCKER_IMAGE_TAG: <code>latest</code></li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Docker-automation/build-docker-image/#script-output","title":"Script output","text":"<pre><code>cmr \"build docker image docker-image dockerimage \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Docker-automation/build-dockerfile/","title":"build-dockerfile","text":"<p>Automatically generated README for this automation recipe: build-dockerfile</p> <p>Category: Docker automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Docker-automation/build-dockerfile/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Docker-automation/build-dockerfile/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Docker-automation/build-dockerfile/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Docker-automation/build-dockerfile/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"build dockerfile\" --help</code></p>"},{"location":"scripts/Docker-automation/build-dockerfile/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Docker-automation/build-dockerfile/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=build,dockerfile[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-dockerfile/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"build dockerfile [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-dockerfile/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'build,dockerfile'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Docker-automation/build-dockerfile/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"build dockerfile[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/build-dockerfile/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_slim</code><ul> <li>ENV variables:<ul> <li>CM_DOCKER_BUILD_SLIM: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <p><code>* CM_DOCKER_OS:</code>ubuntu`</p>"},{"location":"scripts/Docker-automation/build-dockerfile/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--build=value</code>  \u2192  <code>CM_BUILD_DOCKER_IMAGE=value</code></li> <li><code>--cache=value</code>  \u2192  <code>CM_DOCKER_CACHE=value</code></li> <li><code>--cm_repo=value</code>  \u2192  <code>CM_MLOPS_REPO=value</code></li> <li><code>--cm_repo_flags=value</code>  \u2192  <code>CM_DOCKER_ADD_FLAG_TO_CM_MLOPS_REPO=value</code></li> <li><code>--cm_repos=value</code>  \u2192  <code>CM_DOCKER_EXTRA_CM_REPOS=value</code></li> <li><code>--comments=value</code>  \u2192  <code>CM_DOCKER_RUN_COMMENTS=value</code></li> <li><code>--copy_files=value</code>  \u2192  <code>CM_DOCKER_COPY_FILES=value</code></li> <li><code>--docker_base_image=value</code>  \u2192  <code>CM_DOCKER_IMAGE_BASE=value</code></li> <li><code>--docker_os=value</code>  \u2192  <code>CM_DOCKER_OS=value</code></li> <li><code>--docker_os_version=value</code>  \u2192  <code>CM_DOCKER_OS_VERSION=value</code></li> <li><code>--extra_sys_deps=value</code>  \u2192  <code>CM_DOCKER_EXTRA_SYS_DEPS=value</code></li> <li><code>--fake_docker_deps=value</code>  \u2192  <code>CM_DOCKER_FAKE_DEPS=value</code></li> <li><code>--fake_run_option=value</code>  \u2192  <code>CM_DOCKER_FAKE_RUN_OPTION=value</code></li> <li><code>--file_path=value</code>  \u2192  <code>CM_DOCKERFILE_WITH_PATH=value</code></li> <li><code>--gh_token=value</code>  \u2192  <code>CM_GH_TOKEN=value</code></li> <li><code>--image_repo=value</code>  \u2192  <code>CM_DOCKER_IMAGE_REPO=value</code></li> <li><code>--image_tag=value</code>  \u2192  <code>CM_DOCKER_IMAGE_TAG=value</code></li> <li><code>--package_manager_update_cmd=value</code>  \u2192  <code>CM_PACKAGE_MANAGER_UPDATE_CMD=value</code></li> <li><code>--pip_extra_flags=value</code>  \u2192  <code>CM_DOCKER_PIP_INSTALL_EXTRA_FLAGS=value</code></li> <li><code>--post_file=value</code>  \u2192  <code>DOCKER_IMAGE_POST_FILE=value</code></li> <li><code>--post_run_cmds=value</code>  \u2192  <code>CM_DOCKER_POST_RUN_COMMANDS=value</code></li> <li><code>--pre_run_cmds=value</code>  \u2192  <code>CM_DOCKER_PRE_RUN_COMMANDS=value</code></li> <li><code>--push_image=value</code>  \u2192  <code>CM_DOCKER_PUSH_IMAGE=value</code></li> <li><code>--real_run=value</code>  \u2192  <code>CM_REAL_RUN=value</code></li> <li><code>--run_cmd=value</code>  \u2192  <code>CM_DOCKER_RUN_CMD=value</code></li> <li><code>--run_cmd_extra=value</code>  \u2192  <code>CM_DOCKER_RUN_CMD_EXTRA=value</code></li> <li><code>--script_tags=value</code>  \u2192  <code>CM_DOCKER_RUN_SCRIPT_TAGS=value</code></li> <li><code>--skip_cm_sys_upgrade=value</code>  \u2192  <code>CM_DOCKER_SKIP_CM_SYS_UPGRADE=value</code></li> </ul>"},{"location":"scripts/Docker-automation/build-dockerfile/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DOCKER_BUILD_SLIM: <code>no</code></li> <li>CM_DOCKER_IMAGE_EOL: `</li> </ul>"},{"location":"scripts/Docker-automation/build-dockerfile/#script-output","title":"Script output","text":"<pre><code>cmr \"build dockerfile [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Docker-automation/prune-docker/","title":"prune-docker","text":"<p>Automatically generated README for this automation recipe: prune-docker</p> <p>Category: Docker automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Docker-automation/prune-docker/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Docker-automation/prune-docker/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Docker-automation/prune-docker/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Docker-automation/prune-docker/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"prune docker\" --help</code></p>"},{"location":"scripts/Docker-automation/prune-docker/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Docker-automation/prune-docker/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=prune,docker \n</code></pre>"},{"location":"scripts/Docker-automation/prune-docker/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"prune docker \" \n</code></pre>"},{"location":"scripts/Docker-automation/prune-docker/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'prune,docker'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Docker-automation/prune-docker/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"prune docker\" \n</code></pre>"},{"location":"scripts/Docker-automation/prune-docker/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Docker-automation/prune-docker/#script-output","title":"Script output","text":"<pre><code>cmr \"prune docker \"  -j\n</code></pre>"},{"location":"scripts/Docker-automation/run-docker-container/","title":"run-docker-container","text":"<p>Automatically generated README for this automation recipe: run-docker-container</p> <p>Category: Docker automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Docker-automation/run-docker-container/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Docker-automation/run-docker-container/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Docker-automation/run-docker-container/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Docker-automation/run-docker-container/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run docker container\" --help</code></p>"},{"location":"scripts/Docker-automation/run-docker-container/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/Docker-automation/run-docker-container/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,docker,container [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/run-docker-container/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run docker container \" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/run-docker-container/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,docker,container'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Docker-automation/run-docker-container/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run docker container\" [--input_flags]\n</code></pre>"},{"location":"scripts/Docker-automation/run-docker-container/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--all_gpus=value</code>  \u2192  <code>CM_DOCKER_ADD_ALL_GPUS=value</code></li> <li><code>--base=value</code>  \u2192  <code>CM_DOCKER_IMAGE_BASE=value</code></li> <li><code>--cache=value</code>  \u2192  <code>CM_DOCKER_CACHE=value</code></li> <li><code>--cm_repo=value</code>  \u2192  <code>CM_MLOPS_REPO=value</code></li> <li><code>--detached=value</code>  \u2192  <code>CM_DOCKER_DETACHED_MODE=value</code></li> <li><code>--device=value</code>  \u2192  <code>CM_DOCKER_ADD_DEVICE=value</code></li> <li><code>--docker_image_base=value</code>  \u2192  <code>CM_DOCKER_IMAGE_BASE=value</code></li> <li><code>--docker_os=value</code>  \u2192  <code>CM_DOCKER_OS=value</code></li> <li><code>--docker_os_version=value</code>  \u2192  <code>CM_DOCKER_OS_VERSION=value</code></li> <li><code>--extra_run_args=value</code>  \u2192  <code>CM_DOCKER_EXTRA_RUN_ARGS=value</code></li> <li><code>--fake_run_option=value</code>  \u2192  <code>CM_DOCKER_FAKE_RUN_OPTION=value</code></li> <li><code>--gh_token=value</code>  \u2192  <code>CM_GH_TOKEN=value</code></li> <li><code>--image_name=value</code>  \u2192  <code>CM_DOCKER_IMAGE_NAME=value</code></li> <li><code>--image_repo=value</code>  \u2192  <code>CM_DOCKER_IMAGE_REPO=value</code></li> <li><code>--image_tag=value</code>  \u2192  <code>CM_DOCKER_IMAGE_TAG=value</code></li> <li><code>--image_tag_extra=value</code>  \u2192  <code>CM_DOCKER_IMAGE_TAG_EXTRA=value</code></li> <li><code>--interactive=value</code>  \u2192  <code>CM_DOCKER_INTERACTIVE_MODE=value</code></li> <li><code>--it=value</code>  \u2192  <code>CM_DOCKER_INTERACTIVE=value</code></li> <li><code>--mounts=value</code>  \u2192  <code>CM_DOCKER_VOLUME_MOUNTS=value</code></li> <li><code>--num_gpus=value</code>  \u2192  <code>CM_DOCKER_ADD_NUM_GPUS=value</code></li> <li><code>--pass_user_group=value</code>  \u2192  <code>CM_DOCKER_PASS_USER_GROUP=value</code></li> <li><code>--port_maps=value</code>  \u2192  <code>CM_DOCKER_PORT_MAPS=value</code></li> <li><code>--post_run_cmds=value</code>  \u2192  <code>CM_DOCKER_POST_RUN_COMMANDS=value</code></li> <li><code>--pre_run_cmds=value</code>  \u2192  <code>CM_DOCKER_PRE_RUN_COMMANDS=value</code></li> <li><code>--real_run=value</code>  \u2192  <code>CM_REAL_RUN=value</code></li> <li><code>--recreate=value</code>  \u2192  <code>CM_DOCKER_IMAGE_RECREATE=value</code></li> <li><code>--run_cmd=value</code>  \u2192  <code>CM_DOCKER_RUN_CMD=value</code></li> <li><code>--run_cmd_extra=value</code>  \u2192  <code>CM_DOCKER_RUN_CMD_EXTRA=value</code></li> <li><code>--save_script=value</code>  \u2192  <code>CM_DOCKER_SAVE_SCRIPT=value</code></li> <li><code>--script_tags=value</code>  \u2192  <code>CM_DOCKER_RUN_SCRIPT_TAGS=value</code></li> <li><code>--shm_size=value</code>  \u2192  <code>CM_DOCKER_SHM_SIZE=value</code></li> </ul>"},{"location":"scripts/Docker-automation/run-docker-container/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DOCKER_DETACHED_MODE: <code>yes</code></li> </ul>"},{"location":"scripts/Docker-automation/run-docker-container/#script-output","title":"Script output","text":"<pre><code>cmr \"run docker container \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/GUI/","title":"GUI","text":"<ul> <li>gui</li> </ul>"},{"location":"scripts/GUI/gui/","title":"gui","text":"<p>Automatically generated README for this automation recipe: gui</p> <p>Category: GUI</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin</p> <p>This CM script provides a unified GUI to run CM scripts using Streamlit library.</p> <p>If you want to run it in a cloud (Azure, AWS, GCP), you need to open some port and test that you can reach it from outside.</p> <p>By default, streamlit uses port 8501 but you can change it as follows:</p> <pre><code>cm run script \"cm gui\" --port 80\n</code></pre> <p>If you have troubles accessing this port, use this simple python module to test if your port is open: <pre><code>python3 -m http.server 80\n</code></pre></p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/GUI/gui/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/GUI/gui/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/GUI/gui/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/GUI/gui/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"cm gui cm-gui script-gui cm-script-gui streamlit\" --help</code></p>"},{"location":"scripts/GUI/gui/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag MappingDefault environment"},{"location":"scripts/GUI/gui/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=cm,gui,cm-gui,script-gui,cm-script-gui,streamlit[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/GUI/gui/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"cm gui cm-gui script-gui cm-script-gui streamlit [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/GUI/gui/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'cm,gui,cm-gui,script-gui,cm-script-gui,streamlit'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/GUI/gui/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"cm gui cm-gui script-gui cm-script-gui streamlit[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/GUI/gui/#variations","title":"Variations","text":"<ul> <li> <p>Group \"app\"      Click here to expand this section. <ul> <li><code>_chatgpt</code><ul> <li>ENV variables:<ul> <li>CM_GUI_APP: <code>chatgpt</code></li> </ul> </li> </ul> </li> <li><code>_graph</code><ul> <li>ENV variables:<ul> <li>CM_GUI_APP: <code>graph</code></li> </ul> </li> </ul> </li> <li><code>_main</code><ul> <li>ENV variables:<ul> <li>CM_GUI_APP: <code>app</code></li> </ul> </li> </ul> </li> <li><code>_playground</code><ul> <li>ENV variables:<ul> <li>CM_GUI_APP: <code>playground</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/GUI/gui/#input-flags","title":"Input Flags","text":"<ul> <li>--script: script tags</li> <li>--app: gui app</li> </ul>"},{"location":"scripts/GUI/gui/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--address=value</code>  \u2192  <code>CM_GUI_ADDRESS=value</code></li> <li><code>--app=value</code>  \u2192  <code>CM_GUI_APP=value</code></li> <li><code>--exp_key_c=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_AXIS_KEY_C=value</code></li> <li><code>--exp_key_s=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_AXIS_KEY_S=value</code></li> <li><code>--exp_key_x=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_AXIS_KEY_X=value</code></li> <li><code>--exp_key_y=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_AXIS_KEY_Y=value</code></li> <li><code>--exp_max_results=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_MAX_RESULTS=value</code></li> <li><code>--exp_name=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_NAME=value</code></li> <li><code>--exp_tags=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_TAGS=value</code></li> <li><code>--exp_title=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_TITLE=value</code></li> <li><code>--exp_uid=value</code>  \u2192  <code>CM_GUI_GRAPH_EXPERIMENT_RESULT_UID=value</code></li> <li><code>--no_browser=value</code>  \u2192  <code>CM_GUI_NO_BROWSER=value</code></li> <li><code>--no_run=value</code>  \u2192  <code>CM_GUI_NO_RUN=value</code></li> <li><code>--port=value</code>  \u2192  <code>CM_GUI_PORT=value</code></li> <li><code>--prefix=value</code>  \u2192  <code>CM_GUI_SCRIPT_PREFIX_LINUX=value</code></li> <li><code>--script=value</code>  \u2192  <code>CM_GUI_SCRIPT_TAGS=value</code></li> <li><code>--title=value</code>  \u2192  <code>CM_GUI_TITLE=value</code></li> </ul>"},{"location":"scripts/GUI/gui/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GUI_EXTRA_CMD: ``</li> <li>CM_GUI_SCRIPT_PREFIX_LINUX: <code>gnome-terminal --</code></li> <li>CM_GUI_APP: <code>app</code></li> </ul>"},{"location":"scripts/GUI/gui/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/GUI/gui/#script-output","title":"Script output","text":"<pre><code>cmr \"cm gui cm-gui script-gui cm-script-gui streamlit [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Legacy-CK-support/","title":"Legacy-CK-support","text":"<ul> <li>get-ck</li> <li>get-ck-repo-mlops</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck/","title":"get-ck","text":"<p>Automatically generated README for this automation recipe: get-ck</p> <p>Category: Legacy CK support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Legacy-CK-support/get-ck/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Legacy-CK-support/get-ck/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ck ck-framework\" --help</code></p>"},{"location":"scripts/Legacy-CK-support/get-ck/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Legacy-CK-support/get-ck/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ck,ck-framework \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ck ck-framework \" \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ck,ck-framework'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ck ck-framework\" \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck/#script-output","title":"Script output","text":"<pre><code>cmr \"get ck ck-framework \"  -j\n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/","title":"get-ck-repo-mlops","text":"<p>Automatically generated README for this automation recipe: get-ck-repo-mlops</p> <p>Category: Legacy CK support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ck-repo mlops ck-repo-mlops\" --help</code></p>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ck-repo,mlops,ck-repo-mlops \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ck-repo mlops ck-repo-mlops \" \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ck-repo,mlops,ck-repo-mlops'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ck-repo mlops ck-repo-mlops\" \n</code></pre>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Legacy-CK-support/get-ck-repo-mlops/#script-output","title":"Script output","text":"<pre><code>cmr \"get ck-repo mlops ck-repo-mlops \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/","title":"MLPerf-benchmark-support","text":"<ul> <li>add-custom-nvidia-system</li> <li>benchmark-any-mlperf-inference-implementation</li> <li>build-mlperf-inference-server-nvidia</li> <li>generate-mlperf-inference-submission</li> <li>generate-mlperf-inference-user-conf</li> <li>generate-mlperf-tiny-report</li> <li>generate-mlperf-tiny-submission</li> <li>generate-nvidia-engine</li> <li>get-mlperf-inference-intel-scratch-space</li> <li>get-mlperf-inference-loadgen</li> <li>get-mlperf-inference-nvidia-common-code</li> <li>get-mlperf-inference-nvidia-scratch-space</li> <li>get-mlperf-inference-results</li> <li>get-mlperf-inference-results-dir</li> <li>get-mlperf-inference-src</li> <li>get-mlperf-inference-submission-dir</li> <li>get-mlperf-inference-sut-configs</li> <li>get-mlperf-inference-sut-description</li> <li>get-mlperf-logging</li> <li>get-mlperf-power-dev</li> <li>get-mlperf-tiny-eembc-energy-runner-src</li> <li>get-mlperf-tiny-src</li> <li>get-mlperf-training-nvidia-code</li> <li>get-mlperf-training-src</li> <li>get-nvidia-mitten</li> <li>get-spec-ptd</li> <li>import-mlperf-inference-to-experiment</li> <li>import-mlperf-tiny-to-experiment</li> <li>import-mlperf-training-to-experiment</li> <li>install-mlperf-logging-from-src</li> <li>prepare-training-data-bert</li> <li>prepare-training-data-resnet</li> <li>preprocess-mlperf-inference-submission</li> <li>process-mlperf-accuracy</li> <li>push-mlperf-inference-results-to-github</li> <li>run-mlperf-inference-mobilenet-models</li> <li>run-mlperf-inference-submission-checker</li> <li>run-mlperf-power-client</li> <li>run-mlperf-power-server</li> <li>run-mlperf-training-submission-checker</li> <li>truncate-mlperf-inference-accuracy-log</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/","title":"add-custom-nvidia-system","text":"<p>Automatically generated README for this automation recipe: add-custom-nvidia-system</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"add custom system nvidia\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=add,custom,system,nvidia[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"add custom system nvidia [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'add,custom,system,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"add custom system nvidia[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#variations","title":"Variations","text":"<ul> <li> <p>Group \"code\"      Click here to expand this section. <ul> <li><code>_ctuning</code></li> <li><code>_custom</code></li> <li><code>_go</code></li> <li><code>_mlcommons</code></li> <li><code>_nvidia-only</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#versions","title":"Versions","text":"<ul> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> <li><code>r4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/add-custom-nvidia-system/#script-output","title":"Script output","text":"<pre><code>cmr \"add custom system nvidia [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/","title":"benchmark-any-mlperf-inference-implementation","text":"<p>Automatically generated README for this automation recipe: benchmark-any-mlperf-inference-implementation</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"benchmark run natively all inference any mlperf mlperf-implementation implementation mlperf-models\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=benchmark,run,natively,all,inference,any,mlperf,mlperf-implementation,implementation,mlperf-models[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"benchmark run natively all inference any mlperf mlperf-implementation implementation mlperf-models [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'benchmark,run,natively,all,inference,any,mlperf,mlperf-implementation,implementation,mlperf-models'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"benchmark run natively all inference any mlperf mlperf-implementation implementation mlperf-models[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#variations","title":"Variations","text":"<ul> <li> <p>Group \"implementation\"      Click here to expand this section. <ul> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>DIVISION: <code>open</code></li> <li>IMPLEMENTATION: <code>deepsparse</code></li> </ul> </li> </ul> </li> <li><code>_intel</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>intel</code></li> </ul> </li> </ul> </li> <li><code>_mil</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>mil</code></li> </ul> </li> </ul> </li> <li><code>_nvidia</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>nvidia-original</code></li> </ul> </li> </ul> </li> <li><code>_qualcomm</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>qualcomm</code></li> </ul> </li> </ul> </li> <li><code>_reference</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>reference</code></li> </ul> </li> </ul> </li> <li><code>_tflite-cpp</code><ul> <li>ENV variables:<ul> <li>IMPLEMENTATION: <code>tflite_cpp</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"power\"      Click here to expand this section. <ul> <li><code>_performance-only</code> (default)</li> <li><code>_power</code><ul> <li>ENV variables:<ul> <li>POWER: <code>True</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"sut\"      Click here to expand this section. <ul> <li><code>_aws-dl2q.24xlarge</code></li> <li><code>_macbookpro-m1</code><ul> <li>ENV variables:<ul> <li>CATEGORY: <code>edge</code></li> <li>DIVISION: <code>closed</code></li> </ul> </li> </ul> </li> <li><code>_mini</code></li> <li><code>_orin</code></li> <li><code>_orin.32g</code><ul> <li>ENV variables:<ul> <li>CATEGORY: <code>edge</code></li> <li>DIVISION: <code>closed</code></li> </ul> </li> </ul> </li> <li><code>_phoenix</code><ul> <li>ENV variables:<ul> <li>CATEGORY: <code>edge</code></li> <li>DIVISION: <code>closed</code></li> </ul> </li> </ul> </li> <li><code>_rb6</code></li> <li><code>_rpi4</code></li> <li><code>_sapphire-rapids.24c</code><ul> <li>ENV variables:<ul> <li>CATEGORY: <code>edge</code></li> <li>DIVISION: <code>closed</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#default-variations","title":"Default variations","text":"<p><code>_performance-only</code></p>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--backends=value</code>  \u2192  <code>BACKENDS=value</code></li> <li><code>--category=value</code>  \u2192  <code>CATEGORY=value</code></li> <li><code>--devices=value</code>  \u2192  <code>DEVICES=value</code></li> <li><code>--division=value</code>  \u2192  <code>DIVISION=value</code></li> <li><code>--extra_args=value</code>  \u2192  <code>EXTRA_ARGS=value</code></li> <li><code>--models=value</code>  \u2192  <code>MODELS=value</code></li> <li><code>--power_server=value</code>  \u2192  <code>POWER_SERVER=value</code></li> <li><code>--power_server_port=value</code>  \u2192  <code>POWER_SERVER_PORT=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>DIVISION: <code>open</code></li> <li>CATEGORY: <code>edge</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-template.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/benchmark-any-mlperf-inference-implementation/#script-output","title":"Script output","text":"<pre><code>cmr \"benchmark run natively all inference any mlperf mlperf-implementation implementation mlperf-models [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/","title":"build-mlperf-inference-server-nvidia","text":"<p>Automatically generated README for this automation recipe: build-mlperf-inference-server-nvidia</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"build mlcommons mlperf inference inference-server server nvidia-harness nvidia\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=build,mlcommons,mlperf,inference,inference-server,server,nvidia-harness,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"build mlcommons mlperf inference inference-server server nvidia-harness nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'build,mlcommons,mlperf,inference,inference-server,server,nvidia-harness,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"build mlcommons mlperf inference inference-server server nvidia-harness nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#variations","title":"Variations","text":"<ul> <li> <p>Group \"code\"      Click here to expand this section. <ul> <li><code>_ctuning</code> (default)</li> <li><code>_custom</code></li> <li><code>_go</code></li> <li><code>_mlcommons</code></li> <li><code>_nvidia-only</code></li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cuda</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> <li><code>_inferentia</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>inferentia</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_r4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#default-variations","title":"Default variations","text":"<p><code>_ctuning,_cuda</code></p>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MAKE_CLEAN=value</code></li> <li><code>--custom_system=value</code>  \u2192  <code>CM_CUSTOM_SYSTEM_NVIDIA=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MAKE_BUILD_COMMAND: <code>build</code></li> <li>CM_MAKE_CLEAN: <code>no</code></li> <li>CM_CUSTOM_SYSTEM_NVIDIA: <code>yes</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#versions","title":"Versions","text":"<p>Default version: <code>r3.1</code></p> <ul> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> <li><code>r4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/build-mlperf-inference-server-nvidia/#script-output","title":"Script output","text":"<pre><code>cmr \"build mlcommons mlperf inference inference-server server nvidia-harness nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/","title":"generate-mlperf-inference-submission","text":"<p>Automatically generated README for this automation recipe: generate-mlperf-inference-submission</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"generate submission mlperf mlperf-inference inference mlcommons inference-submission mlperf-inference-submission mlcommons-inference-submission\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=generate,submission,mlperf,mlperf-inference,inference,mlcommons,inference-submission,mlperf-inference-submission,mlcommons-inference-submission [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"generate submission mlperf mlperf-inference inference mlcommons inference-submission mlperf-inference-submission mlcommons-inference-submission \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'generate,submission,mlperf,mlperf-inference,inference,mlcommons,inference-submission,mlperf-inference-submission,mlcommons-inference-submission'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"generate submission mlperf mlperf-inference inference mlcommons inference-submission mlperf-inference-submission mlcommons-inference-submission\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--analyzer_settings_file=value</code>  \u2192  <code>CM_MLPERF_POWER_ANALYZER_SETTINGS_FILE_PATH=value</code></li> <li><code>--category=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_CATEGORY=value</code></li> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_SUBMISSION_DIR=value</code></li> <li><code>--dashboard=value</code>  \u2192  <code>CM_MLPERF_DASHBOARD=value</code></li> <li><code>--dashboard_wb_project=value</code>  \u2192  <code>CM_MLPERF_DASHBOARD_WANDB_PROJECT=value</code></li> <li><code>--device=value</code>  \u2192  <code>CM_MLPERF_DEVICE=value</code></li> <li><code>--division=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_DIVISION=value</code></li> <li><code>--duplicate=value</code>  \u2192  <code>CM_MLPERF_DUPLICATE_SCENARIO_RESULTS=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--hw_notes_extra=value</code>  \u2192  <code>CM_MLPERF_SUT_HW_NOTES_EXTRA=value</code></li> <li><code>--infer_scenario_results=value</code>  \u2192  <code>CM_MLPERF_DUPLICATE_SCENARIO_RESULTS=value</code></li> <li><code>--power_settings_file=value</code>  \u2192  <code>CM_MLPERF_POWER_SETTINGS_FILE_PATH=value</code></li> <li><code>--preprocess=value</code>  \u2192  <code>CM_RUN_MLPERF_SUBMISSION_PREPROCESSOR=value</code></li> <li><code>--preprocess_submission=value</code>  \u2192  <code>CM_RUN_MLPERF_SUBMISSION_PREPROCESSOR=value</code></li> <li><code>--results_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_RESULTS_DIR_=value</code></li> <li><code>--run_checker=value</code>  \u2192  <code>CM_RUN_SUBMISSION_CHECKER=value</code></li> <li><code>--run_style=value</code>  \u2192  <code>CM_MLPERF_RUN_STYLE=value</code></li> <li><code>--skip_truncation=value</code>  \u2192  <code>CM_SKIP_TRUNCATE_ACCURACY=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> <li><code>--sw_notes_extra=value</code>  \u2192  <code>CM_MLPERF_SUT_SW_NOTES_EXTRA=value</code></li> <li><code>--tar=value</code>  \u2192  <code>CM_TAR_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_RUN_MLPERF_ACCURACY: <code>on</code></li> <li>CM_MLPERF_RUN_STYLE: <code>valid</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-submission/#script-output","title":"Script output","text":"<pre><code>cmr \"generate submission mlperf mlperf-inference inference mlcommons inference-submission mlperf-inference-submission mlcommons-inference-submission \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/","title":"generate-mlperf-inference-user-conf","text":"<p>Automatically generated README for this automation recipe: generate-mlperf-inference-user-conf</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>Developers: Arjun Suresh, Thomas Zhu, Grigori Fursin</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"generate mlperf inference user-conf inference-user-conf\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=generate,mlperf,inference,user-conf,inference-user-conf [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"generate mlperf inference user-conf inference-user-conf \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'generate,mlperf,inference,user-conf,inference-user-conf'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"generate mlperf inference user-conf inference-user-conf\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--num_threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--regenerate_files=value</code>  \u2192  <code>CM_REGENERATE_MEASURE_FILES=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--test_query_count=value</code>  \u2192  <code>CM_TEST_QUERY_COUNT=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_LOADGEN_MODE: <code>accuracy</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_OUTPUT_FOLDER_NAME: <code>test_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>test</code></li> <li>CM_TEST_QUERY_COUNT: <code>10</code></li> <li>CM_FAST_FACTOR: <code>5</code></li> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-inference-user-conf/#script-output","title":"Script output","text":"<pre><code>cmr \"generate mlperf inference user-conf inference-user-conf \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/","title":"generate-mlperf-tiny-report","text":"<p>Automatically generated README for this automation recipe: generate-mlperf-tiny-report</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"generate mlperf tiny mlperf-tiny report\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=generate,mlperf,tiny,mlperf-tiny,report [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"generate mlperf tiny mlperf-tiny report \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'generate,mlperf,tiny,mlperf-tiny,report'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"generate mlperf tiny mlperf-tiny report\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--repo_tags=value</code>  \u2192  <code>CM_IMPORT_TINYMLPERF_REPO_TAGS=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_IMPORT_TINYMLPERF_REPO_TAGS: <code>1.1-private</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run_submission_checker.sh</li> </ul> <ul> <li>run_submission_checker.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-report/#script-output","title":"Script output","text":"<pre><code>cmr \"generate mlperf tiny mlperf-tiny report \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/","title":"generate-mlperf-tiny-submission","text":"<p>Automatically generated README for this automation recipe: generate-mlperf-tiny-submission</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"generate submission mlperf mlperf-tiny tiny mlcommons tiny-submission mlperf-tiny-submission mlcommons-tiny-submission\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=generate,submission,mlperf,mlperf-tiny,tiny,mlcommons,tiny-submission,mlperf-tiny-submission,mlcommons-tiny-submission \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"generate submission mlperf mlperf-tiny tiny mlcommons tiny-submission mlperf-tiny-submission mlcommons-tiny-submission \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'generate,submission,mlperf,mlperf-tiny,tiny,mlcommons,tiny-submission,mlperf-tiny-submission,mlcommons-tiny-submission'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"generate submission mlperf mlperf-tiny tiny mlcommons tiny-submission mlperf-tiny-submission mlcommons-tiny-submission\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-mlperf-tiny-submission/#script-output","title":"Script output","text":"<pre><code>cmr \"generate submission mlperf mlperf-tiny tiny mlcommons tiny-submission mlperf-tiny-submission mlcommons-tiny-submission \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/","title":"generate-nvidia-engine","text":"<p>Automatically generated README for this automation recipe: generate-nvidia-engine</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>This CM script is in draft stage</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"generate engine mlperf inference nvidia\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=generate,engine,mlperf,inference,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"generate engine mlperf inference nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'generate,engine,mlperf,inference,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"generate engine mlperf inference nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_BATCH_SIZE: <code>None</code></li> </ul> </li> </ul> </li> <li><code>_copy_streams.#</code><ul> <li>ENV variables:<ul> <li>CM_GPU_COPY_STREAMS: <code>None</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#default-variations","title":"Default variations","text":"<p><code>_cpu,_resnet50</code></p>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> <li>CM_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_GPU_COPY_STREAMS: <code>1</code></li> <li>CM_TENSORRT_WORKSPACE_SIZE: <code>4194304</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/generate-nvidia-engine/#script-output","title":"Script output","text":"<pre><code>cmr \"generate engine mlperf inference nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/","title":"get-mlperf-inference-intel-scratch-space","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-intel-scratch-space</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf inference intel scratch space\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,inference,intel,scratch,space[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf inference intel scratch space [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,inference,intel,scratch,space'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf inference intel scratch space[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#variations","title":"Variations","text":"<ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_version.#</code><ul> <li>ENV variables:<ul> <li>CM_INTEL_SCRATCH_SPACE_VERSION: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_version.4_0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_INTEL_SCRATCH_SPACE_VERSION: <code>4_0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#default-variations","title":"Default variations","text":"<p><code>_version.4_0</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--scratch_path=value</code>  \u2192  <code>MLPERF_INTEL_SCRATCH_PATH=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-intel-scratch-space/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf inference intel scratch space [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/","title":"get-mlperf-inference-loadgen","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-loadgen</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get loadgen inference inference-loadgen mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,loadgen,inference,inference-loadgen,mlperf,mlcommons[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get loadgen inference inference-loadgen mlperf mlcommons [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,loadgen,inference,inference-loadgen,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get loadgen inference inference-loadgen mlperf mlcommons[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_copy</code></li> <li><code>_custom-python</code><ul> <li>ENV variables:<ul> <li>CM_TMP_USE_CUSTOM_PYTHON: <code>on</code></li> </ul> </li> </ul> </li> <li><code>_download</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_CHECKSUM: <code>af3f9525965b2c1acc348fb882a5bfd1</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD: <code>YES</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD_URL: <code>https://www.dropbox.com/scl/fi/36dgoiur26i2tvwgsaatf/loadgen.zip?rlkey=ab68i7uza9anvaw0hk1xvf0qk&amp;dl=0</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_VERSION: <code>v3.1</code></li> <li>CM_VERIFY_SSL: <code>False</code></li> </ul> </li> </ul> </li> <li><code>_download_v3.1</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_CHECKSUM: <code>af3f9525965b2c1acc348fb882a5bfd1</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD: <code>YES</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD_URL: <code>https://www.dropbox.com/scl/fi/36dgoiur26i2tvwgsaatf/loadgen.zip?rlkey=ab68i7uza9anvaw0hk1xvf0qk&amp;dl=0</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_VERSION: <code>v3.1</code></li> <li>CM_VERIFY_SSL: <code>False</code></li> </ul> </li> </ul> </li> <li><code>_download_v4.0</code><ul> <li>ENV variables:<ul> <li>CM_DOWNLOAD_CHECKSUM: <code>b4d97525d9ad0539a64667f2a3ca20c5</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD: <code>YES</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_DOWNLOAD_URL: <code>https://www.dropbox.com/scl/fi/gk5e9kziju5t56umxyzyx/loadgen.zip?rlkey=vsie4xnzml1inpjplm5cg7t54&amp;dl=0</code></li> <li>CM_MLPERF_INFERENCE_LOADGEN_VERSION: <code>v4.0</code></li> <li>CM_VERIFY_SSL: <code>False</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SHARED_BUILD: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>custom</code></li> <li><code>main</code></li> <li><code>master</code></li> <li><code>pybind_fix</code></li> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-loadgen/#script-output","title":"Script output","text":"<pre><code>cmr \"get loadgen inference inference-loadgen mlperf mlcommons [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/","title":"get-mlperf-inference-nvidia-common-code","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-nvidia-common-code</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get nvidia mlperf inference common-code\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,nvidia,mlperf,inference,common-code[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get nvidia mlperf inference common-code [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,nvidia,mlperf,inference,common-code'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get nvidia mlperf inference common-code[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#variations","title":"Variations","text":"<ul> <li> <p>Group \"repo-owner\"      Click here to expand this section. <ul> <li><code>_ctuning</code></li> <li><code>_custom</code></li> <li><code>_go</code></li> <li><code>_mlcommons</code></li> <li><code>_nvidia-only</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#versions","title":"Versions","text":"<p>Default version: <code>r3.1</code></p> <ul> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> <li><code>r4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-common-code/#script-output","title":"Script output","text":"<pre><code>cmr \"get nvidia mlperf inference common-code [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/","title":"get-mlperf-inference-nvidia-scratch-space","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-nvidia-scratch-space</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf inference nvidia scratch space\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,inference,nvidia,scratch,space[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf inference nvidia scratch space [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,inference,nvidia,scratch,space'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf inference nvidia scratch space[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#variations","title":"Variations","text":"<ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_version.#</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_SCRATCH_SPACE_VERSION: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_version.4_0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_NVIDIA_SCRATCH_SPACE_VERSION: <code>4_0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#default-variations","title":"Default variations","text":"<p><code>_version.4_0</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--scratch_path=value</code>  \u2192  <code>CM_NVIDIA_MLPERF_SCRATCH_PATH=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-nvidia-scratch-space/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf inference nvidia scratch space [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/","title":"get-mlperf-inference-results","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-results</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get results inference inference-results mlcommons mlperf\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,results,inference,inference-results,mlcommons,mlperf[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get results inference inference-results mlcommons mlperf [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,results,inference,inference-results,mlcommons,mlperf'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get results inference inference-results mlcommons mlperf[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#variations","title":"Variations","text":"<ul> <li> <p>Group \"source-repo\"      Click here to expand this section. <ul> <li><code>_ctuning</code><ul> <li>ENV variables:<ul> <li>GITHUB_REPO_OWNER: <code>ctuning</code></li> </ul> </li> </ul> </li> <li><code>_custom</code><ul> <li>ENV variables:<ul> <li>GITHUB_REPO_OWNER: <code>arjunsuresh</code></li> </ul> </li> </ul> </li> <li><code>_go</code><ul> <li>ENV variables:<ul> <li>GITHUB_REPO_OWNER: <code>GATEOverflow</code></li> </ul> </li> </ul> </li> <li><code>_mlcommons</code> (default)<ul> <li>ENV variables:<ul> <li>GITHUB_REPO_OWNER: <code>mlcommons</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-only</code><ul> <li>ENV variables:<ul> <li>GITHUB_REPO_OWNER: <code>GATEOverflow</code></li> <li>NVIDIA_ONLY: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#default-variations","title":"Default variations","text":"<p><code>_mlcommons</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>master</code></li> <li>CM_GIT_DEPTH: <code>--depth 1</code></li> <li>CM_GIT_PATCH: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#versions","title":"Versions","text":"<p>Default version: <code>v3.1</code></p> <ul> <li><code>v2.1</code></li> <li><code>v3.0</code></li> <li><code>v3.1</code></li> <li><code>v4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results/#script-output","title":"Script output","text":"<pre><code>cmr \"get results inference inference-results mlcommons mlperf [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/","title":"get-mlperf-inference-results-dir","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-results-dir</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf inference results dir directory\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,inference,results,dir,directory[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf inference results dir directory [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,inference,results,dir,directory'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf inference results dir directory[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#variations","title":"Variations","text":"<ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_version.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_RESULTS_VERSION: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_version.4_0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_RESULTS_VERSION: <code>4_0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#default-variations","title":"Default variations","text":"<p><code>_version.4_0</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--results_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_RESULTS_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-results-dir/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf inference results dir directory [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/","title":"get-mlperf-inference-src","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-src</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source inference inference-src inference-source mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,inference,inference-src,inference-source,mlperf,mlcommons[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source inference inference-src inference-source mlperf mlcommons [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,inference,inference-src,inference-source,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source inference inference-src inference-source mlperf mlcommons[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_3d-unet</code><ul> <li>ENV variables:<ul> <li>CM_SUBMODULE_3D_UNET: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_deeplearningexamples</code><ul> <li>ENV variables:<ul> <li>CM_SUBMODULE_DEEPLEARNINGEXAMPLES: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>deepsparse</code></li> <li>CM_GIT_URL: <code>https://github.com/neuralmagic/inference</code></li> <li>CM_MLPERF_LAST_RELEASE: <code>v4.0</code></li> </ul> </li> </ul> </li> <li><code>_gn</code><ul> <li>ENV variables:<ul> <li>CM_SUBMODULE_GN: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_no-recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> </ul> </li> </ul> </li> <li><code>_nvidia-pycocotools</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH_FILENAME: <code>coco.patch</code></li> </ul> </li> </ul> </li> <li><code>_octoml</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/octoml/inference</code></li> </ul> </li> </ul> </li> <li><code>_openimages-nvidia-pycocotools</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH_FILENAME: <code>openimages-pycocotools.patch</code></li> </ul> </li> </ul> </li> <li><code>_patch</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_pybind</code><ul> <li>ENV variables:<ul> <li>CM_SUBMODULE_PYBIND: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: <code>--recurse-submodules</code></li> </ul> </li> </ul> </li> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_submodules.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SUBMODULES: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"checkout\"      Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SHA: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"git-history\"      Click here to expand this section. <ul> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: ``</li> </ul> </li> </ul> </li> <li><code>_short-history</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 10</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#default-variations","title":"Default variations","text":"<p><code>_short-history</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT_FOLDER: <code>inference</code></li> <li>CM_GIT_DEPTH: <code>--depth 4</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> <li>CM_GIT_URL: <code>https://github.com/mlcommons/inference.git</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>custom</code></li> <li><code>deepsparse</code></li> <li><code>main</code></li> <li><code>master</code></li> <li><code>pybind_fix</code></li> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> <li><code>tvm</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source inference inference-src inference-source mlperf mlcommons [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/","title":"get-mlperf-inference-submission-dir","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-submission-dir</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf inference submission dir directory\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,inference,submission,dir,directory[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf inference submission dir directory [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,inference,submission,dir,directory'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf inference submission dir directory[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#variations","title":"Variations","text":"<ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_version.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_SUBMISSION_VERSION: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_version.4_0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_SUBMISSION_VERSION: <code>4_0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#default-variations","title":"Default variations","text":"<p><code>_version.4_0</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-submission-dir/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf inference submission dir directory [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/","title":"get-mlperf-inference-sut-configs","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-sut-configs</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf inference sut configs sut-configs\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,inference,sut,configs,sut-configs [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf inference sut configs sut-configs \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,inference,sut,configs,sut-configs'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf inference sut configs sut-configs\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--configs_git_url=value</code>  \u2192  <code>CM_GIT_URL=value</code></li> <li><code>--repo_path=value</code>  \u2192  <code>CM_SUT_CONFIGS_PATH=value</code></li> <li><code>--run_config=value</code>  \u2192  <code>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SUT_CONFIGS_PATH: ``</li> <li>CM_GIT_URL: ``</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-configs/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf inference sut configs sut-configs \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/","title":"get-mlperf-inference-sut-description","text":"<p>Automatically generated README for this automation recipe: get-mlperf-inference-sut-description</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf sut description system-under-test system-description\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,sut,description,system-under-test,system-description [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf sut description system-under-test system-description \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,sut,description,system-under-test,system-description'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf sut description system-under-test system-description\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SUT_DESC_CACHE: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-inference-sut-description/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf sut description system-under-test system-description \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/","title":"get-mlperf-logging","text":"<p>Automatically generated README for this automation recipe: get-mlperf-logging</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get mlperf logging mlperf-logging\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,mlperf,logging,mlperf-logging \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get mlperf logging mlperf-logging \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,mlperf,logging,mlperf-logging'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get mlperf logging mlperf-logging\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-logging/#script-output","title":"Script output","text":"<pre><code>cmr \"get mlperf logging mlperf-logging \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/","title":"get-mlperf-power-dev","text":"<p>Automatically generated README for this automation recipe: get-mlperf-power-dev</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source power power-dev mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,power,power-dev,mlperf,mlcommons[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source power power-dev mlperf mlcommons [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,power,power-dev,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source power power-dev mlperf mlcommons[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#variations","title":"Variations","text":"<ul> <li> <p>Group \"checkout\"      Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_mlcommons</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/mlcommons/power-dev.git</code></li> </ul> </li> </ul> </li> <li><code>_octoml</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/octoml/power-dev.git</code></li> </ul> </li> </ul> </li> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#default-variations","title":"Default variations","text":"<p><code>_mlcommons</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_DEPTH: <code>--depth 1</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_CHECKOUT_FOLDER: <code>power-dev</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-power-dev/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source power power-dev mlperf mlcommons [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/","title":"get-mlperf-tiny-eembc-energy-runner-src","text":"<p>Automatically generated README for this automation recipe: get-mlperf-tiny-eembc-energy-runner-src</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source eembc energyrunner energy-runner eembc-energy-runner tinymlperf-energy-runner\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,eembc,energyrunner,energy-runner,eembc-energy-runner,tinymlperf-energy-runner \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source eembc energyrunner energy-runner eembc-energy-runner tinymlperf-energy-runner \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,eembc,energyrunner,energy-runner,eembc-energy-runner,tinymlperf-energy-runner'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source eembc energyrunner energy-runner eembc-energy-runner tinymlperf-energy-runner\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>main</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> <li>CM_GIT_URL: <code>https://github.com/eembc/energyrunner</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-eembc-energy-runner-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source eembc energyrunner energy-runner eembc-energy-runner tinymlperf-energy-runner \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/","title":"get-mlperf-tiny-src","text":"<p>Automatically generated README for this automation recipe: get-mlperf-tiny-src</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source tiny tiny-src tiny-source tinymlperf tinymlperf-src mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,tiny,tiny-src,tiny-source,tinymlperf,tinymlperf-src,mlperf,mlcommons \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source tiny tiny-src tiny-source tinymlperf tinymlperf-src mlperf mlcommons \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,tiny,tiny-src,tiny-source,tinymlperf,tinymlperf-src,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source tiny tiny-src tiny-source tinymlperf tinymlperf-src mlperf mlcommons\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>master</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> <li>CM_GIT_URL: <code>https://github.com/mlcommons/tiny.git</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-tiny-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source tiny tiny-src tiny-source tinymlperf tinymlperf-src mlperf mlcommons \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/","title":"get-mlperf-training-nvidia-code","text":"<p>Automatically generated README for this automation recipe: get-mlperf-training-nvidia-code</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get nvidia mlperf training code training-code\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,nvidia,mlperf,training,code,training-code[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get nvidia mlperf training code training-code [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,nvidia,mlperf,training,code,training-code'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get nvidia mlperf training code training-code[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#variations","title":"Variations","text":"<ul> <li> <p>Group \"repo-owner\"      Click here to expand this section. <ul> <li><code>_ctuning</code><ul> <li>ENV variables:<ul> <li>CM_TMP_TRAINING_SRC: <code>ctuning</code></li> </ul> </li> </ul> </li> <li><code>_custom</code></li> <li><code>_mlcommons</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TMP_TRAINING_SRC: <code>mlcommons</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-only</code><ul> <li>ENV variables:<ul> <li>CM_TMP_TRAINING_SRC: <code>GATEOverflow</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#default-variations","title":"Default variations","text":"<p><code>_mlcommons</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#versions","title":"Versions","text":"<p>Default version: <code>r3.0</code></p> <ul> <li><code>r2.1</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-nvidia-code/#script-output","title":"Script output","text":"<pre><code>cmr \"get nvidia mlperf training code training-code [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/","title":"get-mlperf-training-src","text":"<p>Automatically generated README for this automation recipe: get-mlperf-training-src</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source training training-src training-source mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,training,training-src,training-source,mlperf,mlcommons[,variations] \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source training training-src training-source mlperf mlcommons [variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,training,training-src,training-source,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source training training-src training-source mlperf mlcommons[variations]\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_no-recurse-submodules</code><ul> <li>ENV variables:<ul> <li>CM_GIT_RECURSE_SUBMODULES: ``</li> </ul> </li> </ul> </li> <li><code>_nvidia-retinanet</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH_FILENAMES: <code>nvidia-retinanet.patch,cpu_load.patch</code></li> </ul> </li> </ul> </li> <li><code>_patch</code><ul> <li>ENV variables:<ul> <li>CM_GIT_PATCH: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"checkout\"      Click here to expand this section. <ul> <li><code>_branch.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_sha.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_SHA: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_tag.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_CHECKOUT_TAG: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"git-history\"      Click here to expand this section. <ul> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: ``</li> </ul> </li> </ul> </li> <li><code>_short-history</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 5</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"repo\"      Click here to expand this section. <ul> <li><code>_repo.#</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"src\"      Click here to expand this section. <ul> <li><code>_cknowledge</code> (default)<ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/cknowledge/training.git</code></li> </ul> </li> </ul> </li> <li><code>_mlcommons</code><ul> <li>ENV variables:<ul> <li>CM_GIT_URL: <code>https://github.com/mlcommons/training.git</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#default-variations","title":"Default variations","text":"<p><code>_cknowledge,_short-history</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>master</code></li> <li>CM_GIT_DEPTH: <code>--depth 4</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: <code>--recurse-submodules</code></li> <li>CM_GIT_CHECKOUT_FOLDER: <code>training</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>custom</code></li> <li><code>master</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-mlperf-training-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source training training-src training-source mlperf mlcommons [variations]\"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/","title":"get-nvidia-mitten","text":"<p>Automatically generated README for this automation recipe: get-nvidia-mitten</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get nvidia mitten nvidia-mitten\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,nvidia,mitten,nvidia-mitten \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get nvidia mitten nvidia-mitten \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,nvidia,mitten,nvidia-mitten'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get nvidia mitten nvidia-mitten\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-nvidia-mitten/#script-output","title":"Script output","text":"<pre><code>cmr \"get nvidia mitten nvidia-mitten \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/","title":"get-spec-ptd","text":"<p>Automatically generated README for this automation recipe: get-spec-ptd</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get spec ptd ptdaemon power daemon power-daemon mlperf mlcommons\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input FlagsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,spec,ptd,ptdaemon,power,daemon,power-daemon,mlperf,mlcommons [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get spec ptd ptdaemon power daemon power-daemon mlperf mlcommons \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,spec,ptd,ptdaemon,power,daemon,power-daemon,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get spec ptd ptdaemon power daemon power-daemon mlperf mlcommons\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#input-flags","title":"Input Flags","text":"<ul> <li>--input: Path to SPEC PTDaemon (Optional)</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_INPUT=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_GIT_CHECKOUT: <code>main</code></li> <li>CM_GIT_DEPTH: <code>--depth 1</code></li> <li>CM_GIT_PATCH: <code>no</code></li> <li>CM_GIT_RECURSE_SUBMODULES: <code></code></li> <li>CM_GIT_URL: <code>https://github.com/mlcommons/power.git</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#versions","title":"Versions","text":"<p>Default version: <code>main</code></p> <ul> <li><code>custom</code></li> <li><code>main</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/get-spec-ptd/#script-output","title":"Script output","text":"<pre><code>cmr \"get spec ptd ptdaemon power daemon power-daemon mlperf mlcommons \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/","title":"import-mlperf-inference-to-experiment","text":"<p>Automatically generated README for this automation recipe: import-mlperf-inference-to-experiment</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"import mlperf inference mlperf-inference experiment 2experiment to-experiment\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=import,mlperf,inference,mlperf-inference,experiment,2experiment,to-experiment[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"import mlperf inference mlperf-inference experiment 2experiment to-experiment [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'import,mlperf,inference,mlperf-inference,experiment,2experiment,to-experiment'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"import mlperf inference mlperf-inference experiment 2experiment to-experiment[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_skip_checker</code><ul> <li>ENV variables:<ul> <li>CM_SKIP_SUBMISSION_CHECKER: <code>True</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> <li><code>--target_repo=value</code>  \u2192  <code>CM_IMPORT_MLPERF_INFERENCE_TARGET_REPO=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-inference-to-experiment/#script-output","title":"Script output","text":"<pre><code>cmr \"import mlperf inference mlperf-inference experiment 2experiment to-experiment [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/","title":"import-mlperf-tiny-to-experiment","text":"<p>Automatically generated README for this automation recipe: import-mlperf-tiny-to-experiment</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"import mlperf tiny mlperf-tiny experiment 2experiment to-experiment\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=import,mlperf,tiny,mlperf-tiny,experiment,2experiment,to-experiment [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"import mlperf tiny mlperf-tiny experiment 2experiment to-experiment \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'import,mlperf,tiny,mlperf-tiny,experiment,2experiment,to-experiment'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"import mlperf tiny mlperf-tiny experiment 2experiment to-experiment\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--target_repo=value</code>  \u2192  <code>CM_IMPORT_TINYMLPERF_TARGET_REPO=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-tiny-to-experiment/#script-output","title":"Script output","text":"<pre><code>cmr \"import mlperf tiny mlperf-tiny experiment 2experiment to-experiment \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/","title":"import-mlperf-training-to-experiment","text":"<p>Automatically generated README for this automation recipe: import-mlperf-training-to-experiment</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"import mlperf training mlperf-training experiment 2experiment to-experiment\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=import,mlperf,training,mlperf-training,experiment,2experiment,to-experiment [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"import mlperf training mlperf-training experiment 2experiment to-experiment \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'import,mlperf,training,mlperf-training,experiment,2experiment,to-experiment'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"import mlperf training mlperf-training experiment 2experiment to-experiment\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--target_repo=value</code>  \u2192  <code>CM_IMPORT_MLPERF_TRAINING_TARGET_REPO=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run_mlperf_logger.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/import-mlperf-training-to-experiment/#script-output","title":"Script output","text":"<pre><code>cmr \"import mlperf training mlperf-training experiment 2experiment to-experiment \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/","title":"install-mlperf-logging-from-src","text":"<p>Automatically generated README for this automation recipe: install-mlperf-logging-from-src</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install mlperf logging from.src\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,mlperf,logging,from.src \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install mlperf logging from.src \" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,mlperf,logging,from.src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install mlperf logging from.src\" \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#versions","title":"Versions","text":"<ul> <li><code>master</code></li> <li><code>v3.1</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/install-mlperf-logging-from-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install mlperf logging from.src \"  -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/","title":"prepare-training-data-bert","text":"<p>Automatically generated README for this automation recipe: prepare-training-data-bert</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"prepare mlperf training data input bert\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=prepare,mlperf,training,data,input,bert[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"prepare mlperf training data input bert [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'prepare,mlperf,training,data,input,bert'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"prepare mlperf training data input bert[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#variations","title":"Variations","text":"<ul> <li> <p>Group \"implementation\"      Click here to expand this section. <ul> <li><code>_nvidia</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TMP_VARIATION: <code>nvidia</code></li> </ul> </li> </ul> </li> <li><code>_reference</code><ul> <li>ENV variables:<ul> <li>CM_TMP_VARIATION: <code>reference</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#default-variations","title":"Default variations","text":"<p><code>_nvidia</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_TRAINING_CLEAN_TFRECORDS=value</code></li> <li><code>--data_dir=value</code>  \u2192  <code>CM_DATA_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-nvidia.sh</li> <li>run-reference.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-bert/#script-output","title":"Script output","text":"<pre><code>cmr \"prepare mlperf training data input bert [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/","title":"prepare-training-data-resnet","text":"<p>Automatically generated README for this automation recipe: prepare-training-data-resnet</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"prepare mlperf training data input resnet\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=prepare,mlperf,training,data,input,resnet[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"prepare mlperf training data input resnet [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'prepare,mlperf,training,data,input,resnet'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"prepare mlperf training data input resnet[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_mxnet.#</code><ul> <li>ENV variables:<ul> <li>CM_MXNET_VERSION: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"implementation\"      Click here to expand this section. <ul> <li><code>_nvidia</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TMP_VARIATION: <code>nvidia</code></li> </ul> </li> </ul> </li> <li><code>_reference</code><ul> <li>ENV variables:<ul> <li>CM_TMP_VARIATION: <code>reference</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#default-variations","title":"Default variations","text":"<p><code>_nvidia</code></p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--data_dir=value</code>  \u2192  <code>CM_DATA_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-nvidia.sh</li> <li>run-reference.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/prepare-training-data-resnet/#script-output","title":"Script output","text":"<pre><code>cmr \"prepare mlperf training data input resnet [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/","title":"preprocess-mlperf-inference-submission","text":"<p>Automatically generated README for this automation recipe: preprocess-mlperf-inference-submission</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf inference submission mlperf-inference processor preprocessor preprocess\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,inference,submission,mlperf-inference,processor,preprocessor,preprocess [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference submission mlperf-inference processor preprocessor preprocess \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,inference,submission,mlperf-inference,processor,preprocessor,preprocess'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf inference submission mlperf-inference processor preprocessor preprocess\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/preprocess-mlperf-inference-submission/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference submission mlperf-inference processor preprocessor preprocess \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/","title":"process-mlperf-accuracy","text":"<p>Automatically generated README for this automation recipe: process-mlperf-accuracy</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlperf mlcommons accuracy mlc process process-accuracy\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlperf,mlcommons,accuracy,mlc,process,process-accuracy[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlperf mlcommons accuracy mlc process process-accuracy [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlperf,mlcommons,accuracy,mlc,process,process-accuracy'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlperf mlcommons accuracy mlc process process-accuracy[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#variations","title":"Variations","text":"<ul> <li> <p>Group \"coco-evaluation-tool\"      Click here to expand this section. <ul> <li><code>_default-pycocotools</code> (default)</li> <li><code>_nvidia-pycocotools</code></li> </ul> <li> <p>Group \"dataset\"      Click here to expand this section. <ul> <li><code>_cnndm</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>cnndm</code></li> </ul> </li> </ul> </li> <li><code>_coco2014</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>coco2014</code></li> </ul> </li> </ul> </li> <li><code>_imagenet</code> (default)<ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>imagenet</code></li> </ul> </li> </ul> </li> <li><code>_kits19</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>kits19</code></li> </ul> </li> </ul> </li> <li><code>_librispeech</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>librispeech</code></li> </ul> </li> </ul> </li> <li><code>_open-orca</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>openorca</code></li> </ul> </li> </ul> </li> <li><code>_openimages</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>openimages</code></li> </ul> </li> </ul> </li> <li><code>_squad</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>squad</code></li> </ul> </li> </ul> </li> <li><code>_terabyte</code><ul> <li>ENV variables:<ul> <li>CM_DATASET: <code>squad</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_float16</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>float16</code></li> </ul> </li> </ul> </li> <li><code>_float32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_float64</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>float64</code></li> </ul> </li> </ul> </li> <li><code>_int16</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>int16</code></li> </ul> </li> </ul> </li> <li><code>_int32</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>int32</code></li> </ul> </li> </ul> </li> <li><code>_int64</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>int64</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_ACCURACY_DTYPE: <code>int8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#default-variations","title":"Default variations","text":"<p><code>_default-pycocotools,_float32,_imagenet</code></p>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--result_dir=value</code>  \u2192  <code>CM_MLPERF_ACCURACY_RESULTS_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/process-mlperf-accuracy/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlperf mlcommons accuracy mlc process process-accuracy [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/","title":"push-mlperf-inference-results-to-github","text":"<p>Automatically generated README for this automation recipe: push-mlperf-inference-results-to-github</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"push mlperf mlperf-inference-results publish-results inference submission github\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=push,mlperf,mlperf-inference-results,publish-results,inference,submission,github [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"push mlperf mlperf-inference-results publish-results inference submission github \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'push,mlperf,mlperf-inference-results,publish-results,inference,submission,github'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"push mlperf mlperf-inference-results publish-results inference submission github\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--branch=value</code>  \u2192  <code>CM_GIT_BRANCH=value</code></li> <li><code>--commit_message=value</code>  \u2192  <code>CM_MLPERF_RESULTS_REPO_COMMIT_MESSAGE=value</code></li> <li><code>--repo_branch=value</code>  \u2192  <code>CM_GIT_BRANCH=value</code></li> <li><code>--repo_url=value</code>  \u2192  <code>CM_MLPERF_RESULTS_GIT_REPO_URL=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_RESULTS_GIT_REPO_URL: <code>https://github.com/ctuning/mlperf_inference_submissions_v4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/push-mlperf-inference-results-to-github/#script-output","title":"Script output","text":"<pre><code>cmr \"push mlperf mlperf-inference-results publish-results inference submission github \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/","title":"run-mlperf-inference-mobilenet-models","text":"<p>Automatically generated README for this automation recipe: run-mlperf-inference-mobilenet-models</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#set-up","title":"Set up","text":"<p>We need to get imagenet full dataset to make image-classification submissions for MLPerf inference. Since this dataset is not publicly available via a URL please follow the instructions given here to download the dataset and register in CM.  </p> Click here to set up docker (Optional).  ### Docker Setup  CM commands are expected to run natively but if you prefer not to modify the host system, you can do the below command to set up a docker container.   <pre><code>cm docker script --tags=run,mobilenet-models,_tflite,_accuracy-only \\\n--adr.compiler.tags=gcc  \\\n--docker_cm_repo=mlcommons@cm4mlops \\\n--imagenet_path=$HOME/imagenet-2012-val \\\n--results_dir=$HOME/mobilenet_results \\\n--submission_dir=$HOME/inference_submission_3.1 \\\n--docker_skip_run_cmd\n</code></pre>  This command will build a docker container and give you an interactive shell from which you can execute the below CM run commands. * `results_dir`, `submission_dir` and `imagenet_path` are mounted from the host system. * `results_dir` and `submission_dir` are expected to be empty directories to be populated by the docker * `imagenet_path` should point to the imagenet folder containing the 50000 validation images."},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-commands","title":"Run Commands","text":"<p>Since the runs can take many hours, in case you are running remotely you can install screen as follows. You may omit \"screen\" from all commands if you are running on a host system. <pre><code>cmr \"get generic-sys-util _screen\"\n</code></pre></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#default-tflite","title":"Default tflite","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#do-a-full-accuracy-run-for-all-the-models-can-take-almost-a-day","title":"Do a full accuracy run for all the models (can take almost a day)","text":"<pre><code>screen cmr \"run mobilenet-models _tflite _accuracy-only\" \\\n--adr.compiler.tags=gcc \\\n--results_dir=$HOME/mobilenet_results\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#do-a-full-performance-run-for-all-the-models-can-take-almost-a-day","title":"Do a full performance run for all the models (can take almost a day)","text":"<pre><code>screen cmr \"run mobilenet-models _tflite _performance-only\" \\\n--adr.compiler.tags=gcc \\\n--results_dir=$HOME/mobilenet_results \n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#generate-readme-files-for-all-the-runs","title":"Generate README files for all the runs","text":"<pre><code>cmr \"run mobilenet-models _tflite _populate-readme\" \\\n--adr.compiler.tags=gcc \\\n--results_dir=$HOME/mobilenet_results\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#generate-actual-submission-tree","title":"Generate actual submission tree","text":"<p>We should use the master branch of MLCommons inference repo for the submission checker. You can use <code>--hw_note_extra</code> option to add your name to the notes. <pre><code>cmr \"generate inference submission\" \\\n--results_dir=$HOME/mobilenet_results/valid_results \\\n--submission_dir=$HOME/mobilenet_submission_tree \\\n--clean \\\n--infer_scenario_results=yes \\\n--adr.compiler.tags=gcc --adr.inference-src.version=master \\\n--run-checker \\\n--submitter=cTuning \\\n--hw_notes_extra=\"Result taken by NAME\" \n</code></pre> * Use <code>--hw_name=\"My system name\"</code> to give a meaningful system name. Examples can be seen here</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#push-the-results-to-github-repo","title":"Push the results to GitHub repo","text":"<p>First, create a fork of this repo. Then run the following command after replacing <code>--repo_url</code> with your fork URL. <pre><code>cmr \"push github mlperf inference submission\" \\\n--submission_dir=$HOME/mobilenet_submission_tree \\\n--repo_url=https://github.com/ctuning/mlperf_inference_submissions_v3.1/ \\\n--commit_message=\"Mobilenet results added\"\n</code></pre></p> <p>Create a PR to cTuning repo</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#using-armnn-with-neon","title":"Using ARMNN with NEON","text":"<p>Follow the same procedure as above but for the first three experiment runs add <code>_armnn,_neon</code> to the tags. For example <pre><code>cmr \"run mobilenet-models _tflite _armnn _neon _accuracy-only\" \\\n--adr.compiler.tags=gcc \\\n--results_dir=$HOME/mobilenet_results\n</code></pre></p> <p><code>results_dir</code> and <code>submission_dir</code> can be the same as before as results will be going to different subfolders. </p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#using-armnn-with-opencl","title":"Using ARMNN with OpenCL","text":"<p>Follow the same procedure as above but for the first three experiment runs add <code>_armnn,_opencl</code> to the tags. For example <pre><code>cmr \"run mobilenet-models _tflite _armnn _opencl _accuracy-only\" \\\n--adr.compiler.tags=gcc \\\n--results_dir=$HOME/mobilenet_results\n</code></pre></p> <p><code>results_dir</code> and <code>submission_dir</code> can be the same as before as results will be going to different subfolders. </p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mobilenet models image-classification mobilenet-models mlperf inference\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mobilenet,models,image-classification,mobilenet-models,mlperf,inference[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mobilenet models image-classification mobilenet-models mlperf inference [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mobilenet,models,image-classification,mobilenet-models,mlperf,inference'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mobilenet models image-classification mobilenet-models mlperf inference[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_armnn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_USE_ARMNN_LIBRARY: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_neon</code><ul> <li>Aliases: <code>_use-neon</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_USE_NEON: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_only-fp32</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_RUN_INT8: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_only-int8</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_RUN_FP32: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_opencl</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_USE_OPENCL: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"base-framework\"      Click here to expand this section. <ul> <li><code>_tflite</code> (default)</li> </ul> <li> <p>Group \"model-selection\"      Click here to expand this section. <ul> <li><code>_all-models</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_RUN_MOBILENETS: <code>yes</code></li> <li>CM_MLPERF_RUN_EFFICIENTNETS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_efficientnet</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_RUN_EFFICIENTNETS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_mobilenet</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_RUN_MOBILENETS: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"optimization\"      Click here to expand this section. <ul> <li><code>_tflite-default</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_TFLITE_DEFAULT_MODE: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"run-mode\"      Click here to expand this section. <ul> <li><code>_accuracy-only</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>no</code></li> <li>CM_MLPERF_ACCURACY_MODE: <code>yes</code></li> <li>CM_MLPERF_SUBMISSION_MODE: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_find-performance</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>yes</code></li> <li>CM_MLPERF_SUBMISSION_MODE: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_performance-only</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>no</code></li> <li>CM_MLPERF_PERFORMANCE_MODE: <code>yes</code></li> <li>CM_MLPERF_SUBMISSION_MODE: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_populate-readme</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>no</code></li> <li>CM_MLPERF_POPULATE_README: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_submission</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>no</code></li> <li>CM_MLPERF_SUBMISSION_MODE: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#default-variations","title":"Default variations","text":"<p><code>_all-models,_tflite,_tflite-default</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--find-performance=value</code>  \u2192  <code>CM_MLPERF_FIND_PERFORMANCE_MODE=value</code></li> <li><code>--imagenet_path=value</code>  \u2192  <code>IMAGENET_PATH=value</code></li> <li><code>--no-rerun=value</code>  \u2192  <code>CM_MLPERF_NO_RERUN=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--results_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_RESULTS_DIR=value</code></li> <li><code>--submission=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_MODE=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_RUN_MOBILENETS: <code>no</code></li> <li>CM_MLPERF_RUN_EFFICIENTNETS: <code>no</code></li> <li>CM_MLPERF_NO_RERUN: <code>no</code></li> <li>CM_MLPERF_RUN_FP32: <code>yes</code></li> <li>CM_MLPERF_RUN_INT8: <code>yes</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-mobilenet-models/#script-output","title":"Script output","text":"<pre><code>cmr \"run mobilenet models image-classification mobilenet-models mlperf inference [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/","title":"run-mlperf-inference-submission-checker","text":"<p>Automatically generated README for this automation recipe: run-mlperf-inference-submission-checker</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference submission checker submission-checker mlc-submission-checker\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,inference,mlperf-inference,submission,checker,submission-checker,mlc-submission-checker[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference submission checker submission-checker mlc-submission-checker [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,inference,mlperf-inference,submission,checker,submission-checker,mlc-submission-checker'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf inference mlperf-inference submission checker submission-checker mlc-submission-checker[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_short-run</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SHORT_RUN: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--extra_args=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_CHECKER_EXTRA_ARGS=value</code></li> <li><code>--extra_model_benchmark_map=value</code>  \u2192  <code>CM_MLPERF_EXTRA_MODEL_MAPPING=value</code></li> <li><code>--input=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--push_to_github=value</code>  \u2192  <code>CM_MLPERF_RESULT_PUSH_TO_GITHUB=value</code></li> <li><code>--skip_compliance=value</code>  \u2192  <code>CM_MLPERF_SKIP_COMPLIANCE=value</code></li> <li><code>--skip_power_check=value</code>  \u2192  <code>CM_MLPERF_SKIP_POWER_CHECK=value</code></li> <li><code>--src_version=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_CHECKER_VERSION=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> <li><code>--tar=value</code>  \u2192  <code>CM_TAR_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_SHORT_RUN: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>master</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> <li><code>r4.0</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-inference-submission-checker/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference submission checker submission-checker mlc-submission-checker [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/","title":"run-mlperf-power-client","text":"<p>Automatically generated README for this automation recipe: run-mlperf-power-client</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf power client power-client\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,power,client,power-client [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf power client power-client \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,power,client,power-client'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf power client power-client\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--loadgen_logs_dir=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_LOGS_DIR=value</code></li> <li><code>--log_dir=value</code>  \u2192  <code>CM_MLPERF_POWER_LOG_DIR=value</code></li> <li><code>--max_amps=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_AMPS=value</code></li> <li><code>--max_volts=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_VOLTS=value</code></li> <li><code>--ntp_server=value</code>  \u2192  <code>CM_MLPERF_POWER_NTP_SERVER=value</code></li> <li><code>--port=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_PORT=value</code></li> <li><code>--power_server=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_ADDRESS=value</code></li> <li><code>--run_cmd=value</code>  \u2192  <code>CM_MLPERF_RUN_CMD=value</code></li> <li><code>--server=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_ADDRESS=value</code></li> <li><code>--server_port=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_PORT=value</code></li> <li><code>--timestamp=value</code>  \u2192  <code>CM_MLPERF_POWER_TIMESTAMP=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_POWER_LOG_DIR: <code>logs</code></li> <li>CM_MLPERF_RUN_CMD: ``</li> <li>CM_MLPERF_POWER_SERVER_ADDRESS: <code>localhost</code></li> <li>CM_MLPERF_POWER_NTP_SERVER: <code>time.google.com</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-client/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf power client power-client \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/","title":"run-mlperf-power-server","text":"<p>Automatically generated README for this automation recipe: run-mlperf-power-server</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf power server power-server\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,power,server,power-server [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf power server power-server \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,power,server,power-server'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf power server power-server\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--device_port=value</code>  \u2192  <code>CM_MLPERF_POWER_DEVICE_PORT=value</code></li> <li><code>--device_type=value</code>  \u2192  <code>CM_MLPERF_POWER_DEVICE_TYPE=value</code></li> <li><code>--interface_flag=value</code>  \u2192  <code>CM_MLPERF_POWER_INTERFACE_FLAG=value</code></li> <li><code>--ntp_server=value</code>  \u2192  <code>CM_MLPERF_POWER_NTP_SERVER=value</code></li> <li><code>--screen=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_USE_SCREEN=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_POWER_NTP_SERVER: <code>time.google.com</code></li> <li>CM_MLPERF_POWER_INTERFACE_FLAG: ``</li> <li>CM_MLPERF_POWER_DEVICE_TYPE: <code>49</code></li> <li>CM_MLPERF_POWER_SERVER_ADDRESS: <code>0.0.0.0</code></li> <li>CM_MLPERF_POWER_SERVER_PORT: <code>4950</code></li> <li>CM_MLPERF_POWER_DEVICE_PORT: <code>/dev/usbtmc0</code></li> <li>CM_MLPERF_POWER_SERVER_USE_SCREEN: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-power-server/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf power server power-server \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/","title":"run-mlperf-training-submission-checker","text":"<p>Automatically generated README for this automation recipe: run-mlperf-training-submission-checker</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf training train mlperf-training submission checker submission-checker mlc-submission-checker\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,training,train,mlperf-training,submission,checker,submission-checker,mlc-submission-checker[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf training train mlperf-training submission checker submission-checker mlc-submission-checker [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,training,train,mlperf-training,submission,checker,submission-checker,mlc-submission-checker'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf training train mlperf-training submission checker submission-checker mlc-submission-checker[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_short-run</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SHORT_RUN: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--extra_args=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_CHECKER_EXTRA_ARGS=value</code></li> <li><code>--input=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_DIR=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--push_to_github=value</code>  \u2192  <code>CM_MLPERF_RESULT_PUSH_TO_GITHUB=value</code></li> <li><code>--skip_compliance=value</code>  \u2192  <code>CM_MLPERF_SKIP_COMPLIANCE=value</code></li> <li><code>--skip_power_check=value</code>  \u2192  <code>CM_MLPERF_SKIP_POWER_CHECK=value</code></li> <li><code>--src_version=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_CHECKER_VERSION=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> <li><code>--tar=value</code>  \u2192  <code>CM_TAR_SUBMISSION_DIR=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_SHORT_RUN: <code>no</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#versions","title":"Versions","text":"<p>Default version: <code>master</code></p> <ul> <li><code>master</code></li> <li><code>r3.0</code></li> <li><code>r3.1</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/run-mlperf-training-submission-checker/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf training train mlperf-training submission checker submission-checker mlc-submission-checker [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/","title":"truncate-mlperf-inference-accuracy-log","text":"<p>Automatically generated README for this automation recipe: truncate-mlperf-inference-accuracy-log</p> <p>Category: MLPerf benchmark support</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference truncation truncator truncate accuracy accuracy-log accuracy-log-trancation accuracy-log-truncator mlc-accuracy-log-trancation mlc-accuracy-log-truncator\" --help</code></p>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,mlc,mlcommons,mlperf,inference,mlperf-inference,truncation,truncator,truncate,accuracy,accuracy-log,accuracy-log-trancation,accuracy-log-truncator,mlc-accuracy-log-trancation,mlc-accuracy-log-truncator [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference truncation truncator truncate accuracy accuracy-log accuracy-log-trancation accuracy-log-truncator mlc-accuracy-log-trancation mlc-accuracy-log-truncator \" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,mlc,mlcommons,mlperf,inference,mlperf-inference,truncation,truncator,truncate,accuracy,accuracy-log,accuracy-log-trancation,accuracy-log-truncator,mlc-accuracy-log-trancation,mlc-accuracy-log-truncator'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run mlc mlcommons mlperf inference mlperf-inference truncation truncator truncate accuracy accuracy-log accuracy-log-trancation accuracy-log-truncator mlc-accuracy-log-trancation mlc-accuracy-log-truncator\" [--input_flags]\n</code></pre>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> </ul>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/MLPerf-benchmark-support/truncate-mlperf-inference-accuracy-log/#script-output","title":"Script output","text":"<pre><code>cmr \"run mlc mlcommons mlperf inference mlperf-inference truncation truncator truncate accuracy accuracy-log accuracy-log-trancation accuracy-log-truncator mlc-accuracy-log-trancation mlc-accuracy-log-truncator \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/","title":"Modular-AI-ML-application-pipeline","text":"<ul> <li>app-image-classification-onnx-py</li> <li>app-image-classification-tf-onnx-cpp</li> <li>app-image-classification-torch-py</li> <li>app-image-classification-tvm-onnx-py</li> <li>app-stable-diffusion-onnx-py</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/","title":"app-image-classification-onnx-py","text":"<p>Automatically generated README for this automation recipe: app-image-classification-onnx-py</p> <p>Category: Modular AI/ML application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"modular python app image-classification onnx\" --help</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag MappingDefault environment"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=modular,python,app,image-classification,onnx[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"modular python app image-classification onnx [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'modular,python,app,image-classification,onnx'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"modular python app image-classification onnx[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#variations","title":"Variations","text":"<ul> <li> <p>Group \"target\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>USE_CPU: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>USE_CUDA: <code>True</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#default-variations","title":"Default variations","text":"<p><code>_cpu</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#input-flags","title":"Input Flags","text":"<ul> <li>--input: Path to JPEG image to classify</li> <li>--output: Output directory (optional)</li> <li>--j: Print JSON output</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--input=value</code>  \u2192  <code>CM_IMAGE=value</code></li> <li><code>--output=value</code>  \u2192  <code>CM_APP_IMAGE_CLASSIFICATION_ONNX_PY_OUTPUT=value</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-onnx-py/#script-output","title":"Script output","text":"<pre><code>cmr \"modular python app image-classification onnx [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/","title":"app-image-classification-tf-onnx-cpp","text":"<p>Automatically generated README for this automation recipe: app-image-classification-tf-onnx-cpp</p> <p>Category: Modular AI/ML application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app image-classification cpp tensorflow onnx\" --help</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,image-classification,cpp,tensorflow,onnx \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app image-classification cpp tensorflow onnx \" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,image-classification,cpp,tensorflow,onnx'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app image-classification cpp tensorflow onnx\" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tf-onnx-cpp/#script-output","title":"Script output","text":"<pre><code>cmr \"app image-classification cpp tensorflow onnx \"  -j\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/","title":"app-image-classification-torch-py","text":"<p>Automatically generated README for this automation recipe: app-image-classification-torch-py</p> <p>Category: Modular AI/ML application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app image-classification python torch\" --help</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,image-classification,python,torch[,variations] \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app image-classification python torch [variations]\" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,image-classification,python,torch'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app image-classification python torch[variations]\" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>USE_CUDA: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-torch-py/#script-output","title":"Script output","text":"<pre><code>cmr \"app image-classification python torch [variations]\"  -j\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/","title":"app-image-classification-tvm-onnx-py","text":"<p>Automatically generated README for this automation recipe: app-image-classification-tvm-onnx-py</p> <p>Category: Modular AI/ML application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app image-classification python tvm-onnx\" --help</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,image-classification,python,tvm-onnx[,variations] \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app image-classification python tvm-onnx [variations]\" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,image-classification,python,tvm-onnx'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app image-classification python tvm-onnx[variations]\" \n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>USE_CUDA: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_llvm</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-image-classification-tvm-onnx-py/#script-output","title":"Script output","text":"<pre><code>cmr \"app image-classification python tvm-onnx [variations]\"  -j\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/","title":"app-stable-diffusion-onnx-py","text":"<p>Automatically generated README for this automation recipe: app-stable-diffusion-onnx-py</p> <p>Category: Modular AI/ML application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"modular python app stable-diffusion onnx\" --help</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag Mapping"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=modular,python,app,stable-diffusion,onnx[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"modular python app stable-diffusion onnx [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'modular,python,app,stable-diffusion,onnx'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"modular python app stable-diffusion onnx[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#variations","title":"Variations","text":"<ul> <li> <p>Group \"target\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>USE_CPU: <code>True</code></li> <li>CM_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>USE_CUDA: <code>True</code></li> <li>CM_DEVICE: <code>cuda:0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#default-variations","title":"Default variations","text":"<p><code>_cpu</code></p>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#input-flags","title":"Input Flags","text":"<ul> <li>--text: Text to generate image</li> <li>--output: Output directory</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--output=value</code>  \u2192  <code>CM_APP_STABLE_DIFFUSION_ONNX_PY_OUTPUT=value</code></li> <li><code>--text=value</code>  \u2192  <code>CM_APP_STABLE_DIFFUSION_ONNX_PY_TEXT=value</code></li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Modular-AI-ML-application-pipeline/app-stable-diffusion-onnx-py/#script-output","title":"Script output","text":"<pre><code>cmr \"modular python app stable-diffusion onnx [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/","title":"Modular-MLPerf-benchmarks","text":"<ul> <li>app-mlperf-inference-dummy</li> <li>app-mlperf-inference-intel</li> <li>app-mlperf-inference-qualcomm</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/","title":"app-mlperf-inference-dummy","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-dummy</p> <p>Category: Modular MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce mlcommons mlperf inference harness dummy-harness dummy\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,mlcommons,mlperf,inference,harness,dummy-harness,dummy[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness dummy-harness dummy [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,mlcommons,mlperf,inference,harness,dummy-harness,dummy'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce mlcommons mlperf inference harness dummy-harness dummy[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#variations","title":"Variations","text":"<ul> <li> <p>Group \"backend\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_bs.#</code></li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99.9</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99.9</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp16</code></li> <li><code>_fp32</code></li> <li><code>_uint8</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#default-variations","title":"Default variations","text":"<p><code>_cpu,_pytorch,_resnet50</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--results_repo=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_RESULTS_REPO=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--skip_preprocess=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--skip_preprocessing=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_SKIP_PREPROCESS_DATASET: <code>no</code></li> <li>CM_SKIP_MODEL_DOWNLOAD: <code>no</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>dummy_harness</code></li> <li>CM_MLPERF_SKIP_RUN: <code>no</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-dummy/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness dummy-harness dummy [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/","title":"app-mlperf-inference-intel","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-intel</p> <p>Category: Modular MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce mlcommons mlperf inference harness intel-harness intel intel-harness intel\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,mlcommons,mlperf,inference,harness,intel-harness,intel,intel-harness,intel[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness intel-harness intel intel-harness intel [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,mlcommons,mlperf,inference,harness,intel-harness,intel,intel-harness,intel'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce mlcommons mlperf inference harness intel-harness intel intel-harness intel[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_bs.#</code><ul> <li>ENV variables:<ul> <li>ML_MLPERF_MODEL_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_v3.1</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_CODE_VERSION: <code>v3.1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> <li>CM_MLPERF_BACKEND_LIB_NAMESPEC: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-batchsize\"      Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3750364/files/bert_large_v1_1_fake_quant.onnx</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3733910/files/model.onnx</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3733910/files/model.onnx</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99.9</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3733910/files/model.onnx</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> <li>dataset_imagenet_preprocessed_input_square_side: <code>224</code></li> <li>ml_model_has_background_class: <code>YES</code></li> <li>ml_model_image_height: <code>224</code></li> <li>loadgen_buffer_size: <code>1024</code></li> <li>loadgen_dataset_size: <code>50000</code></li> <li>CM_BENCHMARK: <code>STANDALONE_CLASSIFICATION</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/6617981/files/resnext50_32x4d_fpn.pth</code></li> <li>dataset_imagenet_preprocessed_input_square_side: <code>224</code></li> <li>ml_model_image_height: <code>800</code></li> <li>ml_model_image_width: <code>800</code></li> <li>loadgen_buffer_size: <code>64</code></li> <li>loadgen_dataset_size: <code>24576</code></li> <li>CM_BENCHMARK: <code>STANDALONE_OBJECT_DETECTION</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"network-mode\"      Click here to expand this section. <ul> <li><code>_network-server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NETWORK_RUN_MODE: <code>network-server</code></li> </ul> </li> </ul> </li> <li><code>_standalone</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_NETWORK_RUN_MODE: <code>standalone</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"network-run-mode\"      Click here to expand this section. <ul> <li><code>_network-client</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NETWORK_RUN_MODE: <code>network-client</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"power-mode\"      Click here to expand this section. <ul> <li><code>_maxn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXN: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_maxq</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXQ: <code>True</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code><ul> <li>ENV variables:<ul> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_int4</code></li> <li><code>_uint8</code></li> </ul> <li> <p>Group \"run-mode\"      Click here to expand this section. <ul> <li><code>_build-harness</code><ul> <li>ENV variables:<ul> <li>CM_LOCAL_MLPERF_INFERENCE_INTEL_RUN_MODE: <code>build_harness</code></li> </ul> </li> </ul> </li> <li><code>_calibration</code><ul> <li>ENV variables:<ul> <li>CM_LOCAL_MLPERF_INFERENCE_INTEL_RUN_MODE: <code>calibration</code></li> </ul> </li> </ul> </li> <li><code>_run-harness</code> (default)<ul> <li>ENV variables:<ul> <li>CM_LOCAL_MLPERF_INFERENCE_INTEL_RUN_MODE: <code>run_harness</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"sut\"      Click here to expand this section. <ul> <li><code>_sapphire-rapids.112c</code><ul> <li>ENV variables:<ul> <li>WARMUP: <code>--warmup</code></li> </ul> </li> </ul> </li> <li><code>_sapphire-rapids.24c</code></li> </ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_v4.0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_CODE_VERSION: <code>v4.0</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#default-variations","title":"Default variations","text":"<p><code>_cpu,_pytorch,_resnet50,_run-harness,_standalone,_v4.0</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--skip_preprocess=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--skip_preprocessing=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> <li>CM_FAST_COMPILATION: <code>yes</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_SKIP_PREPROCESS_DATASET: <code>no</code></li> <li>CM_SKIP_MODEL_DOWNLOAD: <code>no</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>intel</code></li> <li>CM_MLPERF_SKIP_RUN: <code>no</code></li> <li>verbosity: <code>1</code></li> <li>loadgen_trigger_cold_run: <code>0</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run_bert_harness.sh</li> <li>run_gptj_harness_v3_1.sh</li> <li>run_gptj_harness_v4_0.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-intel/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness intel-harness intel intel-harness intel [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/","title":"app-mlperf-inference-qualcomm","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-qualcomm</p> <p>Category: Modular MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce mlcommons mlperf inference harness qualcomm-harness qualcomm kilt-harness kilt\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,mlcommons,mlperf,inference,harness,qualcomm-harness,qualcomm,kilt-harness,kilt[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness qualcomm-harness qualcomm kilt-harness kilt [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,mlcommons,mlperf,inference,harness,qualcomm-harness,qualcomm,kilt-harness,kilt'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce mlcommons mlperf inference harness qualcomm-harness qualcomm kilt-harness kilt[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_activation-count.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QAIC_ACTIVATION_COUNT: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_num-devices.4</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_DEVICES: <code>0,1,2,3</code></li> </ul> </li> </ul> </li> <li><code>_pro</code><ul> <li>ENV variables:<ul> <li>qaic_queue_length: <code>10</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_bs.#</code><ul> <li>ENV variables:<ul> <li>kilt_model_batch_size: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_bs.0</code><ul> <li>ENV variables:<ul> <li>kilt_model_batch_size: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> <li>kilt_backend_type: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> <li>kilt_backend_type: <code>gpu</code></li> </ul> </li> </ul> </li> <li><code>_qaic</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>qaic</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>QAic</code></li> <li>kilt_backend_type: <code>qaic</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_glow</code><ul> <li>ENV variables:<ul> <li>device: <code>qaic</code></li> <li>CM_MLPERF_BACKEND: <code>glow</code></li> <li>CM_MLPERF_BACKEND_LIB_NAMESPEC: <code>QAic</code></li> </ul> </li> </ul> </li> <li><code>_onnxruntime</code> (default)<ul> <li>ENV variables:<ul> <li>device: <code>onnxrt</code></li> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> <li>CM_MLPERF_BACKEND_LIB_NAMESPEC: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_tensorrt</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tensorrt</code></li> <li>device: <code>tensorrt</code></li> <li>CM_MLPERF_BACKEND_NAME: <code>TensorRT</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-batch-size\"      Click here to expand this section. <ul> <li><code>_loadgen-batch-size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3750364/files/bert_large_v1_1_fake_quant.onnx</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3733910/files/model.onnx</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> <li>kilt_model_name: <code>resnet50</code></li> <li>kilt_input_count: <code>1</code></li> <li>kilt_output_count: <code>1</code></li> <li>kilt_input_format: <code>FLOAT32,-1,224,224,3</code></li> <li>kilt_output_format: <code>INT64,-1</code></li> <li>dataset_imagenet_preprocessed_input_square_side: <code>224</code></li> <li>ml_model_has_background_class: <code>YES</code></li> <li>ml_model_image_height: <code>224</code></li> <li>loadgen_buffer_size: <code>1024</code></li> <li>loadgen_dataset_size: <code>50000</code></li> <li>CM_BENCHMARK: <code>STANDALONE_CLASSIFICATION</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/6617981/files/resnext50_32x4d_fpn.pth</code></li> <li>kilt_model_name: <code>retinanet</code></li> <li>kilt_input_count: <code>1</code></li> <li>kilt_model_max_detections: <code>600</code></li> <li>kilt_output_count: <code>1</code></li> <li>kilt_input_format: <code>FLOAT32,-1,3,800,800</code></li> <li>kilt_output_format: <code>INT64,-1</code></li> <li>dataset_imagenet_preprocessed_input_square_side: <code>224</code></li> <li>ml_model_image_height: <code>800</code></li> <li>ml_model_image_width: <code>800</code></li> <li>loadgen_buffer_size: <code>64</code></li> <li>loadgen_dataset_size: <code>24576</code></li> <li>CM_BENCHMARK: <code>STANDALONE_OBJECT_DETECTION</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"nsp\"      Click here to expand this section. <ul> <li><code>_nsp.#</code></li> <li><code>_nsp.14</code></li> <li><code>_nsp.16</code></li> </ul> <li> <p>Group \"power-mode\"      Click here to expand this section. <ul> <li><code>_maxn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXN: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_maxq</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXQ: <code>True</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp16</code></li> <li><code>_fp32</code><ul> <li>ENV variables:<ul> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code></li> </ul> <li> <p>Group \"run-mode\"      Click here to expand this section. <ul> <li><code>_network-client</code><ul> <li>ENV variables:<ul> <li>CM_RUN_MODE: <code>network-client</code></li> </ul> </li> </ul> </li> <li><code>_network-server</code><ul> <li>ENV variables:<ul> <li>CM_RUN_MODE: <code>network-server</code></li> </ul> </li> </ul> </li> <li><code>_standalone</code> (default)<ul> <li>ENV variables:<ul> <li>CM_RUN_MODE: <code>standalone</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"sut\"      Click here to expand this section. <ul> <li><code>_dl2q.24xlarge</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_DEVICES: <code>0,1,2,3,4,5,6,7</code></li> <li>qaic_queue_length: <code>4</code></li> </ul> </li> </ul> </li> <li><code>_rb6</code><ul> <li>ENV variables:<ul> <li>CM_QAIC_DEVICES: <code>0</code></li> <li>qaic_queue_length: <code>6</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#default-variations","title":"Default variations","text":"<p><code>_cpu,_onnxruntime,_resnet50,_standalone</code></p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--devices=value</code>  \u2192  <code>CM_QAIC_DEVICES=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--skip_preprocess=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--skip_preprocessing=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> <li>CM_FAST_COMPILATION: <code>yes</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_SKIP_PREPROCESS_DATASET: <code>no</code></li> <li>CM_SKIP_MODEL_DOWNLOAD: <code>no</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>kilt</code></li> <li>CM_MLPERF_SKIP_RUN: <code>no</code></li> <li>CM_KILT_REPO_URL: <code>https://github.com/GATEOverflow/kilt-mlperf</code></li> <li>CM_QAIC_DEVICES: <code>0</code></li> <li>kilt_max_wait_abs: <code>10000</code></li> <li>verbosity: <code>0</code></li> <li>loadgen_trigger_cold_run: <code>0</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-benchmarks/app-mlperf-inference-qualcomm/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness qualcomm-harness qualcomm kilt-harness kilt [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/","title":"Modular-MLPerf-inference-benchmark-pipeline","text":"<ul> <li>app-loadgen-generic-python</li> <li>app-mlperf-inference</li> <li>app-mlperf-inference-ctuning-cpp-tflite</li> <li>app-mlperf-inference-mlcommons-cpp</li> <li>app-mlperf-inference-mlcommons-python</li> <li>benchmark-program-mlperf</li> <li>run-mlperf-inference-app</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/","title":"app-loadgen-generic-python","text":"<p>Automatically generated README for this automation recipe: app-loadgen-generic-python</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <p>Developers: Gaz Iqbal, Arjun Suresh, Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"python app generic loadgen\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=python,app,generic,loadgen[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"python app generic loadgen [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'python,app,generic,loadgen'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"python app generic loadgen[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cmc</code><ul> <li>ENV variables:<ul> <li>CM_CUSTOM_MODEL_CMC: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_huggingface</code><ul> <li>ENV variables:<ul> <li>CM_CUSTOM_MODEL_SOURCE: <code>huggingface</code></li> </ul> </li> </ul> </li> <li><code>_model-stub.#</code><ul> <li>ENV variables:<ul> <li>CM_ML_MODEL_STUB: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"backend\"      Click here to expand this section. <ul> <li><code>_onnxruntime</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> <li>CM_MLPERF_EXECUTION_PROVIDER: <code>CPUExecutionProvider</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_EXECUTION_PROVIDER: <code>CUDAExecutionProvider</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"models\"      Click here to expand this section. <ul> <li><code>_custom</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>custom</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#default-variations","title":"Default variations","text":"<p><code>_cpu,_onnxruntime</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#input-flags","title":"Input Flags","text":"<ul> <li>--modelpath: Full path to file with model weights</li> <li>--modelcodepath: (for PyTorch models) Full path to file with model code and cmc.py</li> <li>--modelcfgpath: (for PyTorch models) Full path to JSON file with model cfg</li> <li>--modelsamplepath: (for PyTorch models) Full path to file with model sample in pickle format</li> <li>--ep: ONNX Execution provider</li> <li>--scenario: MLPerf LoadGen scenario</li> <li>--samples: Number of samples (2)</li> <li>--runner: MLPerf runner</li> <li>--execmode: MLPerf exec mode</li> <li>--output_dir: MLPerf output directory</li> <li>--concurrency: MLPerf concurrency</li> <li>--intraop: MLPerf intra op threads</li> <li>--interop: MLPerf inter op threads</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--concurrency=value</code>  \u2192  <code>CM_MLPERF_CONCURRENCY=value</code></li> <li><code>--ep=value</code>  \u2192  <code>CM_MLPERF_EXECUTION_PROVIDER=value</code></li> <li><code>--execmode=value</code>  \u2192  <code>CM_MLPERF_EXEC_MODE=value</code></li> <li><code>--interop=value</code>  \u2192  <code>CM_MLPERF_INTEROP=value</code></li> <li><code>--intraop=value</code>  \u2192  <code>CM_MLPERF_INTRAOP=value</code></li> <li><code>--loadgen_duration_sec=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_DURATION_SEC=value</code></li> <li><code>--loadgen_expected_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_EXPECTED_QPS=value</code></li> <li><code>--modelcfg=value</code>  \u2192  <code>CM_ML_MODEL_CFG=value</code></li> <li><code>--modelcfgpath=value</code>  \u2192  <code>CM_ML_MODEL_CFG_WITH_PATH=value</code></li> <li><code>--modelcodepath=value</code>  \u2192  <code>CM_ML_MODEL_CODE_WITH_PATH=value</code></li> <li><code>--modelpath=value</code>  \u2192  <code>CM_ML_MODEL_FILE_WITH_PATH=value</code></li> <li><code>--modelsamplepath=value</code>  \u2192  <code>CM_ML_MODEL_SAMPLE_WITH_PATH=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--runner=value</code>  \u2192  <code>CM_MLPERF_RUNNER=value</code></li> <li><code>--samples=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SAMPLES=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_EXECUTION_MODE: <code>parallel</code></li> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-loadgen-generic-python/#script-output","title":"Script output","text":"<pre><code>cmr \"python app generic loadgen [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/","title":"app-mlperf-inference","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <p>Developers: Arjun Suresh, Thomas Zhu, Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <p>\ufeffThis CM script provides a unified interface to prepare and run a modular version of the MLPerf inference benchmark across diverse ML models, data sets, frameworks, libraries, run-time systems and platforms using the cross-platform automation meta-framework (MLCommons CM).</p> <p>It is assembled from reusable and interoperable CM scripts for DevOps and MLOps being developed by the open MLCommons taskforce on automation and reproducibility.</p> <p>It is a higher-level wrapper to several other CM scripts modularizing the MLPerf inference benchmark: * Reference Python implementation * Universal C++ implementation * TFLite C++ implementation * NVidia optimized implementation</p> <p>See this SCC'23 tutorial  to use this script to run a reference (unoptimized) Python implementation of the MLPerf object detection benchmark  with RetinaNet model, Open Images dataset, ONNX runtime and CPU target.</p> <p>See this CM script to automate and validate your MLPerf inference submission.</p> <p>Get in touch with the open taskforce on automation and reproducibility at MLCommons if you need help with your submission or if you would like to participate in further modularization of MLPerf  and collaborative design space exploration and optimization of ML Systems.</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app vision language mlcommons mlperf inference generic\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,vision,language,mlcommons,mlperf,inference,generic[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app vision language mlcommons mlperf inference generic [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,vision,language,mlcommons,mlperf,inference,generic'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app vision language mlcommons mlperf inference generic[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#variations","title":"Variations","text":"<ul> <li> <p>Group \"implementation\"      Click here to expand this section. <ul> <li><code>_cpp</code><ul> <li>Aliases: <code>_mil,_mlcommons-cpp</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_CPP: <code>yes</code></li> <li>CM_MLPERF_IMPLEMENTATION: <code>mlcommons_cpp</code></li> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_OPENIMAGES_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_intel-original</code><ul> <li>Aliases: <code>_intel</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_IMPLEMENTATION: <code>intel</code></li> </ul> </li> </ul> </li> <li><code>_kilt</code><ul> <li>Aliases: <code>_qualcomm</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_IMPLEMENTATION: <code>qualcomm</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-original</code><ul> <li>Aliases: <code>_nvidia</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_IMPLEMENTATION: <code>nvidia</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float16</code></li> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>int32</code></li> <li>CM_CNNDM_ACCURACY_DTYPE: <code>int32</code></li> <li>CM_LIBRISPEECH_ACCURACY_DTYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_reference</code> (default)<ul> <li>Aliases: <code>_mlcommons-python,_python</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_PYTHON: <code>yes</code></li> <li>CM_MLPERF_IMPLEMENTATION: <code>mlcommons_python</code></li> <li>CM_SQUAD_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_OPENIMAGES_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_LIBRISPEECH_ACCURACY_DTYPE: <code>float32</code></li> <li>CM_CNNDM_ACCURACY_DTYPE: <code>int32</code></li> </ul> </li> </ul> </li> <li><code>_tflite-cpp</code><ul> <li>Aliases: <code>_ctuning-cpp-tflite</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_TFLITE_CPP: <code>yes</code></li> <li>CM_MLPERF_CPP: <code>yes</code></li> <li>CM_MLPERF_IMPLEMENTATION: <code>ctuning_cpp_tflite</code></li> <li>CM_IMAGENET_ACCURACY_DTYPE: <code>float32</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"backend\"      Click here to expand this section. <ul> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>deepsparse</code></li> </ul> </li> </ul> </li> <li><code>_glow</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>glow</code></li> </ul> </li> </ul> </li> <li><code>_ncnn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>ncnn</code></li> </ul> </li> </ul> </li> <li><code>_onnxruntime</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> </ul> </li> </ul> </li> <li><code>_ray</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>ray</code></li> </ul> </li> </ul> </li> <li><code>_tensorrt</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tensorrt</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tflite</code></li> </ul> </li> </ul> </li> <li><code>_tvm-onnx</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-onnx</code></li> </ul> </li> </ul> </li> <li><code>_tvm-pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-pytorch</code></li> </ul> </li> </ul> </li> <li><code>_tvm-tflite</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-tflite</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> </ul> </li> </ul> </li> <li><code>_qaic</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>qaic</code></li> </ul> </li> </ul> </li> <li><code>_rocm</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>rocm</code></li> </ul> </li> </ul> </li> <li><code>_tpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>tpu</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_3d-unet-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99</code></li> </ul> </li> </ul> </li> <li><code>_3d-unet-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99.9</code></li> </ul> </li> </ul> </li> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-v2-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-v2-99</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-v2-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-v2-99.9</code></li> </ul> </li> </ul> </li> <li><code>_efficientnet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>efficientnet</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99.9</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99.9</code></li> </ul> </li> </ul> </li> <li><code>_mobilenet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>mobilenet</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> </ul> </li> </ul> </li> <li><code>_rnnt</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>rnnt</code></li> </ul> </li> </ul> </li> <li><code>_sdxl</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>stable-diffusion-xl</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_bfloat16</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_float16</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_float32</code> (default)<ul> <li>Aliases: <code>_fp32</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_int4</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>True</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>int4</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>Aliases: <code>_quantized</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>True</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>True</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>uint8</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"execution-mode\"      Click here to expand this section. <ul> <li><code>_fast</code><ul> <li>ENV variables:<ul> <li>CM_FAST_FACTOR: <code>5</code></li> <li>CM_OUTPUT_FOLDER_NAME: <code>fast_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>fast</code></li> </ul> </li> </ul> </li> <li><code>_test</code> (default)<ul> <li>ENV variables:<ul> <li>CM_OUTPUT_FOLDER_NAME: <code>test_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>test</code></li> </ul> </li> </ul> </li> <li><code>_valid</code><ul> <li>ENV variables:<ul> <li>CM_OUTPUT_FOLDER_NAME: <code>valid_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>valid</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"reproducibility\"      Click here to expand this section. <ul> <li><code>_r2.1_default</code><ul> <li>ENV variables:<ul> <li>CM_SKIP_SYS_UTILS: <code>yes</code></li> <li>CM_TEST_QUERY_COUNT: <code>100</code></li> </ul> </li> </ul> </li> <li><code>_r3.0_default</code><ul> <li>ENV variables:<ul> <li>CM_SKIP_SYS_UTILS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_r3.1_default</code></li> <li><code>_r4.0_default</code><ul> <li>ENV variables:<ul> <li>CM_ENV_NVMITTEN_DOCKER_WHEEL_PATH: <code>/opt/nvmitten-0.1.3-cp38-cp38-linux_x86_64.whl</code></li> </ul> </li> </ul> </li> <li><code>_r4.1_default</code><ul> <li>ENV variables:<ul> <li>CM_ENV_NVMITTEN_DOCKER_WHEEL_PATH: <code>/opt/nvmitten-0.1.3b0-cp38-cp38-linux_x86_64.whl</code></li> </ul> </li> </ul> </li> </ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_power</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_POWER: <code>yes</code></li> <li>CM_SYSTEM_POWER: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch_size\"      Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_MAX_BATCHSIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#default-variations","title":"Default variations","text":"<p><code>_cpu,_float32,_offline,_reference,_resnet50,_test</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#input-flags","title":"Input Flags","text":"<ul> <li>--scenario: MLPerf inference scenario {Offline,Server,SingleStream,MultiStream} (Offline)</li> <li>--mode: MLPerf inference mode {performance,accuracy} (accuracy)</li> <li>--test_query_count: Specifies the number of samples to be processed during a test run</li> <li>--target_qps: Target QPS</li> <li>--target_latency: Target Latency</li> <li>--max_batchsize: Maximum batchsize to be used</li> <li>--num_threads: Number of CPU threads to launch the application with</li> <li>--hw_name: Valid value - any system description which has a config file (under same name) defined here</li> <li>--output_dir: Location where the outputs are produced</li> <li>--rerun: Redo the run even if previous run files exist (True)</li> <li>--regenerate_files: Regenerates measurement files including accuracy.txt files even if a previous run exists. This option is redundant if <code>--rerun</code> is used</li> <li>--adr.python.name: Python virtual environment name (optional) (mlperf)</li> <li>--adr.python.version_min: Minimal Python version (3.8)</li> <li>--adr.python.version: Force Python version (must have all system deps)</li> <li>--adr.compiler.tags: Compiler for loadgen (gcc)</li> <li>--adr.inference-src-loadgen.env.CM_GIT_URL: Git URL for MLPerf inference sources to build LoadGen (to enable non-reference implementations)</li> <li>--adr.inference-src.env.CM_GIT_URL: Git URL for MLPerf inference sources to run benchmarks (to enable non-reference implementations)</li> <li>--quiet: Quiet run (select default values for all questions) (False)</li> <li>--readme: Generate README with the reproducibility report</li> <li>--debug: Debug MLPerf script</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_SUBMISSION_DIR=value</code></li> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--debug=value</code>  \u2192  <code>CM_DEBUG_SCRIPT_BENCHMARK_PROGRAM=value</code></li> <li><code>--docker=value</code>  \u2192  <code>CM_RUN_DOCKER_CONTAINER=value</code></li> <li><code>--gpu_name=value</code>  \u2192  <code>CM_NVIDIA_GPU_NAME=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--imagenet_path=value</code>  \u2192  <code>IMAGENET_PATH=value</code></li> <li><code>--max_amps=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_AMPS=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--max_volts=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_VOLTS=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--ntp_server=value</code>  \u2192  <code>CM_MLPERF_POWER_NTP_SERVER=value</code></li> <li><code>--num_threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--power_server=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_ADDRESS=value</code></li> <li><code>--readme=value</code>  \u2192  <code>CM_MLPERF_README=value</code></li> <li><code>--regenerate_files=value</code>  \u2192  <code>CM_REGENERATE_MEASURE_FILES=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--test_query_count=value</code>  \u2192  <code>CM_TEST_QUERY_COUNT=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_LOADGEN_MODE: <code>accuracy</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_OUTPUT_FOLDER_NAME: <code>test_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>test</code></li> <li>CM_TEST_QUERY_COUNT: <code>10</code></li> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference/#script-output","title":"Script output","text":"<pre><code>cmr \"app vision language mlcommons mlperf inference generic [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/","title":"app-mlperf-inference-ctuning-cpp-tflite","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-ctuning-cpp-tflite</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app mlperf inference tflite-cpp\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,mlperf,inference,tflite-cpp[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app mlperf inference tflite-cpp [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,mlperf,inference,tflite-cpp'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app mlperf inference tflite-cpp[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_armnn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_TFLITE_USE_ARMNN: <code>yes</code></li> <li>CM_TMP_LINK_LIBS: <code>tensorflowlite,armnn</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"backend\"      Click here to expand this section. <ul> <li><code>_tf</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tflite</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>master</code></li> <li>CM_TMP_LINK_LIBS: <code>tensorflowlite</code></li> <li>CM_TMP_SRC_FOLDER: <code>src</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_gpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_singlestream</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_efficientnet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>efficientnet</code></li> </ul> </li> </ul> </li> <li><code>_mobilenet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>mobilenet</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"optimization-target\"      Click here to expand this section. <ul> <li><code>_use-neon</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX1: <code>using_neon</code></li> <li>CM_MLPERF_TFLITE_USE_NEON: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_use-opencl</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX1: <code>using_opencl</code></li> <li>CM_MLPERF_TFLITE_USE_OPENCL: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_MODEL_PRECISION: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_COMPRESSED: <code>on</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_uint8</code><ul> <li>ENV variables:<ul> <li>CM_DATASET_COMPRESSED: <code>on</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>uint8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#default-variations","title":"Default variations","text":"<p><code>_cpu,_fp32,_resnet50,_singlestream,_tflite</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--compressed_dataset=value</code>  \u2192  <code>CM_DATASET_COMPRESSED=value</code></li> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> <li><code>--verbose=value</code>  \u2192  <code>CM_VERBOSE=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_DATASET_COMPRESSED: <code>off</code></li> <li>CM_DATASET_INPUT_SQUARE_SIDE: <code>224</code></li> <li>CM_FAST_COMPILATION: <code>yes</code></li> <li>CM_LOADGEN_BUFFER_SIZE: <code>1024</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>accuracy</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> <li>CM_MLPERF_LOADGEN_TRIGGER_COLD_RUN: <code>0</code></li> <li>CM_MLPERF_OUTPUT_DIR: <code>.</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>tflite_cpp</code></li> <li>CM_MLPERF_TFLITE_USE_NEON: <code>0</code></li> <li>CM_MLPERF_TFLITE_USE_OPENCL: <code>0</code></li> <li>CM_ML_MODEL_GIVEN_CHANNEL_MEANS: <code>123.68 116.78 103.94</code></li> <li>CM_ML_MODEL_NORMALIZE_DATA: <code>0</code></li> <li>CM_ML_MODEL_SUBTRACT_MEANS: <code>1</code></li> <li>CM_VERBOSE: <code>0</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-ctuning-cpp-tflite/#script-output","title":"Script output","text":"<pre><code>cmr \"app mlperf inference tflite-cpp [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/","title":"app-mlperf-inference-mlcommons-cpp","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-mlcommons-cpp</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <p>Developers: Thomas Zhu, Arjun Suresh, Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app mlcommons mlperf inference cpp\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,mlcommons,mlperf,inference,cpp[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app mlcommons mlperf inference cpp [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,mlcommons,mlperf,inference,cpp'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app mlcommons mlperf inference cpp[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#variations","title":"Variations","text":"<ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_batch-size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_MAX_BATCHSIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_onnxruntime</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> <li>CM_MLPERF_BACKEND_LIB_NAMESPEC: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tflite</code></li> </ul> </li> </ul> </li> <li><code>_tvm-onnx</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-onnx</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> <li>CM_MLPERF_LOADGEN_MAX_BATCHSIZE: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#default-variations","title":"Default variations","text":"<p><code>_cpu,_offline,_onnxruntime,_resnet50</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> <li>CM_FAST_COMPILATION: <code>yes</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>cpp</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-cpp/#script-output","title":"Script output","text":"<pre><code>cmr \"app mlcommons mlperf inference cpp [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/","title":"app-mlperf-inference-mlcommons-python","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-mlcommons-python</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <p>Developers: Arjun Suresh, Thomas Zhu, Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <p>This portable CM script is being developed by the MLCommons taskforce on automation and reproducibility to modularize the python reference implementations of the MLPerf inference benchmark  using the MLCommons CM automation meta-framework. The goal is to make it easier to run, optimize and reproduce MLPerf benchmarks  across diverse platforms with continuously changing software and hardware.</p> <p>See the current coverage of different models, devices and backends here.</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app vision language mlcommons mlperf inference reference ref\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,vision,language,mlcommons,mlperf,inference,reference,ref[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app vision language mlcommons mlperf inference reference ref [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,vision,language,mlcommons,mlperf,inference,reference,ref'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app vision language mlcommons mlperf inference reference ref[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_3d-unet</code><ul> <li>ENV variables:<ul> <li>CM_TMP_IGNORE_MLPERF_QUERY_COUNT: <code>True</code></li> <li>CM_MLPERF_MODEL_SKIP_BATCHING: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_beam_size.#</code><ul> <li>ENV variables:<ul> <li>GPTJ_BEAM_SIZE: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_bert</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_MODEL_SKIP_BATCHING: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_dlrm</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_MODEL_SKIP_BATCHING: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_r2.1_default</code><ul> <li>ENV variables:<ul> <li>CM_RERUN: <code>yes</code></li> <li>CM_SKIP_SYS_UTILS: <code>yes</code></li> <li>CM_TEST_QUERY_COUNT: <code>100</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_MAX_BATCHSIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> <li>CUDA_VISIBLE_DEVICES: ``</li> <li>USE_CUDA: <code>False</code></li> <li>USE_GPU: <code>False</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>USE_CUDA: <code>True</code></li> <li>USE_GPU: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_rocm</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>rocm</code></li> <li>USE_GPU: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_tpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>tpu</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>deepsparse</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_DEEPSPARSE_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_ncnn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>ncnn</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_NCNN_VERSION&gt;&gt;&gt;</code></li> <li>CM_MLPERF_VISION_DATASET_OPTION: <code>imagenet_pytorch</code></li> </ul> </li> </ul> </li> <li><code>_onnxruntime</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TORCH_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_ray</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>ray</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TORCH_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>Aliases: <code>_tensorflow</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TENSORFLOW_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tflite</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TFLITE_VERSION&gt;&gt;&gt;</code></li> <li>CM_MLPERF_VISION_DATASET_OPTION: <code>imagenet_tflite_tpu</code></li> </ul> </li> </ul> </li> <li><code>_tvm-onnx</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-onnx</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_ONNXRUNTIME_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tvm-pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-pytorch</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TORCH_VERSION&gt;&gt;&gt;</code></li> <li>CM_PREPROCESS_PYTORCH: <code>yes</code></li> <li>MLPERF_TVM_TORCH_QUANTIZED_ENGINE: <code>qnnpack</code></li> </ul> </li> </ul> </li> <li><code>_tvm-tflite</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tvm-tflite</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TVM-TFLITE_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"implementation\"      Click here to expand this section. <ul> <li><code>_python</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_PYTHON: <code>yes</code></li> <li>CM_MLPERF_IMPLEMENTATION: <code>reference</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"models\"      Click here to expand this section. <ul> <li><code>_3d-unet-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99</code></li> </ul> </li> </ul> </li> <li><code>_3d-unet-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99.9</code></li> </ul> </li> </ul> </li> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-99</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-99.9</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99.9</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99</code></li> </ul> </li> </ul> </li> <li><code>_llama2-70b-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>llama2-70b-99.9</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> <li>CM_MLPERF_USE_MLCOMMONS_RUN_SCRIPT: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> <li>CM_MLPERF_USE_MLCOMMONS_RUN_SCRIPT: <code>yes</code></li> <li>CM_MLPERF_LOADGEN_MAX_BATCHSIZE: <code>1</code></li> </ul> </li> </ul> </li> <li><code>_rnnt</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>rnnt</code></li> <li>CM_MLPERF_MODEL_SKIP_BATCHING: <code>True</code></li> <li>CM_TMP_IGNORE_MLPERF_QUERY_COUNT: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_sdxl</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>stable-diffusion-xl</code></li> <li>CM_NUM_THREADS: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"network\"      Click here to expand this section. <ul> <li><code>_network-lon</code><ul> <li>ENV variables:<ul> <li>CM_NETWORK_LOADGEN: <code>lon</code></li> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX1: <code>network_loadgen</code></li> </ul> </li> </ul> </li> <li><code>_network-sut</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX1: <code>network_sut</code></li> <li>CM_NETWORK_LOADGEN: <code>sut</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"precision\"      Click here to expand this section. <ul> <li><code>_bfloat16</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>bfloat16</code></li> </ul> </li> </ul> </li> <li><code>_float16</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>float16</code></li> </ul> </li> </ul> </li> <li><code>_fp32</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>float32</code></li> </ul> </li> </ul> </li> <li><code>_int8</code><ul> <li>Aliases: <code>_quantized</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_QUANTIZATION: <code>True</code></li> <li>CM_MLPERF_MODEL_PRECISION: <code>int8</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#default-variations","title":"Default variations","text":"<p><code>_cpu,_fp32,_onnxruntime,_python,_resnet50</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_SUBMISSION_DIR=value</code></li> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--dataset=value</code>  \u2192  <code>CM_MLPERF_VISION_DATASET_OPTION=value</code></li> <li><code>--dataset_args=value</code>  \u2192  <code>CM_MLPERF_EXTRA_DATASET_ARGS=value</code></li> <li><code>--docker=value</code>  \u2192  <code>CM_RUN_DOCKER_CONTAINER=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--imagenet_path=value</code>  \u2192  <code>IMAGENET_PATH=value</code></li> <li><code>--max_amps=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_AMPS=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--max_volts=value</code>  \u2192  <code>CM_MLPERF_POWER_MAX_VOLTS=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--model=value</code>  \u2192  <code>CM_MLPERF_CUSTOM_MODEL_PATH=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--network=value</code>  \u2192  <code>CM_NETWORK_LOADGEN=value</code></li> <li><code>--ntp_server=value</code>  \u2192  <code>CM_MLPERF_POWER_NTP_SERVER=value</code></li> <li><code>--num_threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_MLPERF_POWER=value</code></li> <li><code>--power_server=value</code>  \u2192  <code>CM_MLPERF_POWER_SERVER_ADDRESS=value</code></li> <li><code>--regenerate_files=value</code>  \u2192  <code>CM_REGENERATE_MEASURE_FILES=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--sut_servers=value</code>  \u2192  <code>CM_NETWORK_LOADGEN_SUT_SERVERS=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--test_query_count=value</code>  \u2192  <code>CM_TEST_QUERY_COUNT=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_LOADGEN_MODE: <code>accuracy</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_OUTPUT_FOLDER_NAME: <code>test_results</code></li> <li>CM_MLPERF_RUN_STYLE: <code>test</code></li> <li>CM_TEST_QUERY_COUNT: <code>10</code></li> <li>CM_MLPERF_QUANTIZATION: <code>False</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>reference</code></li> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX: ``</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/app-mlperf-inference-mlcommons-python/#script-output","title":"Script output","text":"<pre><code>cmr \"app vision language mlcommons mlperf inference reference ref [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/","title":"benchmark-program-mlperf","text":"<p>Automatically generated README for this automation recipe: benchmark-program-mlperf</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"mlperf benchmark-mlperf\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=mlperf,benchmark-mlperf[,variations] \n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"mlperf benchmark-mlperf [variations]\" \n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'mlperf,benchmark-mlperf'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"mlperf benchmark-mlperf[variations]\" \n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#variations","title":"Variations","text":"<ul> <li> <p>Group \"power-mode\"      Click here to expand this section. <ul> <li><code>_no-power</code> (default)</li> <li><code>_power</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_POWER: <code>yes</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#default-variations","title":"Default variations","text":"<p><code>_no-power</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/benchmark-program-mlperf/#script-output","title":"Script output","text":"<pre><code>cmr \"mlperf benchmark-mlperf [variations]\"  -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/","title":"run-mlperf-inference-app","text":"<p>Automatically generated README for this automation recipe: run-mlperf-inference-app</p> <p>Category: Modular MLPerf inference benchmark pipeline</p> <p>License: Apache 2.0</p> <p>Developers: Arjun Suresh, Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run-mlperf,inference\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput FlagsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run-mlperf,inference[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run-mlperf,inference [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run-mlperf,inference'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run-mlperf,inference[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_all-scenarios</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_ALL_SCENARIOS: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_compliance</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_COMPLIANCE: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_dashboard</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DASHBOARD: <code>on</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"benchmark-version\"      Click here to expand this section. <ul> <li><code>_r2.1</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>2.1</code></li> <li>CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS: <code>r2.1_default</code></li> </ul> </li> </ul> </li> <li><code>_r3.0</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>3.0</code></li> <li>CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS: <code>r3.0_default</code></li> </ul> </li> </ul> </li> <li><code>_r3.1</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>3.1</code></li> <li>CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS: <code>r3.1_default</code></li> </ul> </li> </ul> </li> <li><code>_r4.0</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>4.0</code></li> <li>CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS: <code>r4.0_default</code></li> </ul> </li> </ul> </li> <li><code>_r4.1</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>4.1</code></li> <li>CM_RUN_MLPERF_INFERENCE_APP_DEFAULTS: <code>r4.1_default</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"mode\"      Click here to expand this section. <ul> <li><code>_all-modes</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_ALL_MODES: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"submission-generation\"      Click here to expand this section. <ul> <li><code>_accuracy-only</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_MODE: <code>accuracy</code></li> <li>CM_MLPERF_SUBMISSION_RUN: <code>yes</code></li> <li>CM_RUN_MLPERF_ACCURACY: <code>on</code></li> <li>CM_RUN_SUBMISSION_CHECKER: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_find-performance</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_FIND_PERFORMANCE_MODE: <code>yes</code></li> <li>CM_MLPERF_LOADGEN_ALL_MODES: <code>no</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_MLPERF_RESULT_PUSH_TO_GITHUB: <code>False</code></li> </ul> </li> </ul> </li> <li><code>_performance-and-accuracy</code> (default)</li> <li><code>_performance-only</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_MLPERF_SUBMISSION_RUN: <code>yes</code></li> <li>CM_RUN_SUBMISSION_CHECKER: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_populate-readme</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_README: <code>yes</code></li> <li>CM_MLPERF_SUBMISSION_RUN: <code>yes</code></li> <li>CM_RUN_SUBMISSION_CHECKER: <code>no</code></li> </ul> </li> </ul> </li> <li><code>_submission</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_COMPLIANCE: <code>yes</code></li> <li>CM_MLPERF_SUBMISSION_RUN: <code>yes</code></li> <li>CM_RUN_MLPERF_ACCURACY: <code>on</code></li> <li>CM_RUN_SUBMISSION_CHECKER: <code>yes</code></li> <li>CM_TAR_SUBMISSION_DIR: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"submission-generation-style\"      Click here to expand this section. <ul> <li><code>_full</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_SUBMISSION_GENERATION_STYLE: <code>full</code></li> <li>CM_MLPERF_SKIP_SUBMISSION_GENERATION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_short</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_SUBMISSION_GENERATION_STYLE: <code>short</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#default-variations","title":"Default variations","text":"<p><code>_performance-and-accuracy,_short</code></p>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#input-flags","title":"Input Flags","text":"<ul> <li>--division: MLPerf division {open,closed} (open)</li> <li>--category: MLPerf category {edge,datacenter,network} (edge)</li> <li>--device: MLPerf device {cpu,cuda,rocm,qaic} (cpu)</li> <li>--model: MLPerf model {resnet50,retinanet,bert-99,bert-99.9,3d-unet-99,3d-unet-99.9,rnnt,dlrm-v2-99,dlrm-v2-99.9,gptj-99,gptj-99.9,sdxl,llama2-70b-99,llama2-70b-99.9,mobilenet,efficientnet} (resnet50)</li> <li>--precision: MLPerf model precision {float32,float16,bfloat16,int8,uint8}</li> <li>--implementation: MLPerf implementation {mlcommons-python,mlcommons-cpp,nvidia,intel,qualcomm,ctuning-cpp-tflite} (mlcommons-python)</li> <li>--backend: MLPerf framework (backend) {onnxruntime,tf,pytorch,deepsparse,tensorrt,glow,tvm-onnx} (onnxruntime)</li> <li>--scenario: MLPerf scenario {Offline,Server,SingleStream,MultiStream} (Offline)</li> <li>--mode: MLPerf benchmark mode {,accuracy,performance}</li> <li>--execution_mode: MLPerf execution mode {test,fast,valid} (test)</li> <li>--sut: SUT configuration (if known)</li> <li>--submitter: Submitter name (without space) (CTuning)</li> <li>--results_dir: Folder path to store results (defaults to the current working directory)</li> <li>--submission_dir: Folder path to store MLPerf submission tree</li> <li>--adr.compiler.tags: Compiler for loadgen and any C/C++ part of implementation</li> <li>--adr.inference-src-loadgen.env.CM_GIT_URL: Git URL for MLPerf inference sources to build LoadGen (to enable non-reference implementations)</li> <li>--adr.inference-src.env.CM_GIT_URL: Git URL for MLPerf inference sources to run benchmarks (to enable non-reference implementations)</li> <li>--adr.mlperf-inference-implementation.max_batchsize: Maximum batchsize to be used</li> <li>--adr.mlperf-inference-implementation.num_threads: Number of threads (reference &amp; C++ implementation only)</li> <li>--adr.python.name: Python virtual environment name (optional)</li> <li>--adr.python.version: Force Python version (must have all system deps)</li> <li>--adr.python.version_min: Minimal Python version (3.8)</li> <li>--power: Measure power {yes,no} (no)</li> <li>--adr.mlperf-power-client.power_server: MLPerf Power server IP address (192.168.0.15)</li> <li>--adr.mlperf-power-client.port: MLPerf Power server port (4950)</li> <li>--clean: Clean run (False)</li> <li>--compliance: Whether to run compliance tests (applicable only for closed division) {yes,no} (no)</li> <li>--dashboard_wb_project: W&amp;B dashboard project (cm-mlperf-dse-testing)</li> <li>--dashboard_wb_user: W&amp;B dashboard user (cmind)</li> <li>--hw_name: MLPerf hardware name (for example \"gcp.c3_standard_8\", \"nvidia_orin\", \"lenovo_p14s_gen_4_windows_11\", \"macbook_pro_m1_2\", \"thundercomm_rb6\" ...)</li> <li>--multistream_target_latency: Set MultiStream target latency</li> <li>--offline_target_qps: Set LoadGen Offline target QPS</li> <li>--quiet: Quiet run (select default values for all questions) (True)</li> <li>--server_target_qps: Set Server target QPS</li> <li>--singlestream_target_latency: Set SingleStream target latency</li> <li>--target_latency: Set Target latency</li> <li>--target_qps: Set LoadGen target QPS</li> <li>--j: Print results dictionary to console at the end of the run (False)</li> <li>--repro: Record input/output/state/info files to make it easier to reproduce results (False)</li> <li>--time: Print script execution time at the end of the run (True)</li> <li>--debug: Debug this script (False)</li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--backend=value</code>  \u2192  <code>CM_MLPERF_BACKEND=value</code></li> <li><code>--batch_size=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--beam_size=value</code>  \u2192  <code>GPTJ_BEAM_SIZE=value</code></li> <li><code>--category=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_SYSTEM_TYPE=value</code></li> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_ALL=value</code></li> <li><code>--compliance=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_COMPLIANCE=value</code></li> <li><code>--dashboard_wb_project=value</code>  \u2192  <code>CM_MLPERF_DASHBOARD_WANDB_PROJECT=value</code></li> <li><code>--dashboard_wb_user=value</code>  \u2192  <code>CM_MLPERF_DASHBOARD_WANDB_USER=value</code></li> <li><code>--debug=value</code>  \u2192  <code>CM_DEBUG_SCRIPT_BENCHMARK_PROGRAM=value</code></li> <li><code>--device=value</code>  \u2192  <code>CM_MLPERF_DEVICE=value</code></li> <li><code>--division=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_DIVISION=value</code></li> <li><code>--docker=value</code>  \u2192  <code>CM_MLPERF_USE_DOCKER=value</code></li> <li><code>--dump_version_info=value</code>  \u2192  <code>CM_DUMP_VERSION_INFO=value</code></li> <li><code>--execution_mode=value</code>  \u2192  <code>CM_MLPERF_RUN_STYLE=value</code></li> <li><code>--find_performance=value</code>  \u2192  <code>CM_MLPERF_FIND_PERFORMANCE_MODE=value</code></li> <li><code>--gpu_name=value</code>  \u2192  <code>CM_NVIDIA_GPU_NAME=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--hw_notes_extra=value</code>  \u2192  <code>CM_MLPERF_SUT_SW_NOTES_EXTRA=value</code></li> <li><code>--imagenet_path=value</code>  \u2192  <code>IMAGENET_PATH=value</code></li> <li><code>--implementation=value</code>  \u2192  <code>CM_MLPERF_IMPLEMENTATION=value</code></li> <li><code>--lang=value</code>  \u2192  <code>CM_MLPERF_IMPLEMENTATION=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--model=value</code>  \u2192  <code>CM_MLPERF_MODEL=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--network=value</code>  \u2192  <code>CM_NETWORK_LOADGEN=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--output_summary=value</code>  \u2192  <code>MLPERF_INFERENCE_SUBMISSION_SUMMARY=value</code></li> <li><code>--output_tar=value</code>  \u2192  <code>MLPERF_INFERENCE_SUBMISSION_TAR_FILE=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--power=value</code>  \u2192  <code>CM_SYSTEM_POWER=value</code></li> <li><code>--precision=value</code>  \u2192  <code>CM_MLPERF_MODEL_PRECISION=value</code></li> <li><code>--preprocess_submission=value</code>  \u2192  <code>CM_RUN_MLPERF_SUBMISSION_PREPROCESSOR=value</code></li> <li><code>--push_to_github=value</code>  \u2192  <code>CM_MLPERF_RESULT_PUSH_TO_GITHUB=value</code></li> <li><code>--readme=value</code>  \u2192  <code>CM_MLPERF_README=value</code></li> <li><code>--regenerate_accuracy_file=value</code>  \u2192  <code>CM_MLPERF_REGENERATE_ACCURACY_FILE=value</code></li> <li><code>--regenerate_files=value</code>  \u2192  <code>CM_REGENERATE_MEASURE_FILES=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--results_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--results_git_url=value</code>  \u2192  <code>CM_MLPERF_RESULTS_GIT_REPO_URL=value</code></li> <li><code>--run_checker=value</code>  \u2192  <code>CM_RUN_SUBMISSION_CHECKER=value</code></li> <li><code>--run_style=value</code>  \u2192  <code>CM_MLPERF_RUN_STYLE=value</code></li> <li><code>--save_console_log=value</code>  \u2192  <code>CM_SAVE_CONSOLE_LOG=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--skip_submission_generation=value</code>  \u2192  <code>CM_MLPERF_SKIP_SUBMISSION_GENERATION=value</code></li> <li><code>--skip_truncation=value</code>  \u2192  <code>CM_SKIP_TRUNCATE_ACCURACY=value</code></li> <li><code>--submission_dir=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUBMISSION_DIR=value</code></li> <li><code>--submitter=value</code>  \u2192  <code>CM_MLPERF_SUBMITTER=value</code></li> <li><code>--sut=value</code>  \u2192  <code>CM_MLPERF_INFERENCE_SUT_VARIATION=value</code></li> <li><code>--sut_servers=value</code>  \u2192  <code>CM_NETWORK_LOADGEN_SUT_SERVERS=value</code></li> <li><code>--sw_notes_extra=value</code>  \u2192  <code>CM_MLPERF_SUT_SW_NOTES_EXTRA=value</code></li> <li><code>--system_type=value</code>  \u2192  <code>CM_MLPERF_SUBMISSION_SYSTEM_TYPE=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--test_query_count=value</code>  \u2192  <code>CM_TEST_QUERY_COUNT=value</code></li> <li><code>--threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_IMPLEMENTATION: <code>reference</code></li> <li>CM_MLPERF_MODEL: <code>resnet50</code></li> <li>CM_MLPERF_RUN_STYLE: <code>test</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#versions","title":"Versions","text":"<ul> <li><code>master</code></li> <li><code>r2.1</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-inference-benchmark-pipeline/run-mlperf-inference-app/#script-output","title":"Script output","text":"<pre><code>cmr \"run-mlperf,inference [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/","title":"Modular-MLPerf-training-benchmark-pipeline","text":"<ul> <li>app-mlperf-training-nvidia</li> <li>app-mlperf-training-reference</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/","title":"app-mlperf-training-nvidia","text":"<p>Automatically generated README for this automation recipe: app-mlperf-training-nvidia</p> <p>Category: Modular MLPerf training benchmark pipeline</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app vision language mlcommons mlperf training nvidia\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,vision,language,mlcommons,mlperf,training,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app vision language mlcommons mlperf training nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,vision,language,mlcommons,mlperf,training,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app vision language mlcommons mlperf training nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_bert</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_MODEL: <code>bert</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cuda</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cuda</code></li> <li>USE_CUDA: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_tpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>tpu</code></li> <li>CUDA_VISIBLE_DEVICES: ``</li> <li>USE_CUDA: <code>False</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TORCH_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>Aliases: <code>_tensorflow</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TENSORFLOW_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#default-variations","title":"Default variations","text":"<p><code>_cuda</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_SUBMISSION_DIR=value</code></li> <li><code>--docker=value</code>  \u2192  <code>CM_RUN_DOCKER_CONTAINER=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--model=value</code>  \u2192  <code>CM_MLPERF_CUSTOM_MODEL_PATH=value</code></li> <li><code>--num_threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>nvidia</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-bert-training.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-nvidia/#script-output","title":"Script output","text":"<pre><code>cmr \"app vision language mlcommons mlperf training nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/","title":"app-mlperf-training-reference","text":"<p>Automatically generated README for this automation recipe: app-mlperf-training-reference</p> <p>Category: Modular MLPerf training benchmark pipeline</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app vision language mlcommons mlperf training reference ref\" --help</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,vision,language,mlcommons,mlperf,training,reference,ref[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app vision language mlcommons mlperf training reference ref [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,vision,language,mlcommons,mlperf,training,reference,ref'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app vision language mlcommons mlperf training reference ref[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_bert</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_MODEL: <code>bert</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cuda</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cuda</code></li> <li>USE_CUDA: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_tpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>tpu</code></li> <li>CUDA_VISIBLE_DEVICES: ``</li> <li>USE_CUDA: <code>False</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"framework\"      Click here to expand this section. <ul> <li><code>_pytorch</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>pytorch</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TORCH_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_tf</code><ul> <li>Aliases: <code>_tensorflow</code></li> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tf</code></li> <li>CM_MLPERF_BACKEND_VERSION: <code>&lt;&lt;&lt;CM_TENSORFLOW_VERSION&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#default-variations","title":"Default variations","text":"<p><code>_cuda</code></p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--clean=value</code>  \u2192  <code>CM_MLPERF_CLEAN_SUBMISSION_DIR=value</code></li> <li><code>--docker=value</code>  \u2192  <code>CM_RUN_DOCKER_CONTAINER=value</code></li> <li><code>--hw_name=value</code>  \u2192  <code>CM_HW_NAME=value</code></li> <li><code>--model=value</code>  \u2192  <code>CM_MLPERF_CUSTOM_MODEL_PATH=value</code></li> <li><code>--num_threads=value</code>  \u2192  <code>CM_NUM_THREADS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>OUTPUT_BASE_DIR=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>reference</code></li> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX: ``</li> </ul>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-bert-training.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-MLPerf-training-benchmark-pipeline/app-mlperf-training-reference/#script-output","title":"Script output","text":"<pre><code>cmr \"app vision language mlcommons mlperf training reference ref [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Modular-application-pipeline/","title":"Modular-application-pipeline","text":"<ul> <li>app-image-corner-detection</li> </ul>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/","title":"app-image-corner-detection","text":"<p>Automatically generated README for this automation recipe: app-image-corner-detection</p> <p>Category: Modular application pipeline</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app image corner-detection\" --help</code></p>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,image,corner-detection \n</code></pre>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app image corner-detection \" \n</code></pre>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,image,corner-detection'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app image corner-detection\" \n</code></pre>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Modular-application-pipeline/app-image-corner-detection/#script-output","title":"Script output","text":"<pre><code>cmr \"app image corner-detection \"  -j\n</code></pre>"},{"location":"scripts/Platform-information/","title":"Platform-information","text":"<ul> <li>detect-cpu</li> <li>detect-os</li> </ul>"},{"location":"scripts/Platform-information/detect-cpu/","title":"detect-cpu","text":"<p>Automatically generated README for this automation recipe: detect-cpu</p> <p>Category: Platform information</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Platform-information/detect-cpu/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Platform-information/detect-cpu/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Platform-information/detect-cpu/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Platform-information/detect-cpu/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"detect cpu detect-cpu info\" --help</code></p>"},{"location":"scripts/Platform-information/detect-cpu/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Platform-information/detect-cpu/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=detect,cpu,detect-cpu,info \n</code></pre>"},{"location":"scripts/Platform-information/detect-cpu/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"detect cpu detect-cpu info \" \n</code></pre>"},{"location":"scripts/Platform-information/detect-cpu/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'detect,cpu,detect-cpu,info'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Platform-information/detect-cpu/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"detect cpu detect-cpu info\" \n</code></pre>"},{"location":"scripts/Platform-information/detect-cpu/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Platform-information/detect-cpu/#script-output","title":"Script output","text":"<pre><code>cmr \"detect cpu detect-cpu info \"  -j\n</code></pre>"},{"location":"scripts/Platform-information/detect-os/","title":"detect-os","text":"<p>Automatically generated README for this automation recipe: detect-os</p> <p>Category: Platform information</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Platform-information/detect-os/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Platform-information/detect-os/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Platform-information/detect-os/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Platform-information/detect-os/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"detect-os detect os info\" --help</code></p>"},{"location":"scripts/Platform-information/detect-os/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Platform-information/detect-os/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=detect-os,detect,os,info \n</code></pre>"},{"location":"scripts/Platform-information/detect-os/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"detect-os detect os info \" \n</code></pre>"},{"location":"scripts/Platform-information/detect-os/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'detect-os,detect,os,info'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Platform-information/detect-os/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"detect-os detect os info\" \n</code></pre>"},{"location":"scripts/Platform-information/detect-os/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Platform-information/detect-os/#script-output","title":"Script output","text":"<pre><code>cmr \"detect-os detect os info \"  -j\n</code></pre>"},{"location":"scripts/Python-automation/","title":"Python-automation","text":"<ul> <li>activate-python-venv</li> <li>get-generic-python-lib</li> <li>get-python3</li> <li>install-generic-conda-package</li> <li>install-python-src</li> <li>install-python-venv</li> </ul>"},{"location":"scripts/Python-automation/activate-python-venv/","title":"Activate virtual Python environment","text":"<p>Automatically generated README for this automation recipe: activate-python-venv</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Python-automation/activate-python-venv/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/activate-python-venv/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/activate-python-venv/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/activate-python-venv/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"activate python-venv\" --help</code></p>"},{"location":"scripts/Python-automation/activate-python-venv/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Python-automation/activate-python-venv/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=activate,python-venv \n</code></pre>"},{"location":"scripts/Python-automation/activate-python-venv/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"activate python-venv \" \n</code></pre>"},{"location":"scripts/Python-automation/activate-python-venv/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'activate,python-venv'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/activate-python-venv/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"activate python-venv\" \n</code></pre>"},{"location":"scripts/Python-automation/activate-python-venv/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Python-automation/activate-python-venv/#script-output","title":"Script output","text":"<pre><code>cmr \"activate python-venv \"  -j\n</code></pre>"},{"location":"scripts/Python-automation/get-generic-python-lib/","title":"get-generic-python-lib","text":"<p>Automatically generated README for this automation recipe: get-generic-python-lib</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Python-automation/get-generic-python-lib/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/get-generic-python-lib/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/get-generic-python-lib/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/get-generic-python-lib/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get generic-python-lib\" --help</code></p>"},{"location":"scripts/Python-automation/get-generic-python-lib/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/Python-automation/get-generic-python-lib/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,generic-python-lib[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Python-automation/get-generic-python-lib/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get generic-python-lib [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Python-automation/get-generic-python-lib/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,generic-python-lib'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/get-generic-python-lib/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get generic-python-lib[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Python-automation/get-generic-python-lib/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_Pillow</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>Pillow</code></li> </ul> </li> </ul> </li> <li><code>_anthropic</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>anthropic</code></li> </ul> </li> </ul> </li> <li><code>_apache-tvm</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>apache-tvm</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA: <code>--pre</code></li> </ul> </li> </ul> </li> <li><code>_apex</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>apex</code></li> </ul> </li> </ul> </li> <li><code>_async_timeout</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>async_timeout</code></li> </ul> </li> </ul> </li> <li><code>_attr</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>attr</code></li> </ul> </li> </ul> </li> <li><code>_attrs</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>attrs</code></li> </ul> </li> </ul> </li> <li><code>_boto3</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>boto3</code></li> </ul> </li> </ul> </li> <li><code>_cloudpickle</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>cloudpickle</code></li> </ul> </li> </ul> </li> <li><code>_cmind</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>cmind</code></li> </ul> </li> </ul> </li> <li><code>_colored</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>colored</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://pypi.ngc.nvidia.com</code></li> </ul> </li> </ul> </li> <li><code>_conda.#</code></li> <li><code>_cupy</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>cupy</code></li> </ul> </li> </ul> </li> <li><code>_custom-python</code><ul> <li>ENV variables:<ul> <li>CM_TMP_USE_CUSTOM_PYTHON: <code>on</code></li> </ul> </li> </ul> </li> <li><code>_datasets</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>datasets</code></li> </ul> </li> </ul> </li> <li><code>_decorator</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>decorator</code></li> </ul> </li> </ul> </li> <li><code>_deepsparse</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>deepsparse</code></li> </ul> </li> </ul> </li> <li><code>_dllogger</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>dllogger</code></li> <li>CM_GENERIC_PYTHON_PIP_URL: <code>git+https://github.com/NVIDIA/dllogger#egg=dllogger</code></li> </ul> </li> </ul> </li> <li><code>_fiftyone</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>fiftyone</code></li> </ul> </li> </ul> </li> <li><code>_google-api-python-client</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>google_api_python_client</code></li> </ul> </li> </ul> </li> <li><code>_google-auth-oauthlib</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>google_auth_oauthlib</code></li> </ul> </li> </ul> </li> <li><code>_huggingface_hub</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>huggingface_hub</code></li> </ul> </li> </ul> </li> <li><code>_inflect</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>inflect</code></li> </ul> </li> </ul> </li> <li><code>_jax</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>jax</code></li> </ul> </li> </ul> </li> <li><code>_jax_cuda</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>jax[cuda]</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA: <code>-f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html</code></li> <li>CM_JAX_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_librosa</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>librosa</code></li> </ul> </li> </ul> </li> <li><code>_matplotlib</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>matplotlib</code></li> </ul> </li> </ul> </li> <li><code>_mlperf_loadgen</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>mlperf_loadgen</code></li> <li>CM_GENERIC_PYTHON_PIP_URL: <code>git+https://github.com/mlcommons/inference.git#subdirectory=loadgen</code></li> </ul> </li> </ul> </li> <li><code>_mlperf_logging</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>mlperf_logging</code></li> <li>CM_GENERIC_PYTHON_PIP_URL: <code>git+https://github.com/mlperf/logging.git</code></li> </ul> </li> </ul> </li> <li><code>_mpld3</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>mpld3</code></li> </ul> </li> </ul> </li> <li><code>_nibabel</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>nibabel</code></li> </ul> </li> </ul> </li> <li><code>_numpy</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>numpy</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-apex</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>apex</code></li> <li>CM_GENERIC_PYTHON_PACKAGE_VARIANT: <code>nvidia-apex</code></li> <li>CM_GENERIC_PYTHON_PIP_URL: <code>git+https://github.com/nvidia/apex@0da3ffb92ee6fbe5336602f0e3989db1cd16f880</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-apex-from-src</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>apex</code></li> <li>CM_GENERIC_PYTHON_PACKAGE_VARIANT: <code>nvidia-apex</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-dali</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>nvidia-dali-cuda120</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA: <code>--upgrade --default-timeout=900</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://developer.download.nvidia.com/compute/redist</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-pycocotools</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PIP_UNINSTALL_DEPS: <code>pycocotools</code></li> <li>CM_GENERIC_PYTHON_PIP_URL: <code>pycocotools@git+https://github.com/NVIDIA/cocoapi#subdirectory=PythonAPI</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-pyindex</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>nvidia-pyindex</code></li> </ul> </li> </ul> </li> <li><code>_nvidia-tensorrt</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>nvidia-tensorrt</code></li> </ul> </li> </ul> </li> <li><code>_onnx</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>onnx</code></li> </ul> </li> </ul> </li> <li><code>_onnx-graphsurgeon</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>onnx_graphsurgeon</code></li> </ul> </li> </ul> </li> <li><code>_onnxruntime</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>onnxruntime</code></li> </ul> </li> </ul> </li> <li><code>_onnxruntime_gpu</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>onnxruntime_gpu</code></li> <li>CM_ONNXRUNTIME_VERSION_EXTRA: <code>GPU</code></li> </ul> </li> </ul> </li> <li><code>_openai</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>openai</code></li> </ul> </li> </ul> </li> <li><code>_opencv-python</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>opencv-python</code></li> </ul> </li> </ul> </li> <li><code>_package.#</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>#</code></li> <li>CM_GENERIC_PYTHON_PIP_UNINSTALL_DEPS: ``</li> <li>CM_GENERIC_PYTHON_PIP_URL: ``</li> </ul> </li> </ul> </li> <li><code>_pandas</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>pandas</code></li> </ul> </li> </ul> </li> <li><code>_path.#</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PIP_URL: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_pillow</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>Pillow</code></li> </ul> </li> </ul> </li> <li><code>_pip</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>pip</code></li> </ul> </li> </ul> </li> <li><code>_polygraphy</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>polygraphy</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://pypi.ngc.nvidia.com</code></li> </ul> </li> </ul> </li> <li><code>_pre</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_DEV_VERSION: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_protobuf</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>protobuf</code></li> </ul> </li> </ul> </li> <li><code>_psutil</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>psutil</code></li> </ul> </li> </ul> </li> <li><code>_pycocotools</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>pycocotools</code></li> </ul> </li> </ul> </li> <li><code>_pycuda</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>pycuda</code></li> </ul> </li> </ul> </li> <li><code>_ray</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>ray[default]</code></li> </ul> </li> </ul> </li> <li><code>_requests</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>requests</code></li> </ul> </li> </ul> </li> <li><code>_rocm</code></li> <li><code>_safetensors</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>safetensors</code></li> </ul> </li> </ul> </li> <li><code>_scikit-learn</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>scikit-learn</code></li> </ul> </li> </ul> </li> <li><code>_scipy</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>scipy</code></li> </ul> </li> </ul> </li> <li><code>_scons</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>scons</code></li> </ul> </li> </ul> </li> <li><code>_setfit</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>setfit</code></li> </ul> </li> </ul> </li> <li><code>_setuptools</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>setuptools</code></li> </ul> </li> </ul> </li> <li><code>_six</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>six</code></li> </ul> </li> </ul> </li> <li><code>_sklearn</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>sklearn</code></li> </ul> </li> </ul> </li> <li><code>_sox</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>sox</code></li> </ul> </li> </ul> </li> <li><code>_sparsezoo</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>sparsezoo</code></li> </ul> </li> </ul> </li> <li><code>_streamlit</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>streamlit</code></li> </ul> </li> </ul> </li> <li><code>_streamlit_option_menu</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>streamlit_option_menu</code></li> </ul> </li> </ul> </li> <li><code>_tensorboard</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tensorboard</code></li> </ul> </li> </ul> </li> <li><code>_tensorflow</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tensorflow</code></li> </ul> </li> </ul> </li> <li><code>_tensorrt</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tensorrt</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://download.pytorch.org/whl/&lt;&lt;&lt;CM_CUDA_VERSION_STRING&gt;&gt;&gt;</code></li> <li>CM_TORCH_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_tflite</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tflite</code></li> </ul> </li> </ul> </li> <li><code>_tflite-runtime</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tflite-runtime</code></li> </ul> </li> </ul> </li> <li><code>_tokenization</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tokenization</code></li> </ul> </li> </ul> </li> <li><code>_toml</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>toml</code></li> </ul> </li> </ul> </li> <li><code>_torch</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torch</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://download.pytorch.org/whl/cpu</code></li> </ul> </li> </ul> </li> <li><code>_torch_cuda</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torch</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL1: <code>https://download.pytorch.org/whl/&lt;&lt;&lt;CM_CUDA_VERSION_STRING&gt;&gt;&gt;</code></li> <li>CM_TORCH_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_torch_tensorrt</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torch-tensorrt</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://download.pytorch.org/whl/&lt;&lt;&lt;CM_CUDA_VERSION_STRING&gt;&gt;&gt;</code></li> <li>CM_TORCH_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_torchaudio</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torchaudio</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://download.pytorch.org/whl/cpu</code></li> </ul> </li> </ul> </li> <li><code>_torchaudio_cuda</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torchaudio</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL1: <code>https://download.pytorch.org/whl/&lt;&lt;&lt;CM_CUDA_VERSION_STRING&gt;&gt;&gt;</code></li> <li>CM_TORCHAUDIO_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_torchvision</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torchvision</code></li> <li>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL: <code>https://download.pytorch.org/whl/cpu</code></li> </ul> </li> </ul> </li> <li><code>_torchvision_cuda</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>torchvision</code></li> <li>CM_TORCHVISION_VERSION_EXTRA: <code>CUDA</code></li> </ul> </li> </ul> </li> <li><code>_tornado</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tornado</code></li> </ul> </li> </ul> </li> <li><code>_tqdm</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>tqdm</code></li> </ul> </li> </ul> </li> <li><code>_transformers</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>transformers</code></li> </ul> </li> </ul> </li> <li><code>_typing_extensions</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>typing_extensions</code></li> </ul> </li> </ul> </li> <li><code>_ujson</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>ujson</code></li> </ul> </li> </ul> </li> <li><code>_unidecode</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>unidecode</code></li> </ul> </li> </ul> </li> <li><code>_url.#</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PIP_URL: <code>#</code></li> <li>CM_TMP_PYTHON_PACKAGE_FORCE_INSTALL: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_wandb</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>wandb</code></li> </ul> </li> </ul> </li> <li><code>_west</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>west</code></li> </ul> </li> </ul> </li> <li><code>_xgboost</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>xgboost</code></li> </ul> </li> </ul> </li> <li><code>_xlsxwriter</code><ul> <li>ENV variables:<ul> <li>CM_GENERIC_PYTHON_PACKAGE_NAME: <code>xlsxwriter</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Python-automation/get-generic-python-lib/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--extra_index_url=value</code>  \u2192  <code>CM_GENERIC_PYTHON_PIP_EXTRA_INDEX_URL=value</code></li> <li><code>--force_install=value</code>  \u2192  <code>CM_TMP_PYTHON_PACKAGE_FORCE_INSTALL=value</code></li> <li><code>--index_url=value</code>  \u2192  <code>CM_GENERIC_PYTHON_PIP_INDEX_URL=value</code></li> </ul>"},{"location":"scripts/Python-automation/get-generic-python-lib/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Python-automation/get-generic-python-lib/#script-output","title":"Script output","text":"<pre><code>cmr \"get generic-python-lib [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Python-automation/get-python3/","title":"get-python3","text":"<p>Automatically generated README for this automation recipe: get-python3</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Python-automation/get-python3/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/get-python3/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/get-python3/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/get-python3/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get python python3 get-python get-python3\" --help</code></p>"},{"location":"scripts/Python-automation/get-python3/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Python-automation/get-python3/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,python,python3,get-python,get-python3[,variations] \n</code></pre>"},{"location":"scripts/Python-automation/get-python3/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get python python3 get-python get-python3 [variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/get-python3/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,python,python3,get-python,get-python3'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/get-python3/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get python python3 get-python get-python3[variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/get-python3/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_conda.#</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_CONDA: <code>yes</code></li> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>_conda.#</code></li> </ul> </li> </ul> </li> <li><code>_custom-path.#</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_BIN_WITH_PATH: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_lto</code></li> <li><code>_optimized</code></li> <li><code>_shared</code></li> <li><code>_with-custom-ssl</code></li> <li><code>_with-ssl</code></li> </ul>"},{"location":"scripts/Python-automation/get-python3/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Python-automation/get-python3/#script-output","title":"Script output","text":"<pre><code>cmr \"get python python3 get-python get-python3 [variations]\"  -j\n</code></pre>"},{"location":"scripts/Python-automation/install-generic-conda-package/","title":"install-generic-conda-package","text":"<p>Automatically generated README for this automation recipe: install-generic-conda-package</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Python-automation/install-generic-conda-package/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/install-generic-conda-package/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/install-generic-conda-package/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/install-generic-conda-package/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get install generic generic-conda-lib conda-lib conda-package generic-conda-package\" --help</code></p>"},{"location":"scripts/Python-automation/install-generic-conda-package/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Python-automation/install-generic-conda-package/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,install,generic,generic-conda-lib,conda-lib,conda-package,generic-conda-package[,variations] \n</code></pre>"},{"location":"scripts/Python-automation/install-generic-conda-package/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get install generic generic-conda-lib conda-lib conda-package generic-conda-package [variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-generic-conda-package/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,install,generic,generic-conda-lib,conda-lib,conda-package,generic-conda-package'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/install-generic-conda-package/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get install generic generic-conda-lib conda-lib conda-package generic-conda-package[variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-generic-conda-package/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_name.#</code></li> <li><code>_package.#</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_PKG_NAME: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"package-source\"      Click here to expand this section. <ul> <li><code>_source.#</code><ul> <li>ENV variables:<ul> <li>CM_CONDA_PKG_SRC: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Python-automation/install-generic-conda-package/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Python-automation/install-generic-conda-package/#script-output","title":"Script output","text":"<pre><code>cmr \"get install generic generic-conda-lib conda-lib conda-package generic-conda-package [variations]\"  -j\n</code></pre>"},{"location":"scripts/Python-automation/install-python-src/","title":"install-python-src","text":"<p>Automatically generated README for this automation recipe: install-python-src</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Python-automation/install-python-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/install-python-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/install-python-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/install-python-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install src python python3 src-python3 src-python\" --help</code></p>"},{"location":"scripts/Python-automation/install-python-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsDefault environment"},{"location":"scripts/Python-automation/install-python-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,src,python,python3,src-python3,src-python[,variations] \n</code></pre>"},{"location":"scripts/Python-automation/install-python-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install src python python3 src-python3 src-python [variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-python-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,src,python,python3,src-python3,src-python'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/install-python-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install src python python3 src-python3 src-python[variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-python-src/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_lto</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_LTO_FLAG: <code>--lto</code></li> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>with-lto</code></li> </ul> </li> </ul> </li> <li><code>_optimized</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_OPTIMIZATION_FLAG: <code>--enable-optimizations</code></li> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>optimized</code></li> </ul> </li> </ul> </li> <li><code>_shared</code><ul> <li>ENV variables:<ul> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>shared</code></li> <li>CM_SHARED_BUILD: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_with-custom-ssl</code><ul> <li>ENV variables:<ul> <li>CM_CUSTOM_SSL: <code>yes</code></li> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>with-custom-ssl</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"ssl\"      Click here to expand this section. <ul> <li><code>_with-ssl</code><ul> <li>ENV variables:<ul> <li>CM_ENABLE_SSL: <code>yes</code></li> <li>CM_PYTHON_INSTALL_CACHE_TAGS: <code>with-ssl</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Python-automation/install-python-src/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ENABLE_SSL: <code>no</code></li> <li>CM_CUSTOM_SSL: <code>no</code></li> <li>CM_SHARED_BUILD: <code>no</code></li> <li>CM_PYTHON_OPTIMIZATION_FLAG: ``</li> <li>CM_PYTHON_LTO_FLAG: ``</li> <li>CM_WGET_URL: <code>https://www.python.org/ftp/python/[PYTHON_VERSION]/Python-[PYTHON_VERSION].tgz</code></li> </ul>"},{"location":"scripts/Python-automation/install-python-src/#versions","title":"Versions","text":"<p>Default version: <code>3.10.13</code></p>"},{"location":"scripts/Python-automation/install-python-src/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Python-automation/install-python-src/#script-output","title":"Script output","text":"<pre><code>cmr \"install src python python3 src-python3 src-python [variations]\"  -j\n</code></pre>"},{"location":"scripts/Python-automation/install-python-venv/","title":"install-python-venv","text":"<p>Automatically generated README for this automation recipe: install-python-venv</p> <p>Category: Python automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Python-automation/install-python-venv/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Python-automation/install-python-venv/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Python-automation/install-python-venv/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Python-automation/install-python-venv/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"install python get-python-venv python-venv\" --help</code></p>"},{"location":"scripts/Python-automation/install-python-venv/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/Python-automation/install-python-venv/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=install,python,get-python-venv,python-venv[,variations] \n</code></pre>"},{"location":"scripts/Python-automation/install-python-venv/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"install python get-python-venv python-venv [variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-python-venv/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'install,python,get-python-venv,python-venv'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Python-automation/install-python-venv/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"install python get-python-venv python-venv[variations]\" \n</code></pre>"},{"location":"scripts/Python-automation/install-python-venv/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_lto</code></li> <li><code>_optimized</code></li> <li><code>_shared</code></li> <li><code>_with-custom-ssl</code></li> <li><code>_with-ssl</code></li> </ul>"},{"location":"scripts/Python-automation/install-python-venv/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Python-automation/install-python-venv/#script-output","title":"Script output","text":"<pre><code>cmr \"install python get-python-venv python-venv [variations]\"  -j\n</code></pre>"},{"location":"scripts/Remote-automation/","title":"Remote-automation","text":"<ul> <li>remote-run-commands</li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/","title":"remote-run-commands","text":"<p>Automatically generated README for this automation recipe: remote-run-commands</p> <p>Category: Remote automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Remote-automation/remote-run-commands/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Remote-automation/remote-run-commands/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"remote run cmds remote-run remote-run-cmds ssh-run ssh\" --help</code></p>"},{"location":"scripts/Remote-automation/remote-run-commands/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/Remote-automation/remote-run-commands/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=remote,run,cmds,remote-run,remote-run-cmds,ssh-run,ssh [--input_flags]\n</code></pre>"},{"location":"scripts/Remote-automation/remote-run-commands/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"remote run cmds remote-run remote-run-cmds ssh-run ssh \" [--input_flags]\n</code></pre>"},{"location":"scripts/Remote-automation/remote-run-commands/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'remote,run,cmds,remote-run,remote-run-cmds,ssh-run,ssh'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Remote-automation/remote-run-commands/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"remote run cmds remote-run remote-run-cmds ssh-run ssh\" [--input_flags]\n</code></pre>"},{"location":"scripts/Remote-automation/remote-run-commands/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--client_refresh=value</code>  \u2192  <code>CM_SSH_CLIENT_REFRESH=value</code></li> <li><code>--host=value</code>  \u2192  <code>CM_SSH_HOST=value</code></li> <li><code>--password=value</code>  \u2192  <code>CM_SSH_PASSWORD=value</code></li> <li><code>--port=value</code>  \u2192  <code>CM_SSH_PORT=value</code></li> <li><code>--run_cmds=value</code>  \u2192  <code>CM_SSH_RUN_COMMANDS=value</code></li> <li><code>--skip_host_verify=value</code>  \u2192  <code>CM_SSH_SKIP_HOST_VERIFY=value</code></li> <li><code>--ssh_key_file=value</code>  \u2192  <code>CM_SSH_KEY_FILE=value</code></li> <li><code>--user=value</code>  \u2192  <code>CM_SSH_USER=value</code></li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SSH_PORT: <code>22</code></li> <li>CM_SSH_HOST: <code>localhost</code></li> <li>CM_SSH_USER: <code>$USER</code></li> <li>CM_SSH_CLIENT_REFRESH: <code>10</code></li> <li>CM_SSH_KEY_FILE: <code>$HOME/.ssh/id_rsa</code></li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Remote-automation/remote-run-commands/#script-output","title":"Script output","text":"<pre><code>cmr \"remote run cmds remote-run remote-run-cmds ssh-run ssh \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/","title":"Reproduce-MLPerf-benchmarks","text":"<ul> <li>app-mlperf-inference-nvidia</li> <li>reproduce-mlperf-octoml-tinyml-results</li> <li>reproduce-mlperf-training-nvidia</li> <li>wrapper-reproduce-octoml-tinyml-submission</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/","title":"app-mlperf-inference-nvidia","text":"<p>Automatically generated README for this automation recipe: app-mlperf-inference-nvidia</p> <p>Category: Reproduce MLPerf benchmarks</p> <p>License: Apache 2.0</p> <p>This script is a CM wrapper to the official Nvidia submission code used for MLPerf inference submissions. </p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#download-the-needed-files","title":"Download the needed files","text":"<ul> <li>Please ask privately in this discord channel if you would like to get access to an Amazon S3 bucket containing all the needed files for easiness. Otherwise, you can download them from the below links.</li> </ul> <p>For x86 machines, please download the latest install tar files from the below sites 1. cuDNN (for cuda 11) 2. TensorRT 3. Imagenet validation set (unfortunately not available via public URL) following the instructions given here</p>   ## Using Docker (Recommended on x86 systems)   Assuming all the downloaded files are to the user home directory please do the following steps:  1. Download CUDA 11.8     <pre><code>wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\n</code></pre> 2. [Install docker](https://docs.docker.com/engine/install/) and [Nvidia container toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)  3. Give docker permission to the current user      <pre><code>sudo usermod -aG docker $USER\n</code></pre>      Logout and login      Restart docker if required and confirm that Nvidia container toolkit is working by      <pre><code>nvidia-ctk --version\n</code></pre> 4. Check if Nvidia driver is working properly on the host.       <pre><code>nvidia-smi\n</code></pre>      If the above command produces any error you'll need to install Nvidia drivers on the host. You can do this via CM if you have sudo access      <pre><code>cmr \"install cuda prebuilt _driver\" --version=11.8.0\n</code></pre> 5. Build the docker container and mount the paths from the host machine.     ** You may want to change the `scratch_path` location as it can take 100s of GBs.**     <pre><code>cm docker script --tags=build,nvidia,inference,server \\\n--cuda_run_file_path=$HOME/cuda_11.8.0_520.61.05_linux.run \\\n--tensorrt_tar_file_path=$HOME/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz \\\n--cudnn_tar_file_path=$HOME/cudnn-linux-x86_64-8.9.2.26_cuda11-archive.tar.xz \\\n--imagenet_path=$HOME/imagenet-2012-val \\\n--scratch_path=$HOME/mlperf_scratch \\\n--docker_cm_repo=mlcommons@cm4mlops  \\\n--results_dir=$HOME/results_dir \\\n--submission_dir=$HOME/submission_dir \\\n--adr.compiler.tags=gcc\n</code></pre>       * Use `--docker_cache=no` to turn off docker caching       * Use `--docker_run_cmd_prefix=\"cm pull repo mlcommons@cm4mlops --checkout=dev\"` to update the CK repository when docker caching is used       * Use `--custom_system=no` if you are using a similar system to the [Nvidia submission systems for MLPerf inference 3.0](https://github.com/mlcommons/inference_results_v3.0/tree/main/closed/NVIDIA/systems).  6. At the end of the build you'll get the following prompt unless you have chosen `--custom_system=no`. Please give a system name and say yes to generating the configuration files     ### Example output     <pre><code>============================================\n=&gt; A system ID is a string containing only letters, numbers, and underscores\n=&gt; that is used as the human-readable name of the system. It is also used as\n=&gt; the system name when creating the measurements/ and results/ entries.\n=&gt; This string should also start with a letter to be a valid Python enum member name.\n=&gt; Specify the system ID to use for the current system: phoenix\n  =&gt; Reloaded system list. MATCHED_SYSTEM: KnownSystem.phoenix\n=&gt; This script will generate Benchmark Configuration stubs for the detected system.\nContinue? [y/n]: y\n</code></pre>     Now you'll be inside the CM Nvidia docker container and can run further scripts.   7. Once the build is complete, you can proceed with any further CM scripts like for MLPerf inference. You can also save the container at this stage using [docker commit](https://docs.docker.com/engine/reference/commandline/commit/) so that it can be launched later without having to go through the previous steps.     ## Without Docker   1. Install CUDA     If CUDA is not detected, CM should download and install it automatically when you run the workflow.      ** Nvidia drivers are expected to be installed on the system **  2. Install cuDNN     <pre><code>  cmr \"get cudnn\" --tar_file=&lt;PATH_TO_CUDNN_TAR_FILE&gt;\n</code></pre> 3. Install TensorRT     <pre><code>  cmr \"get tensorrt _dev\" --tar_file=&lt;PATH_TO_TENSORRT_TAR_FILE&gt;\n</code></pre>     On non x86 systems like Nvidia Orin, you can do a package manager install and then CM should pick up the installation automatically during the workflow run.  4. Build the Nvidia inference server      ```       cmr \"build nvidia inference server\" \\       --adr.install-cuda-prebuilt.local_run_file_path=/data/cuda_11.8.0_520.61.05_linux.run \\       --adr.tensorrt.tar_file=/data/TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz \\       --adr.cudnn.tar_file=/data/cudnn-linux-x86_64-8.9.2.26_cuda11-archive.tar.xz \\       --adr.compiler.tags=gcc \\       [--custom_system=no]       ```     Use `--custom_system=no` if you are using a similar system to the [Nvidia submission systems for MLPerf inference 3.0](https://github.com/mlcommons/inference_results_v3.0/tree/main/closed/NVIDIA/systems).  5. At the end of the build you'll get the following prompt unless you have chosen `--custom_system=no`. Please give a system name and say yes to generating the configuration files      ### Example output     <pre><code>============================================\n=&gt; A system ID is a string containing only letters, numbers, and underscores\n=&gt; that is used as the human-readable name of the system. It is also used as\n=&gt; the system name when creating the measurements/ and results/ entries.\n=&gt; This string should also start with a letter to be a valid Python enum member name.\n=&gt; Specify the system ID to use for the current system: phoenix\n  =&gt; Reloaded system list. MATCHED_SYSTEM: KnownSystem.phoenix\n=&gt; This script will generate Benchmark Configuration stubs for the detected system.\nContinue? [y/n]: y\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#acknowledgments","title":"Acknowledgments","text":"<ul> <li>A common CM interface and automation for MLPerf inference benchmarks was developed by Arjun Suresh and Grigori Fursin    sponsored by the cTuning foundation and cKnowledge.org.</li> <li> <p>Nvidia's MLPerf inference implementation was developed by Zhihan Jiang, Ethan Cheng, Yiheng Zhang and Jinho Suh.</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce mlcommons mlperf inference harness nvidia-harness nvidia\" --help</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,mlcommons,mlperf,inference,harness,nvidia-harness,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness nvidia-harness nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,mlcommons,mlperf,inference,harness,nvidia-harness,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce mlcommons mlperf inference harness nvidia-harness nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_run-harness</code></li> <li><code>_v3.1</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>v3.1</code></li> <li>CM_MLPERF_GPTJ_MODEL_FP8_PATH_SUFFIX: <code>GPTJ-07142023.pth</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"backend\"      Click here to expand this section. <ul> <li><code>_tensorrt</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_BACKEND: <code>tensorrt</code></li> <li>CM_MLPERF_BACKEND_NAME: <code>TensorRT</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"batch-size\"      Click here to expand this section. <ul> <li><code>_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MODEL_BATCH_SIZE: <code>#</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_GPU_BATCH_SIZE: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"build-engine-options\"      Click here to expand this section. <ul> <li><code>_build_engine_options.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_EXTRA_BUILD_ENGINE_OPTIONS: <code>#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device\"      Click here to expand this section. <ul> <li><code>_cpu</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>cpu</code></li> </ul> </li> </ul> </li> <li><code>_cuda</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_DEVICE: <code>gpu</code></li> <li>CM_MLPERF_DEVICE_LIB_NAMESPEC: <code>cudart</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"device-memory\"      Click here to expand this section. <ul> <li><code>_gpu_memory.16</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>16</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.24</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>24</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.32</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>32</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.40</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>40</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.48</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>48</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.8</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>8</code></li> </ul> </li> </ul> </li> <li><code>_gpu_memory.80</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_GPU_MEMORY: <code>80</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"dla-batch-size\"      Click here to expand this section. <ul> <li><code>_dla_batch_size.#</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_DLA_BATCH_SIZE: <code>#</code></li> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX2: <code>dla_batch_size.#</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"gpu-connection\"      Click here to expand this section. <ul> <li><code>_pcie</code></li> <li><code>_sxm</code></li> </ul> <li> <p>Group \"gpu-name\"      Click here to expand this section. <ul> <li><code>_a100</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_a6000</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_custom</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> <li>CM_MODEL_BATCH_SIZE: ``</li> <li>CM_MLPERF_NVIDIA_HARNESS_GPU_BATCH_SIZE: <code>&lt;&lt;&lt;CM_MODEL_BATCH_SIZE&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_l4</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_orin</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> <li>CM_MODEL_BATCH_SIZE: ``</li> <li>CM_MLPERF_NVIDIA_HARNESS_GPU_BATCH_SIZE: <code>&lt;&lt;&lt;CM_MODEL_BATCH_SIZE&gt;&gt;&gt;</code></li> </ul> </li> </ul> </li> <li><code>_rtx_4090</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_rtx_6000_ada</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_t4</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_CUSTOM_GPU: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"loadgen-scenario\"      Click here to expand this section. <ul> <li><code>_multistream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>MultiStream</code></li> </ul> </li> </ul> </li> <li><code>_offline</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> </ul> </li> </ul> </li> <li><code>_server</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Server</code></li> </ul> </li> </ul> </li> <li><code>_singlestream</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>SingleStream</code></li> <li>CUDA_VISIBLE_DEVICES_NOT_USED: <code>0</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"model\"      Click here to expand this section. <ul> <li><code>_3d-unet-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/5597155/files/3dunet_kits19_128x128x128.onnx</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_3d-unet-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>3d-unet-99.9</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/5597155/files/3dunet_kits19_128x128x128.onnx</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_bert-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3750364/files/bert_large_v1_1_fake_quant.onnx</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_bert-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>bert-99.9</code></li> <li>CM_NOT_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3733910/files/model.onnx</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-v2-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-v2-99</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_dlrm-v2-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>dlrm-v2-99.9</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_gptj-99.9</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>gptj-99.9</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int32</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> <li><code>_resnet50</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>resnet50</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_retinanet</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>retinanet</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/6617981/files/resnext50_32x4d_fpn.pth</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>int8</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>int8</code></li> </ul> </li> </ul> </li> <li><code>_rnnt</code><ul> <li>ENV variables:<ul> <li>CM_MODEL: <code>rnnt</code></li> <li>CM_ML_MODEL_STARTING_WEIGHTS_FILENAME: <code>https://zenodo.org/record/3662521/files/DistributedDataParallel_1576581068.9962234-epoch-100.pt</code></li> <li>CM_ML_MODEL_WEIGHT_TRANSFORMATIONS: <code>quantization, affine fusion</code></li> <li>CM_ML_MODEL_INPUTS_DATA_TYPE: <code>fp16</code></li> <li>CM_ML_MODEL_WEIGHTS_DATA_TYPE: <code>fp16</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"num-gpus\"      Click here to expand this section. <ul> <li><code>_num-gpus.#</code><ul> <li>ENV variables:<ul> <li>CM_NVIDIA_NUM_GPUS: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_num-gpus.1</code> (default)<ul> <li>ENV variables:<ul> <li>CM_NVIDIA_NUM_GPUS: <code>1</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"power-mode\"      Click here to expand this section. <ul> <li><code>_maxn</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXN: <code>True</code></li> </ul> </li> </ul> </li> <li><code>_maxq</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_MAXQ: <code>True</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"run-mode\"      Click here to expand this section. <ul> <li><code>_build</code><ul> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>build</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>build</code></li> </ul> </li> </ul> </li> <li><code>_build_engine</code><ul> <li>Aliases: <code>_build-engine</code></li> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>generate_engines</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>generate_engines</code></li> </ul> </li> </ul> </li> <li><code>_calibrate</code><ul> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>calibrate</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>calibrate</code></li> </ul> </li> </ul> </li> <li><code>_download_model</code><ul> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>download_model</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>download_model</code></li> </ul> </li> </ul> </li> <li><code>_prebuild</code><ul> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>prebuild</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>prebuild</code></li> </ul> </li> </ul> </li> <li><code>_preprocess_data</code><ul> <li>ENV variables:<ul> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>preprocess_data</code></li> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>preprocess_data</code></li> </ul> </li> </ul> </li> <li><code>_run_harness</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_RUN_MODE: <code>run_harness</code></li> <li>MLPERF_NVIDIA_RUN_COMMAND: <code>run_harness</code></li> <li>CM_CALL_MLPERF_RUNNER: <code>yes</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"triton\"      Click here to expand this section. <ul> <li><code>_use_triton</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_NVIDIA_HARNESS_USE_TRITON: <code>yes</code></li> <li>CM_MLPERF_SUT_NAME_RUN_CONFIG_SUFFIX3: <code>using_triton</code></li> </ul> </li> </ul> </li> </ul> <li> <p>Group \"version\"      Click here to expand this section. <ul> <li><code>_v4.0</code> (default)<ul> <li>ENV variables:<ul> <li>CM_MLPERF_INFERENCE_VERSION: <code>v4.0</code></li> <li>CM_MLPERF_GPTJ_MODEL_FP8_PATH_SUFFIX: <code>GPTJ-FP8-quantized</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#default-variations","title":"Default variations","text":"<p><code>_cuda,_num-gpus.1,_resnet50,_run_harness,_tensorrt,_v4.0</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--audio_buffer_num_lines=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_AUDIO_BUFFER_NUM_LINES=value</code></li> <li><code>--count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_QUERY_COUNT=value</code></li> <li><code>--deque_timeout_usec=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_DEQUE_TIMEOUT_USEC=value</code></li> <li><code>--devices=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_DEVICES=value</code></li> <li><code>--dla_batch_size=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_DLA_BATCH_SIZE=value</code></li> <li><code>--dla_copy_streams=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_DLA_COPY_STREAMS=value</code></li> <li><code>--dla_inference_streams=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_DLA_INFERENCE_STREAMS=value</code></li> <li><code>--embedding_weights_on_gpu_part=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_EMBEDDING_WEIGHTS_ON_GPU_PART=value</code></li> <li><code>--enable_sort=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_ENABLE_SORT=value</code></li> <li><code>--end_on_device=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_END_ON_DEVICE=value</code></li> <li><code>--extra_run_options=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_EXTRA_RUN_OPTIONS=value</code></li> <li><code>--gpu_batch_size=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_GPU_BATCH_SIZE=value</code></li> <li><code>--gpu_copy_streams=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_GPU_COPY_STREAMS=value</code></li> <li><code>--gpu_inference_streams=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_GPU_INFERENCE_STREAMS=value</code></li> <li><code>--graphs_max_seqlen=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_GRAPHS_MAX_SEQLEN=value</code></li> <li><code>--input_format=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_INPUT_FORMAT=value</code></li> <li><code>--log_dir=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_LOG_DIR=value</code></li> <li><code>--make_cmd=value</code>  \u2192  <code>MLPERF_NVIDIA_RUN_COMMAND=value</code></li> <li><code>--max_batchsize=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MAX_BATCHSIZE=value</code></li> <li><code>--max_dlas=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_MAX_DLAS=value</code></li> <li><code>--mlperf_conf=value</code>  \u2192  <code>CM_MLPERF_CONF=value</code></li> <li><code>--mode=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MODE=value</code></li> <li><code>--multistream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_MULTISTREAM_TARGET_LATENCY=value</code></li> <li><code>--num_issue_query_threads=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_NUM_ISSUE_QUERY_THREADS=value</code></li> <li><code>--num_sort_segments=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_NUM_SORT_SEGMENTS=value</code></li> <li><code>--num_warmups=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_NUM_WARMUPS=value</code></li> <li><code>--offline_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_OFFLINE_TARGET_QPS=value</code></li> <li><code>--output_dir=value</code>  \u2192  <code>CM_MLPERF_OUTPUT_DIR=value</code></li> <li><code>--performance_sample_count=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_PERFORMANCE_SAMPLE_COUNT=value</code></li> <li><code>--power_setting=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_POWER_SETTING=value</code></li> <li><code>--rerun=value</code>  \u2192  <code>CM_RERUN=value</code></li> <li><code>--run_infer_on_copy_streams=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_RUN_INFER_ON_COPY_STREAMS=value</code></li> <li><code>--scenario=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SCENARIO=value</code></li> <li><code>--server_target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SERVER_TARGET_QPS=value</code></li> <li><code>--singlestream_target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_SINGLESTREAM_TARGET_LATENCY=value</code></li> <li><code>--skip_postprocess=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_SKIP_POSTPROCESS=value</code></li> <li><code>--skip_preprocess=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--skip_preprocessing=value</code>  \u2192  <code>CM_SKIP_PREPROCESS_DATASET=value</code></li> <li><code>--soft_drop=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_SOFT_DROP=value</code></li> <li><code>--start_from_device=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_START_FROM_DEVICE=value</code></li> <li><code>--target_latency=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_LATENCY=value</code></li> <li><code>--target_qps=value</code>  \u2192  <code>CM_MLPERF_LOADGEN_TARGET_QPS=value</code></li> <li><code>--use_cuda_thread_per_device=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_CUDA_THREAD_PER_DEVICE=value</code></li> <li><code>--use_deque_limit=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_DEQUE_LIMIT=value</code></li> <li><code>--use_fp8=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_FP8=value</code></li> <li><code>--use_graphs=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_GRAPHS=value</code></li> <li><code>--use_small_tile_gemm_plugin=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_SMALL_TILE_GEMM_PLUGIN=value</code></li> <li><code>--use_triton=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_USE_TRITON=value</code></li> <li><code>--user_conf=value</code>  \u2192  <code>CM_MLPERF_USER_CONF=value</code></li> <li><code>--workspace_size=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_HARNESS_WORKSPACE_SIZE=value</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_BATCH_COUNT: <code>1</code></li> <li>CM_BATCH_SIZE: <code>1</code></li> <li>CM_FAST_COMPILATION: <code>yes</code></li> <li>CM_MLPERF_LOADGEN_SCENARIO: <code>Offline</code></li> <li>CM_MLPERF_LOADGEN_MODE: <code>performance</code></li> <li>CM_SKIP_PREPROCESS_DATASET: <code>no</code></li> <li>CM_SKIP_MODEL_DOWNLOAD: <code>no</code></li> <li>CM_MLPERF_SUT_NAME_IMPLEMENTATION_PREFIX: <code>nvidia_original</code></li> <li>CM_MLPERF_SKIP_RUN: <code>no</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/app-mlperf-inference-nvidia/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce mlcommons mlperf inference harness nvidia-harness nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/","title":"reproduce-mlperf-octoml-tinyml-results","text":"<p>Automatically generated README for this automation recipe: reproduce-mlperf-octoml-tinyml-results</p> <p>Category: Reproduce MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce tiny results mlperf octoml mlcommons\" --help</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,tiny,results,mlperf,octoml,mlcommons[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce tiny results mlperf octoml mlcommons [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,tiny,results,mlperf,octoml,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce tiny results mlperf octoml mlcommons[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_NRF</code><ul> <li>ENV variables:<ul> <li>CM_TINY_BOARD: <code>NRF5340DK</code></li> </ul> </li> </ul> </li> <li><code>_NUCLEO</code><ul> <li>ENV variables:<ul> <li>CM_TINY_BOARD: <code>NUCLEO_L4R5ZI</code></li> </ul> </li> </ul> </li> <li><code>_ad</code><ul> <li>ENV variables:<ul> <li>CM_TINY_MODEL: <code>ad</code></li> </ul> </li> </ul> </li> <li><code>_cmsis_nn</code><ul> <li>ENV variables:<ul> <li>CM_MICROTVM_VARIANT: <code>microtvm_cmsis_nn</code></li> </ul> </li> </ul> </li> <li><code>_ic</code><ul> <li>ENV variables:<ul> <li>CM_TINY_MODEL: <code>ic</code></li> </ul> </li> </ul> </li> <li><code>_kws</code><ul> <li>ENV variables:<ul> <li>CM_TINY_MODEL: <code>kws</code></li> </ul> </li> </ul> </li> <li><code>_native</code><ul> <li>ENV variables:<ul> <li>CM_MICROTVM_VARIANT: <code>microtvm_native</code></li> </ul> </li> </ul> </li> <li><code>_vww</code><ul> <li>ENV variables:<ul> <li>CM_TINY_MODEL: <code>vww</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--flash=value</code>  \u2192  <code>CM_FLASH_BOARD=value</code></li> <li><code>--recreate_binary=value</code>  \u2192  <code>CM_RECREATE_BINARY=value</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#versions","title":"Versions","text":"<p>Default version: <code>r1.0</code></p> <ul> <li><code>r1.0</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-octoml-tinyml-results/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce tiny results mlperf octoml mlcommons [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/","title":"reproduce-mlperf-training-nvidia","text":"<p>Automatically generated README for this automation recipe: reproduce-mlperf-training-nvidia</p> <p>Category: Reproduce MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce mlcommons mlperf train training nvidia-training nvidia\" --help</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,mlcommons,mlperf,train,training,nvidia-training,nvidia[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce mlcommons mlperf train training nvidia-training nvidia [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,mlcommons,mlperf,train,training,nvidia-training,nvidia'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce mlcommons mlperf train training nvidia-training nvidia[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#variations","title":"Variations","text":"<ul> <li> <p>Group \"benchmark\"      Click here to expand this section. <ul> <li><code>_resnet</code><ul> <li>ENV variables:<ul> <li>CM_MLPERF_TRAINING_BENCHMARK: <code>resnet</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--results_dir=value</code>  \u2192  <code>CM_MLPERF_RESULTS_DIR=value</code></li> <li><code>--system_conf_name=value</code>  \u2192  <code>CM_MLPERF_NVIDIA_TRAINING_SYSTEM_CONF_NAME=value</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#versions","title":"Versions","text":"<ul> <li><code>r2.1</code></li> <li><code>r3.0</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-resnet.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/reproduce-mlperf-training-nvidia/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce mlcommons mlperf train training nvidia-training nvidia [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/","title":"wrapper-reproduce-octoml-tinyml-submission","text":"<p>Automatically generated README for this automation recipe: wrapper-reproduce-octoml-tinyml-submission</p> <p>Category: Reproduce MLPerf benchmarks</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run generate-tiny generate submission tiny generate-tiny-submission results mlcommons mlperf octoml\" --help</code></p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,generate-tiny,generate,submission,tiny,generate-tiny-submission,results,mlcommons,mlperf,octoml [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run generate-tiny generate submission tiny generate-tiny-submission results mlcommons mlperf octoml \" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,generate-tiny,generate,submission,tiny,generate-tiny-submission,results,mlcommons,mlperf,octoml'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run generate-tiny generate submission tiny generate-tiny-submission results mlcommons mlperf octoml\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--flash=value</code>  \u2192  <code>CM_FLASH_BOARD=value</code></li> <li><code>--recreate_binary=value</code>  \u2192  <code>CM_RECREATE_BINARY=value</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#versions","title":"Versions","text":"<p>Default version: <code>r1.0</code></p> <ul> <li><code>r1.0</code></li> </ul>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Reproduce-MLPerf-benchmarks/wrapper-reproduce-octoml-tinyml-submission/#script-output","title":"Script output","text":"<pre><code>cmr \"run generate-tiny generate submission tiny generate-tiny-submission results mlcommons mlperf octoml \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/","title":"Reproducibility-and-artifact-evaluation","text":"<ul> <li>get-ipol-src</li> <li>process-ae-users</li> <li>reproduce-ipol-paper-2022-439</li> <li>reproduce-micro-paper-2023-victima</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/","title":"get-ipol-src","text":"<p>Automatically generated README for this automation recipe: get-ipol-src</p> <p>Category: Reproducibility and artifact evaluation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get ipol journal src ipol-src\" --help</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input FlagsInput Flag Mapping"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,ipol,journal,src,ipol-src [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get ipol journal src ipol-src \" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,ipol,journal,src,ipol-src'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get ipol journal src ipol-src\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#input-flags","title":"Input Flags","text":"<ul> <li>--number: IPOL publication number</li> <li>--year: IPOL publication year</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--number=value</code>  \u2192  <code>CM_IPOL_NUMBER=value</code></li> <li><code>--year=value</code>  \u2192  <code>CM_IPOL_YEAR=value</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/get-ipol-src/#script-output","title":"Script output","text":"<pre><code>cmr \"get ipol journal src ipol-src \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/","title":"process-ae-users","text":"<p>Automatically generated README for this automation recipe: process-ae-users</p> <p>Category: Reproducibility and artifact evaluation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"process ae users\" --help</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=process,ae,users [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"process ae users \" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'process,ae,users'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"process ae users\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--file=value</code>  \u2192  <code>CM_PROCESS_AE_USERS_INPUT_FILE=value</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/process-ae-users/#script-output","title":"Script output","text":"<pre><code>cmr \"process ae users \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/","title":"reproduce-ipol-paper-2022-439","text":"<p>Automatically generated README for this automation recipe: reproduce-ipol-paper-2022-439</p> <p>Category: Reproducibility and artifact evaluation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"app python reproduce project paper ipol journal repro reproducibility pytorch 2022-439\" --help</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=app,python,reproduce,project,paper,ipol,journal,repro,reproducibility,pytorch,2022-439 [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"app python reproduce project paper ipol journal repro reproducibility pytorch 2022-439 \" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'app,python,reproduce,project,paper,ipol,journal,repro,reproducibility,pytorch,2022-439'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"app python reproduce project paper ipol journal repro reproducibility pytorch 2022-439\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--image1=value</code>  \u2192  <code>CM_IMAGE_1=value</code></li> <li><code>--image2=value</code>  \u2192  <code>CM_IMAGE_2=value</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-ipol-paper-2022-439/#script-output","title":"Script output","text":"<pre><code>cmr \"app python reproduce project paper ipol journal repro reproducibility pytorch 2022-439 \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/","title":"reproduce-micro-paper-2023-victima","text":"<p>Automatically generated README for this automation recipe: reproduce-micro-paper-2023-victima</p> <p>Category: Reproducibility and artifact evaluation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"reproduce project paper micro micro-2023 victima\" --help</code></p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=reproduce,project,paper,micro,micro-2023,victima[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"reproduce project paper micro micro-2023 victima [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'reproduce,project,paper,micro,micro-2023,victima'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"reproduce project paper micro micro-2023 victima[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_install_deps</code></li> <li><code>_plot</code></li> <li><code>_run</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--container=value</code>  \u2192  <code>CM_VICTIMA_CONTAINER=value</code></li> <li><code>--job_manager=value</code>  \u2192  <code>CM_VICTIMA_JOB_MANAGER=value</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_VICTIMA_JOB_MANAGER: <code>native</code></li> <li>CM_VICTIMA_CONTAINER: <code>docker</code></li> </ul>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Reproducibility-and-artifact-evaluation/reproduce-micro-paper-2023-victima/#script-output","title":"Script output","text":"<pre><code>cmr \"reproduce project paper micro micro-2023 victima [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/","title":"Tests","text":"<ul> <li>print-any-text</li> <li>print-croissant-desc</li> <li>print-hello-world</li> <li>print-hello-world-java</li> <li>print-hello-world-javac</li> <li>print-hello-world-py</li> <li>print-python-version</li> <li>run-python</li> <li>test-cm-core</li> <li>test-cm-script-pipeline</li> <li>test-deps-conditions</li> <li>test-deps-conditions2</li> <li>test-download-and-extract-artifacts</li> <li>test-set-sys-user-cm</li> <li>upgrade-python-pip</li> </ul>"},{"location":"scripts/Tests/print-any-text/","title":"print-any-text","text":"<p>Automatically generated README for this automation recipe: print-any-text</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-any-text/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-any-text/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-any-text/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-any-text/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print any-text\" --help</code></p>"},{"location":"scripts/Tests/print-any-text/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Tests/print-any-text/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,any-text[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-any-text/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print any-text [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-any-text/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,any-text'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-any-text/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print any-text[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-any-text/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_cm_env.#</code><ul> <li>ENV variables:<ul> <li>CM_PRINT_ANY_CM_ENV_KEYS: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_os_env.#</code><ul> <li>ENV variables:<ul> <li>CM_PRINT_ANY_OS_ENV_KEYS: <code>#</code></li> </ul> </li> </ul> </li> <li><code>_text.#</code><ul> <li>ENV variables:<ul> <li>CM_PRINT_ANY_TEXT: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Tests/print-any-text/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--cm_env_keys=value</code>  \u2192  <code>CM_PRINT_ANY_CM_ENV_KEYS=value</code></li> <li><code>--os_env_keys=value</code>  \u2192  <code>CM_PRINT_ANY_OS_ENV_KEYS=value</code></li> <li><code>--text=value</code>  \u2192  <code>CM_PRINT_ANY_TEXT=value</code></li> </ul>"},{"location":"scripts/Tests/print-any-text/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_PRINT_ANY_TEXT: ``</li> </ul>"},{"location":"scripts/Tests/print-any-text/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-any-text/#script-output","title":"Script output","text":"<pre><code>cmr \"print any-text [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/print-croissant-desc/","title":"print-croissant-desc","text":"<p>Automatically generated README for this automation recipe: print-croissant-desc</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-croissant-desc/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-croissant-desc/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-croissant-desc/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-croissant-desc/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print croissant desc\" --help</code></p>"},{"location":"scripts/Tests/print-croissant-desc/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag MappingDefault environment"},{"location":"scripts/Tests/print-croissant-desc/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,croissant,desc [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-croissant-desc/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print croissant desc \" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-croissant-desc/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,croissant,desc'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-croissant-desc/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print croissant desc\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-croissant-desc/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--url=value</code>  \u2192  <code>CM_PRINT_CROISSANT_URL=value</code></li> </ul>"},{"location":"scripts/Tests/print-croissant-desc/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_PRINT_CROISSANT_URL: <code>https://raw.githubusercontent.com/mlcommons/croissant/main/datasets/1.0/gpt-3/metadata.json</code></li> </ul>"},{"location":"scripts/Tests/print-croissant-desc/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-croissant-desc/#script-output","title":"Script output","text":"<pre><code>cmr \"print croissant desc \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/print-hello-world/","title":"print-hello-world","text":"<p>Automatically generated README for this automation recipe: print-hello-world</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-hello-world/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-hello-world/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-hello-world/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-hello-world/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print hello-world hello world hello world native-script native script\" --help</code></p>"},{"location":"scripts/Tests/print-hello-world/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag MappingDefault environment"},{"location":"scripts/Tests/print-hello-world/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,hello-world,hello world,hello,world,native-script,native,script[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-hello-world/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print hello-world hello world hello world native-script native script [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-hello-world/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,hello-world,hello world,hello,world,native-script,native,script'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-hello-world/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print hello-world hello world hello world native-script native script[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/print-hello-world/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_skip_print_env</code><ul> <li>ENV variables:<ul> <li>CM_PRINT_HELLO_WORLD_SKIP_PRINT_ENV: <code>yes</code></li> </ul> </li> </ul> </li> <li><code>_text.#</code><ul> <li>ENV variables:<ul> <li>CM_PRINT_HELLO_WORLD_TEXT: <code>#</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/Tests/print-hello-world/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--test1=value</code>  \u2192  <code>CM_ENV_TEST1=value</code></li> </ul>"},{"location":"scripts/Tests/print-hello-world/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_ENV_TEST1: <code>TEST1</code></li> </ul>"},{"location":"scripts/Tests/print-hello-world/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-hello-world/#script-output","title":"Script output","text":"<pre><code>cmr \"print hello-world hello world hello world native-script native script [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-java/","title":"print-hello-world-java","text":"<p>Automatically generated README for this automation recipe: print-hello-world-java</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-hello-world-java/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-hello-world-java/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-hello-world-java/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-hello-world-java/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print hello world hello-world hello world java\" --help</code></p>"},{"location":"scripts/Tests/print-hello-world-java/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/print-hello-world-java/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,hello world,hello-world,hello,world,java \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-java/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print hello world hello-world hello world java \" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-java/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,hello world,hello-world,hello,world,java'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-java/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print hello world hello-world hello world java\" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-java/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-hello-world-java/#script-output","title":"Script output","text":"<pre><code>cmr \"print hello world hello-world hello world java \"  -j\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-javac/","title":"print-hello-world-javac","text":"<p>Automatically generated README for this automation recipe: print-hello-world-javac</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-hello-world-javac/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-hello-world-javac/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-hello-world-javac/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-hello-world-javac/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print hello world hello-world hello world javac\" --help</code></p>"},{"location":"scripts/Tests/print-hello-world-javac/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/print-hello-world-javac/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,hello world,hello-world,hello,world,javac \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-javac/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print hello world hello-world hello world javac \" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-javac/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,hello world,hello-world,hello,world,javac'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-javac/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print hello world hello-world hello world javac\" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-javac/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-hello-world-javac/#script-output","title":"Script output","text":"<pre><code>cmr \"print hello world hello-world hello world javac \"  -j\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-py/","title":"print-hello-world-py","text":"<p>Automatically generated README for this automation recipe: print-hello-world-py</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-hello-world-py/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-hello-world-py/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-hello-world-py/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-hello-world-py/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print hello world hello-world hello world python\" --help</code></p>"},{"location":"scripts/Tests/print-hello-world-py/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/print-hello-world-py/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,hello world,hello-world,hello,world,python \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-py/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print hello world hello-world hello world python \" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-py/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,hello world,hello-world,hello,world,python'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-hello-world-py/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print hello world hello-world hello world python\" \n</code></pre>"},{"location":"scripts/Tests/print-hello-world-py/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-hello-world-py/#script-output","title":"Script output","text":"<pre><code>cmr \"print hello world hello-world hello world python \"  -j\n</code></pre>"},{"location":"scripts/Tests/print-python-version/","title":"print-python-version","text":"<p>Automatically generated README for this automation recipe: print-python-version</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/print-python-version/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/print-python-version/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/print-python-version/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/print-python-version/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"print python version python-version\" --help</code></p>"},{"location":"scripts/Tests/print-python-version/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/print-python-version/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=print,python,version,python-version \n</code></pre>"},{"location":"scripts/Tests/print-python-version/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"print python version python-version \" \n</code></pre>"},{"location":"scripts/Tests/print-python-version/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'print,python,version,python-version'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/print-python-version/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"print python version python-version\" \n</code></pre>"},{"location":"scripts/Tests/print-python-version/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/print-python-version/#script-output","title":"Script output","text":"<pre><code>cmr \"print python version python-version \"  -j\n</code></pre>"},{"location":"scripts/Tests/run-python/","title":"run-python","text":"<p>Automatically generated README for this automation recipe: run-python</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/run-python/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/run-python/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/run-python/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/run-python/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"run python\" --help</code></p>"},{"location":"scripts/Tests/run-python/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Tests/run-python/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=run,python [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/run-python/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"run python \" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/run-python/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'run,python'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/run-python/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"run python\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/run-python/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--command=value</code>  \u2192  <code>CM_RUN_PYTHON_CMD=value</code></li> </ul>"},{"location":"scripts/Tests/run-python/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/run-python/#script-output","title":"Script output","text":"<pre><code>cmr \"run python \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/test-cm-core/","title":"test-cm-core","text":"<p>Automatically generated README for this automation recipe: test-cm-core</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/test-cm-core/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-cm-core/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-cm-core/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-cm-core/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test cm core\" --help</code></p>"},{"location":"scripts/Tests/test-cm-core/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/test-cm-core/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,cm,core \n</code></pre>"},{"location":"scripts/Tests/test-cm-core/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test cm core \" \n</code></pre>"},{"location":"scripts/Tests/test-cm-core/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,cm,core'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-cm-core/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test cm core\" \n</code></pre>"},{"location":"scripts/Tests/test-cm-core/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/test-cm-core/#script-output","title":"Script output","text":"<pre><code>cmr \"test cm core \"  -j\n</code></pre>"},{"location":"scripts/Tests/test-cm-script-pipeline/","title":"test-cm-script-pipeline","text":"<p>Automatically generated README for this automation recipe: test-cm-script-pipeline</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/test-cm-script-pipeline/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-cm-script-pipeline/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-cm-script-pipeline/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-cm-script-pipeline/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test cm-script pipeline\" --help</code></p>"},{"location":"scripts/Tests/test-cm-script-pipeline/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/test-cm-script-pipeline/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,cm-script,pipeline \n</code></pre>"},{"location":"scripts/Tests/test-cm-script-pipeline/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test cm-script pipeline \" \n</code></pre>"},{"location":"scripts/Tests/test-cm-script-pipeline/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,cm-script,pipeline'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-cm-script-pipeline/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test cm-script pipeline\" \n</code></pre>"},{"location":"scripts/Tests/test-cm-script-pipeline/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> <li>run2.sh</li> </ul> <ul> <li>run.bat</li> <li>run2.bat</li> </ul>"},{"location":"scripts/Tests/test-cm-script-pipeline/#script-output","title":"Script output","text":"<pre><code>cmr \"test cm-script pipeline \"  -j\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions/","title":"test-deps-conditions","text":"<p>Automatically generated README for this automation recipe: test-deps-conditions</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/test-deps-conditions/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-deps-conditions/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-deps-conditions/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-deps-conditions/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test deps conditions\" --help</code></p>"},{"location":"scripts/Tests/test-deps-conditions/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Tests/test-deps-conditions/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,deps,conditions [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test deps conditions \" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,deps,conditions'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test deps conditions\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--test1=value</code>  \u2192  <code>CM_ENV1=value</code></li> <li><code>--test2=value</code>  \u2192  <code>CM_ENV2=value</code></li> <li><code>--test3=value</code>  \u2192  <code>CM_ENV3=value</code></li> </ul>"},{"location":"scripts/Tests/test-deps-conditions/#script-output","title":"Script output","text":"<pre><code>cmr \"test deps conditions \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions2/","title":"test-deps-conditions2","text":"<p>Automatically generated README for this automation recipe: test-deps-conditions2</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <p>Developers: Grigori Fursin * Notes from the authors, contributors and users: README-extra</p> <ul> <li>CM meta description for this script: _cm.yaml</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/test-deps-conditions2/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-deps-conditions2/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-deps-conditions2/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-deps-conditions2/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test deps conditions2\" --help</code></p>"},{"location":"scripts/Tests/test-deps-conditions2/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Input Flag Mapping"},{"location":"scripts/Tests/test-deps-conditions2/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,deps,conditions2 [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions2/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test deps conditions2 \" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions2/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,deps,conditions2'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions2/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test deps conditions2\" [--input_flags]\n</code></pre>"},{"location":"scripts/Tests/test-deps-conditions2/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--test=value</code>  \u2192  <code>TEST=value</code></li> </ul>"},{"location":"scripts/Tests/test-deps-conditions2/#script-output","title":"Script output","text":"<pre><code>cmr \"test deps conditions2 \" [--input_flags] -j\n</code></pre>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/","title":"test-download-and-extract-artifacts","text":"<p>Automatically generated README for this automation recipe: test-download-and-extract-artifacts</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.yaml</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-download-and-extract-artifacts/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"test download-and-extract-artifacts\" --help</code></p>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=test,download-and-extract-artifacts \n</code></pre>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"test download-and-extract-artifacts \" \n</code></pre>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'test,download-and-extract-artifacts'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"test download-and-extract-artifacts\" \n</code></pre>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/test-download-and-extract-artifacts/#script-output","title":"Script output","text":"<pre><code>cmr \"test download-and-extract-artifacts \"  -j\n</code></pre>"},{"location":"scripts/Tests/test-set-sys-user-cm/","title":"test-set-sys-user-cm","text":"<p>Automatically generated README for this automation recipe: test-set-sys-user-cm</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/Tests/test-set-sys-user-cm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/test-set-sys-user-cm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/test-set-sys-user-cm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/test-set-sys-user-cm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"demo set sys-user cm sys-user-cm\" --help</code></p>"},{"location":"scripts/Tests/test-set-sys-user-cm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Default environment"},{"location":"scripts/Tests/test-set-sys-user-cm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=demo,set,sys-user,cm,sys-user-cm \n</code></pre>"},{"location":"scripts/Tests/test-set-sys-user-cm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"demo set sys-user cm sys-user-cm \" \n</code></pre>"},{"location":"scripts/Tests/test-set-sys-user-cm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'demo,set,sys-user,cm,sys-user-cm'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/test-set-sys-user-cm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"demo set sys-user cm sys-user-cm\" \n</code></pre>"},{"location":"scripts/Tests/test-set-sys-user-cm/#default-environment","title":"Default environment","text":"<p>These keys can be updated via <code>--env.KEY=VALUE</code> or <code>env</code> dictionary in <code>@input.json</code> or using script flags.</p> <ul> <li>CM_SUDO: <code>sudo</code></li> </ul>"},{"location":"scripts/Tests/test-set-sys-user-cm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/Tests/test-set-sys-user-cm/#script-output","title":"Script output","text":"<pre><code>cmr \"demo set sys-user cm sys-user-cm \"  -j\n</code></pre>"},{"location":"scripts/Tests/upgrade-python-pip/","title":"upgrade-python-pip","text":"<p>Automatically generated README for this automation recipe: upgrade-python-pip</p> <p>Category: Tests</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/Tests/upgrade-python-pip/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/Tests/upgrade-python-pip/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/Tests/upgrade-python-pip/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/Tests/upgrade-python-pip/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"upgrade python pip python-pip\" --help</code></p>"},{"location":"scripts/Tests/upgrade-python-pip/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/Tests/upgrade-python-pip/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=upgrade,python,pip,python-pip \n</code></pre>"},{"location":"scripts/Tests/upgrade-python-pip/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"upgrade python pip python-pip \" \n</code></pre>"},{"location":"scripts/Tests/upgrade-python-pip/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'upgrade,python,pip,python-pip'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/Tests/upgrade-python-pip/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"upgrade python pip python-pip\" \n</code></pre>"},{"location":"scripts/Tests/upgrade-python-pip/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <ul> <li>run.bat</li> </ul>"},{"location":"scripts/Tests/upgrade-python-pip/#script-output","title":"Script output","text":"<pre><code>cmr \"upgrade python pip python-pip \"  -j\n</code></pre>"},{"location":"scripts/TinyML-automation/","title":"TinyML-automation","text":"<ul> <li>create-fpgaconvnet-app-tinyml</li> <li>create-fpgaconvnet-config-tinyml</li> <li>flash-tinyml-binary</li> <li>get-microtvm</li> <li>get-zephyr</li> <li>get-zephyr-sdk</li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/","title":"create-fpgaconvnet-app-tinyml","text":"<p>Automatically generated README for this automation recipe: create-fpgaconvnet-app-tinyml</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? False</li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"create app fpgaconvnet\" --help</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=create,app,fpgaconvnet[,variations] \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"create app fpgaconvnet [variations]\" \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'create,app,fpgaconvnet'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"create app fpgaconvnet[variations]\" \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#variations","title":"Variations","text":"<ul> <li> <p>Group \"benchmark\"      Click here to expand this section. <ul> <li><code>_ic</code> (default)</li> </ul> <li> <p>Group \"board\"      Click here to expand this section. <ul> <li><code>_zc706</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TINY_BOARD: <code>zc706</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#default-variations","title":"Default variations","text":"<p><code>_ic,_zc706</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-app-tinyml/#script-output","title":"Script output","text":"<pre><code>cmr \"create app fpgaconvnet [variations]\"  -j\n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/","title":"create-fpgaconvnet-config-tinyml","text":"<p>Automatically generated README for this automation recipe: create-fpgaconvnet-config-tinyml</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li>CM meta description for this script: _cm.json</li> <li>Output cached? True</li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"create config fpgaconvnet\" --help</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker Variations"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=create,config,fpgaconvnet[,variations] \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"create config fpgaconvnet [variations]\" \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'create,config,fpgaconvnet'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"create config fpgaconvnet[variations]\" \n</code></pre>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#variations","title":"Variations","text":"<ul> <li> <p>Group \"benchmark\"      Click here to expand this section. <ul> <li><code>_ic</code> (default)</li> </ul> <li> <p>Group \"board\"      Click here to expand this section. <ul> <li><code>_zc706</code> (default)<ul> <li>ENV variables:<ul> <li>CM_TINY_BOARD: <code>zc706</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#default-variations","title":"Default variations","text":"<p><code>_ic,_zc706</code></p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/create-fpgaconvnet-config-tinyml/#script-output","title":"Script output","text":"<pre><code>cmr \"create config fpgaconvnet [variations]\"  -j\n</code></pre>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/","title":"flash-tinyml-binary","text":"<p>Automatically generated README for this automation recipe: flash-tinyml-binary</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? False</li> </ul>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"flash tiny mlperf mlcommons\" --help</code></p>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=flash,tiny,mlperf,mlcommons[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"flash tiny mlperf mlcommons [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'flash,tiny,mlperf,mlcommons'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"flash tiny mlperf mlcommons[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_NRF</code></li> <li><code>_NUCLEO</code></li> <li><code>_ad</code></li> <li><code>_cmsis_nn</code></li> <li><code>_ic</code></li> <li><code>_kws</code></li> <li><code>_native</code></li> <li><code>_vww</code></li> </ul>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--build_dir=value</code>  \u2192  <code>CM_TINY_BUILD_DIR=value</code></li> </ul>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#versions","title":"Versions","text":"<p>Default version: <code>r1.0</code></p>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/flash-tinyml-binary/#script-output","title":"Script output","text":"<pre><code>cmr \"flash tiny mlperf mlcommons [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/TinyML-automation/get-microtvm/","title":"get-microtvm","text":"<p>Automatically generated README for this automation recipe: get-microtvm</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/TinyML-automation/get-microtvm/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/get-microtvm/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/get-microtvm/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/get-microtvm/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get src source microtvm tiny\" --help</code></p>"},{"location":"scripts/TinyML-automation/get-microtvm/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker VariationsInput Flag Mapping"},{"location":"scripts/TinyML-automation/get-microtvm/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,src,source,microtvm,tiny[,variations] [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/get-microtvm/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get src source microtvm tiny [variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/get-microtvm/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,src,source,microtvm,tiny'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/get-microtvm/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get src source microtvm tiny[variations]\" [--input_flags]\n</code></pre>"},{"location":"scripts/TinyML-automation/get-microtvm/#variations","title":"Variations","text":"<ul> <li> <p>No group (any combination of variations can be selected) Click here to expand this section. <ul> <li><code>_full-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 10</code></li> </ul> </li> </ul> </li> <li><code>_short-history</code><ul> <li>ENV variables:<ul> <li>CM_GIT_DEPTH: <code>--depth 10</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"scripts/TinyML-automation/get-microtvm/#script-flags-mapped-to-environment","title":"Script flags mapped to environment","text":"<ul> <li><code>--ssh=value</code>  \u2192  <code>CM_GIT_SSH=value</code></li> </ul>"},{"location":"scripts/TinyML-automation/get-microtvm/#versions","title":"Versions","text":"<p>Default version: <code>main</code></p> <ul> <li><code>custom</code></li> <li><code>main</code></li> </ul>"},{"location":"scripts/TinyML-automation/get-microtvm/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/get-microtvm/#script-output","title":"Script output","text":"<pre><code>cmr \"get src source microtvm tiny [variations]\" [--input_flags] -j\n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr/","title":"get-zephyr","text":"<p>Automatically generated README for this automation recipe: get-zephyr</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/get-zephyr/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/get-zephyr/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get zephyr\" --help</code></p>"},{"location":"scripts/TinyML-automation/get-zephyr/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/TinyML-automation/get-zephyr/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,zephyr \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get zephyr \" \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,zephyr'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get zephyr\" \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr/#versions","title":"Versions","text":"<p>Default version: <code>v2.7</code></p> <ul> <li><code>v2.7</code></li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run-ubuntu.sh</li> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/get-zephyr/#script-output","title":"Script output","text":"<pre><code>cmr \"get zephyr \"  -j\n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/","title":"get-zephyr-sdk","text":"<p>Automatically generated README for this automation recipe: get-zephyr-sdk</p> <p>Category: TinyML automation</p> <p>License: Apache 2.0</p> <ul> <li> <p>Notes from the authors, contributors and users: README-extra</p> </li> <li> <p>CM meta description for this script: _cm.json</p> </li> <li>Output cached? True</li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#reuse-this-script-in-your-project","title":"Reuse this script in your project","text":""},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#install-mlcommons-cm-automation-meta-framework","title":"Install MLCommons CM automation meta-framework","text":"<ul> <li>Install CM</li> <li>CM Getting Started Guide</li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#pull-cm-repository-with-this-automation-recipe-cm-script","title":"Pull CM repository with this automation recipe (CM script)","text":"<p><code>cm pull repo mlcommons@cm4mlops</code></p>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#print-cm-help-from-the-command-line","title":"Print CM help from the command line","text":"<p><code>cmr \"get zephyr-sdk\" --help</code></p>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#run-this-script","title":"Run this script","text":"CLICLI AltPythonDocker"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#run-this-script-via-cli","title":"Run this script via CLI","text":"<pre><code>cm run script --tags=get,zephyr-sdk \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#run-this-script-via-cli-alternative","title":"Run this script via CLI (alternative)","text":"<pre><code>cmr \"get zephyr-sdk \" \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#run-this-script-from-python","title":"Run this script from Python","text":"<pre><code>import cmind\n\nr = cmind.access({'action':'run'\n              'automation':'script',\n              'tags':'get,zephyr-sdk'\n              'out':'con',\n              ...\n              (other input keys for this script)\n              ...\n             })\n\nif r['return']&gt;0:\n    print (r['error'])\n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#run-this-script-via-docker-beta","title":"Run this script via Docker (beta)","text":"<pre><code>cm docker script \"get zephyr-sdk\" \n</code></pre>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#versions","title":"Versions","text":"<p>Default version: <code>0.13.2</code></p> <ul> <li><code>0.13.1</code></li> <li><code>0.13.2</code></li> <li><code>0.15.0</code></li> </ul>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#native-script-being-run","title":"Native script being run","text":"Linux/macOSWindows <ul> <li>run.sh</li> </ul> <p>No run file exists for Windows</p>"},{"location":"scripts/TinyML-automation/get-zephyr-sdk/#script-output","title":"Script output","text":"<pre><code>cmr \"get zephyr-sdk \"  -j\n</code></pre>"}]}